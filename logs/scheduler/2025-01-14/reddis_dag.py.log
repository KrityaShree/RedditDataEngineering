[2025-01-14T02:51:22.139+0000] {processor.py:186} INFO - Started process (PID=1073) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T02:51:22.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T02:51:22.143+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:22.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T02:51:22.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:22.707+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T02:51:22.713+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T02:51:22.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.624 seconds
[2025-01-14T05:54:18.837+0000] {processor.py:186} INFO - Started process (PID=1075) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T05:54:18.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T05:54:18.846+0000] {logging_mixin.py:190} INFO - [2025-01-14T05:54:18.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T05:54:19.331+0000] {logging_mixin.py:190} INFO - [2025-01-14T05:54:19.328+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T05:54:19.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T05:54:19.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.551 seconds
[2025-01-14T06:55:21.431+0000] {processor.py:186} INFO - Started process (PID=1077) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T06:55:21.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T06:55:21.435+0000] {logging_mixin.py:190} INFO - [2025-01-14T06:55:21.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T06:55:21.950+0000] {logging_mixin.py:190} INFO - [2025-01-14T06:55:21.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T06:55:21.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T06:55:21.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.574 seconds
[2025-01-14T10:11:06.099+0000] {processor.py:186} INFO - Started process (PID=1079) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T10:11:06.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T10:11:06.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T10:11:06.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T10:11:06.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T10:11:06.606+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T10:11:06.610+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T10:11:06.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.545 seconds
[2025-01-14T13:54:56.376+0000] {processor.py:186} INFO - Started process (PID=1081) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T13:54:56.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T13:54:56.380+0000] {logging_mixin.py:190} INFO - [2025-01-14T13:54:56.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T13:54:56.884+0000] {logging_mixin.py:190} INFO - [2025-01-14T13:54:56.880+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T13:54:56.884+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T13:54:56.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.550 seconds
[2025-01-14T15:00:05.699+0000] {processor.py:186} INFO - Started process (PID=1083) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:00:05.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:00:05.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:00:05.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:00:06.247+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:00:06.243+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:00:06.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:00:06.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.596 seconds
[2025-01-14T15:38:46.992+0000] {processor.py:186} INFO - Started process (PID=1085) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:38:46.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:38:46.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:38:46.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:38:47.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:38:47.504+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:38:47.507+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:38:47.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.577 seconds
[2025-01-14T15:39:18.177+0000] {processor.py:186} INFO - Started process (PID=1087) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:18.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:39:18.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:39:18.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:18.686+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:39:18.683+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:39:18.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:18.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.551 seconds
[2025-01-14T15:39:48.953+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:48.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:39:48.960+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:39:48.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:49.442+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:39:49.433+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:39:49.443+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:39:49.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.549 seconds
[2025-01-14T15:40:19.726+0000] {processor.py:186} INFO - Started process (PID=1091) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:19.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:40:19.739+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:40:19.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:20.679+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:40:20.664+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:40:20.681+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:20.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.048 seconds
[2025-01-14T15:40:51.590+0000] {processor.py:186} INFO - Started process (PID=1093) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:51.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:40:51.596+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:40:51.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:52.209+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:40:52.205+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:40:52.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:40:52.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.681 seconds
[2025-01-14T15:41:23.273+0000] {processor.py:186} INFO - Started process (PID=1095) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:23.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:41:23.282+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:41:23.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:24.296+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:41:24.265+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:41:24.296+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:24.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.187 seconds
[2025-01-14T15:41:54.904+0000] {processor.py:186} INFO - Started process (PID=1097) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:54.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:41:54.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:41:54.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:55.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:41:55.426+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:41:55.430+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:41:55.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.573 seconds
[2025-01-14T15:42:26.059+0000] {processor.py:186} INFO - Started process (PID=1099) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:26.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:42:26.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:42:26.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:26.805+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:42:26.800+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:42:26.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:26.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.803 seconds
[2025-01-14T15:42:57.734+0000] {processor.py:186} INFO - Started process (PID=1101) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:57.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:42:57.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:42:57.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:58.358+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:42:58.350+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:42:58.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:42:58.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.694 seconds
[2025-01-14T15:43:29.017+0000] {processor.py:186} INFO - Started process (PID=1103) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:43:29.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:43:29.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:43:29.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:43:29.642+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:43:29.637+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:43:29.643+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:43:29.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.687 seconds
[2025-01-14T15:44:00.323+0000] {processor.py:186} INFO - Started process (PID=1105) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:00.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:44:00.331+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:44:00.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:00.843+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:44:00.840+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:44:00.844+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:00.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.571 seconds
[2025-01-14T15:44:31.162+0000] {processor.py:186} INFO - Started process (PID=1107) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:31.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:44:31.167+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:44:31.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:31.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:44:31.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:44:31.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:44:31.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.592 seconds
[2025-01-14T15:45:01.989+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:02.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:45:02.007+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:45:02.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:02.671+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:45:02.668+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:45:02.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:02.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-14T15:45:33.240+0000] {processor.py:186} INFO - Started process (PID=1111) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:33.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:45:33.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:45:33.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:33.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:45:33.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:45:33.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:45:33.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.618 seconds
[2025-01-14T15:46:04.213+0000] {processor.py:186} INFO - Started process (PID=1113) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:04.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:46:04.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:46:04.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:04.708+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:46:04.705+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:46:04.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:04.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.554 seconds
[2025-01-14T15:46:35.386+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:35.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:46:35.392+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:46:35.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:35.924+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:46:35.920+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:46:35.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:46:35.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.614 seconds
[2025-01-14T15:47:06.156+0000] {processor.py:186} INFO - Started process (PID=1117) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:06.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:47:06.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:47:06.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:07.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:47:07.112+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:47:07.118+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:07.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.021 seconds
[2025-01-14T15:47:37.717+0000] {processor.py:186} INFO - Started process (PID=1119) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:37.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:47:37.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:47:37.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:38.188+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:47:38.184+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:47:38.189+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:47:38.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.547 seconds
[2025-01-14T15:48:08.868+0000] {processor.py:186} INFO - Started process (PID=1121) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:08.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:48:08.877+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:48:08.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:09.421+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:48:09.417+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:48:09.421+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:09.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.620 seconds
[2025-01-14T15:48:39.720+0000] {processor.py:186} INFO - Started process (PID=1123) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:39.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:48:39.738+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:48:39.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:40.264+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:48:40.260+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:48:40.265+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:48:40.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.605 seconds
[2025-01-14T15:49:11.266+0000] {processor.py:186} INFO - Started process (PID=1125) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:11.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:49:11.276+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:49:11.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:11.782+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:49:11.779+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:49:11.783+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:11.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.589 seconds
[2025-01-14T15:49:42.453+0000] {processor.py:186} INFO - Started process (PID=1127) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:42.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:49:42.458+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:49:42.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:43.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:49:43.374+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:49:43.382+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:49:43.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.017 seconds
[2025-01-14T15:50:14.331+0000] {processor.py:186} INFO - Started process (PID=1129) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:14.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:50:14.335+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:50:14.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:14.827+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:50:14.823+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:50:14.828+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:14.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.537 seconds
[2025-01-14T15:50:45.510+0000] {processor.py:186} INFO - Started process (PID=1131) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:45.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:50:45.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:50:45.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:46.087+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:50:46.082+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:50:46.088+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:50:46.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.657 seconds
[2025-01-14T15:51:16.368+0000] {processor.py:186} INFO - Started process (PID=1133) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:16.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:51:16.373+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:51:16.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:16.929+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:51:16.925+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:51:16.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:16.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.600 seconds
[2025-01-14T15:51:47.050+0000] {processor.py:186} INFO - Started process (PID=1135) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:47.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:51:47.056+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:51:47.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:47.568+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:51:47.565+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:51:47.569+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:51:47.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.561 seconds
[2025-01-14T15:52:17.893+0000] {processor.py:186} INFO - Started process (PID=1137) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:17.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:52:17.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:52:17.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:18.409+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:52:18.406+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:52:18.410+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:18.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.561 seconds
[2025-01-14T15:52:48.600+0000] {processor.py:186} INFO - Started process (PID=1139) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:48.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:52:48.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:52:48.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:49.663+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:52:49.656+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:52:49.664+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:52:49.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.134 seconds
[2025-01-14T15:53:20.402+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:20.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:53:20.407+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:53:20.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:20.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:53:20.956+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:53:20.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:20.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.602 seconds
[2025-01-14T15:53:51.628+0000] {processor.py:186} INFO - Started process (PID=1143) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:51.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:53:51.655+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:53:51.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:52.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:53:52.167+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:53:52.172+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:53:52.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.598 seconds
[2025-01-14T15:54:22.558+0000] {processor.py:186} INFO - Started process (PID=1145) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:22.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:54:22.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:54:22.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:23.032+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:54:23.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:54:23.033+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:23.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.527 seconds
[2025-01-14T15:54:53.232+0000] {processor.py:186} INFO - Started process (PID=1147) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:53.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:54:53.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:54:53.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:53.856+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:54:53.852+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:54:53.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:54:53.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.681 seconds
[2025-01-14T15:55:24.197+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:24.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:55:24.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:55:24.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:24.791+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:55:24.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:55:24.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:24.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.645 seconds
[2025-01-14T15:55:55.361+0000] {processor.py:186} INFO - Started process (PID=1151) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:55.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:55:55.369+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:55:55.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:55.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:55:55.894+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:55:55.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:55:55.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.627 seconds
[2025-01-14T15:56:26.458+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:26.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:56:26.461+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:56:26.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:26.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:56:26.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:56:26.947+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:26.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-14T15:56:57.224+0000] {processor.py:186} INFO - Started process (PID=1155) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:57.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:56:57.230+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:56:57.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:57.797+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:56:57.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:56:57.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:56:57.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.629 seconds
[2025-01-14T15:57:28.052+0000] {processor.py:186} INFO - Started process (PID=1157) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:28.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:57:28.076+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:57:28.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:28.548+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:57:28.541+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:57:28.548+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:28.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.543 seconds
[2025-01-14T15:57:58.864+0000] {processor.py:186} INFO - Started process (PID=1159) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:58.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:57:58.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:57:58.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:59.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:57:59.437+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:57:59.441+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:57:59.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.626 seconds
[2025-01-14T15:58:30.324+0000] {processor.py:186} INFO - Started process (PID=1161) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:58:30.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:58:30.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:58:30.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:58:31.005+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:58:31.000+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:58:31.005+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:58:31.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-14T15:59:01.858+0000] {processor.py:186} INFO - Started process (PID=1163) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:01.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:59:01.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:01.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:02.407+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:02.404+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T15:59:02.408+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:02.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.629 seconds
[2025-01-14T15:59:27.559+0000] {processor.py:186} INFO - Started process (PID=1165) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:27.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:59:27.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:27.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:27.650+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:27.649+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 9, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2025-01-14T15:59:27.651+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:27.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.158 seconds
[2025-01-14T15:59:58.330+0000] {processor.py:186} INFO - Started process (PID=1166) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:58.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T15:59:58.334+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:58.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:58.392+0000] {logging_mixin.py:190} INFO - [2025-01-14T15:59:58.391+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 9, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2025-01-14T15:59:58.393+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T15:59:58.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.128 seconds
[2025-01-14T16:00:03.523+0000] {processor.py:186} INFO - Started process (PID=1167) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:03.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:00:03.528+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:03.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:03.675+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:03.668+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:00:03.676+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:03.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.244 seconds
[2025-01-14T16:00:29.218+0000] {processor.py:186} INFO - Started process (PID=1168) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:29.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:00:29.224+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:29.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:29.308+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:29.302+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:00:29.308+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:29.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.220 seconds
[2025-01-14T16:00:59.720+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:59.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:00:59.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:59.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:59.795+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:00:59.790+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:00:59.795+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:00:59.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.139 seconds
[2025-01-14T16:01:30.513+0000] {processor.py:186} INFO - Started process (PID=1170) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:01:30.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:01:30.536+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:01:30.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:01:30.678+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:01:30.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:01:30.679+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:01:30.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.287 seconds
[2025-01-14T16:02:00.871+0000] {processor.py:186} INFO - Started process (PID=1171) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:00.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:02:00.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:02:00.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:00.971+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:02:00.967+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:02:00.972+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:01.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.199 seconds
[2025-01-14T16:02:31.291+0000] {processor.py:186} INFO - Started process (PID=1172) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:31.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:02:31.298+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:02:31.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:31.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:02:31.373+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:02:31.378+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:02:31.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.185 seconds
[2025-01-14T16:03:01.934+0000] {processor.py:186} INFO - Started process (PID=1173) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:01.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:03:01.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:03:01.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:02.026+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:03:02.022+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:03:02.026+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:02.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.156 seconds
[2025-01-14T16:03:32.734+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:32.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:03:32.742+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:03:32.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:32.881+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:03:32.874+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:03:32.881+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:03:32.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.281 seconds
[2025-01-14T16:04:03.734+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:03.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:04:03.740+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:04:03.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:03.834+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:04:03.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:04:03.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:03.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.174 seconds
[2025-01-14T16:04:34.271+0000] {processor.py:186} INFO - Started process (PID=1176) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:34.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:04:34.277+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:04:34.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:34.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:04:34.341+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:04:34.346+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:04:34.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.160 seconds
[2025-01-14T16:05:04.785+0000] {processor.py:186} INFO - Started process (PID=1177) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:04.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:05:04.790+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:05:04.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:04.859+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:05:04.855+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:05:04.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:04.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.127 seconds
[2025-01-14T16:05:35.321+0000] {processor.py:186} INFO - Started process (PID=1178) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:35.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:05:35.328+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:05:35.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:35.413+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:05:35.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:05:35.414+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:05:35.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.165 seconds
[2025-01-14T16:06:06.024+0000] {processor.py:186} INFO - Started process (PID=1179) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:06.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:06:06.030+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:06:06.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:06.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:06:06.099+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:06:06.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:06.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.154 seconds
[2025-01-14T16:06:36.528+0000] {processor.py:186} INFO - Started process (PID=1180) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:36.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:06:36.533+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:06:36.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:36.687+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:06:36.676+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:06:36.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:06:36.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.275 seconds
[2025-01-14T16:07:07.025+0000] {processor.py:186} INFO - Started process (PID=1181) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:07.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:07:07.039+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:07:07.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:07.130+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:07:07.126+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:07:07.130+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:07.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.198 seconds
[2025-01-14T16:07:37.713+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:37.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:07:37.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:07:37.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:37.801+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:07:37.785+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:07:37.804+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:07:37.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.150 seconds
[2025-01-14T16:08:08.227+0000] {processor.py:186} INFO - Started process (PID=1183) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:08.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:08:08.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:08:08.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:08.300+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:08:08.296+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:08:08.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:08.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.140 seconds
[2025-01-14T16:08:38.865+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:38.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:08:38.872+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:08:38.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:38.984+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:08:38.978+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:08:38.985+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:08:39.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.225 seconds
[2025-01-14T16:09:09.476+0000] {processor.py:186} INFO - Started process (PID=1185) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:09.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:09:09.481+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:09:09.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:09.562+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:09:09.557+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:09:09.562+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:09.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.142 seconds
[2025-01-14T16:09:39.967+0000] {processor.py:186} INFO - Started process (PID=1186) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:39.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:09:39.971+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:09:39.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:40.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:09:40.053+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:09:40.057+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:09:40.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.146 seconds
[2025-01-14T16:10:10.533+0000] {processor.py:186} INFO - Started process (PID=1187) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:10.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:10:10.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:10:10.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:10.618+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:10:10.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:10:10.618+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:10.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.136 seconds
[2025-01-14T16:10:41.092+0000] {processor.py:186} INFO - Started process (PID=1188) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:41.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:10:41.097+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:10:41.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:41.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:10:41.168+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:10:41.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:10:41.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.133 seconds
[2025-01-14T16:11:11.888+0000] {processor.py:186} INFO - Started process (PID=1189) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:11.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:11:11.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:11:11.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:11.987+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:11:11.982+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:11:11.988+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:12.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.155 seconds
[2025-01-14T16:11:42.373+0000] {processor.py:186} INFO - Started process (PID=1190) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:42.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:11:42.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:11:42.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:42.469+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:11:42.464+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:11:42.469+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:11:42.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.170 seconds
[2025-01-14T16:12:12.918+0000] {processor.py:186} INFO - Started process (PID=1191) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:12.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:12:12.945+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:12:12.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:13.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:12:13.050+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:12:13.058+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:13.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.188 seconds
[2025-01-14T16:12:43.408+0000] {processor.py:186} INFO - Started process (PID=1192) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:43.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:12:43.412+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:12:43.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:43.480+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:12:43.476+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:12:43.481+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:12:43.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.148 seconds
[2025-01-14T16:13:13.931+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:13.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:13:13.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:13:13.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:14.026+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:13:14.022+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:13:14.027+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:14.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T16:13:44.463+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:44.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:13:44.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:13:44.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:44.550+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:13:44.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:13:44.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:13:44.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.136 seconds
[2025-01-14T16:14:15.026+0000] {processor.py:186} INFO - Started process (PID=1195) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:15.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:14:15.035+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:14:15.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:15.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:14:15.113+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:14:15.117+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:15.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.178 seconds
[2025-01-14T16:14:45.617+0000] {processor.py:186} INFO - Started process (PID=1196) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:45.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:14:45.622+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:14:45.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:45.695+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:14:45.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:14:45.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:14:45.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.131 seconds
[2025-01-14T16:15:16.202+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:16.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:15:16.213+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:15:16.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:16.487+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:15:16.468+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:15:16.488+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:16.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.545 seconds
[2025-01-14T16:15:47.512+0000] {processor.py:186} INFO - Started process (PID=1198) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:47.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:15:47.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:15:47.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:47.590+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:15:47.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:15:47.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:15:47.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.144 seconds
[2025-01-14T16:16:18.167+0000] {processor.py:186} INFO - Started process (PID=1199) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:18.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:16:18.173+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:16:18.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:18.253+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:16:18.247+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:16:18.254+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:18.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.193 seconds
[2025-01-14T16:16:48.578+0000] {processor.py:186} INFO - Started process (PID=1200) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:48.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:16:48.592+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:16:48.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:48.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:16:48.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:16:48.661+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:16:48.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.167 seconds
[2025-01-14T16:17:19.168+0000] {processor.py:186} INFO - Started process (PID=1201) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:19.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:17:19.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:17:19.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:19.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:17:19.245+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:17:19.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:19.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.127 seconds
[2025-01-14T16:17:49.742+0000] {processor.py:186} INFO - Started process (PID=1202) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:49.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:17:49.749+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:17:49.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:49.833+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:17:49.828+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:17:49.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:17:49.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.173 seconds
[2025-01-14T16:18:20.253+0000] {processor.py:186} INFO - Started process (PID=1203) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:20.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:18:20.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:18:20.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:20.324+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:18:20.320+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:18:20.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:20.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.173 seconds
[2025-01-14T16:18:50.975+0000] {processor.py:186} INFO - Started process (PID=1204) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:50.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:18:50.979+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:18:50.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:51.040+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:18:51.036+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:18:51.041+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:18:51.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.111 seconds
[2025-01-14T16:19:21.543+0000] {processor.py:186} INFO - Started process (PID=1205) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:21.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:19:21.548+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:19:21.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:21.631+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:19:21.626+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:19:21.631+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:21.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.170 seconds
[2025-01-14T16:19:52.093+0000] {processor.py:186} INFO - Started process (PID=1206) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:52.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:19:52.098+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:19:52.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:52.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:19:52.178+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:19:52.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:19:52.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.139 seconds
[2025-01-14T16:20:22.609+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:22.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:20:22.614+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:20:22.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:22.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:20:22.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:20:22.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:22.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T16:20:53.161+0000] {processor.py:186} INFO - Started process (PID=1208) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:53.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:20:53.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:20:53.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:53.258+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:20:53.253+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:20:53.259+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:20:53.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.157 seconds
[2025-01-14T16:21:23.655+0000] {processor.py:186} INFO - Started process (PID=1209) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:23.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:21:23.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:21:23.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:23.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:21:23.744+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:21:23.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:23.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.146 seconds
[2025-01-14T16:21:54.211+0000] {processor.py:186} INFO - Started process (PID=1210) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:54.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:21:54.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:21:54.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:54.302+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:21:54.298+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:21:54.303+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:21:54.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T16:22:24.708+0000] {processor.py:186} INFO - Started process (PID=1211) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:24.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:22:24.718+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:22:24.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:24.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:22:24.788+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:22:24.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:24.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.182 seconds
[2025-01-14T16:22:55.232+0000] {processor.py:186} INFO - Started process (PID=1212) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:55.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:22:55.237+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:22:55.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:55.322+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:22:55.318+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:22:55.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:22:55.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.158 seconds
[2025-01-14T16:23:25.787+0000] {processor.py:186} INFO - Started process (PID=1213) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:25.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:23:25.792+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:23:25.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:25.867+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:23:25.856+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:23:25.867+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:25.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.158 seconds
[2025-01-14T16:23:56.275+0000] {processor.py:186} INFO - Started process (PID=1214) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:56.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:23:56.279+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:23:56.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:56.357+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:23:56.353+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:23:56.357+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:23:56.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.128 seconds
[2025-01-14T16:24:26.792+0000] {processor.py:186} INFO - Started process (PID=1215) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:26.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:24:26.797+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:24:26.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:26.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:24:26.874+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:24:26.878+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:26.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.149 seconds
[2025-01-14T16:24:57.221+0000] {processor.py:186} INFO - Started process (PID=1216) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:57.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:24:57.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:24:57.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:57.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:24:57.310+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:24:57.320+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:24:57.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.190 seconds
[2025-01-14T16:25:27.844+0000] {processor.py:186} INFO - Started process (PID=1217) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:27.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:25:27.849+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:25:27.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:27.914+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:25:27.911+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:25:27.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:27.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.168 seconds
[2025-01-14T16:25:58.345+0000] {processor.py:186} INFO - Started process (PID=1218) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:58.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:25:58.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:25:58.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:58.425+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:25:58.420+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:25:58.425+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:25:58.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.130 seconds
[2025-01-14T16:26:29.007+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:29.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:26:29.010+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:26:29.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:29.077+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:26:29.063+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:26:29.078+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:29.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.138 seconds
[2025-01-14T16:26:59.667+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:59.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:26:59.672+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:26:59.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:59.743+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:26:59.740+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:26:59.744+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:26:59.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.134 seconds
[2025-01-14T16:27:30.291+0000] {processor.py:186} INFO - Started process (PID=1221) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:27:30.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:27:30.296+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:27:30.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:27:30.356+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:27:30.352+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:27:30.356+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:27:30.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.137 seconds
[2025-01-14T16:28:00.955+0000] {processor.py:186} INFO - Started process (PID=1222) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:00.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:28:00.960+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:28:00.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:01.040+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:28:01.031+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:28:01.041+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:01.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.225 seconds
[2025-01-14T16:28:32.607+0000] {processor.py:186} INFO - Started process (PID=1223) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:32.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:28:32.665+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:28:32.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:32.986+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:28:32.978+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:28:32.987+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:28:33.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.681 seconds
[2025-01-14T16:29:04.107+0000] {processor.py:186} INFO - Started process (PID=1224) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:04.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:29:04.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:29:04.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:04.213+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:29:04.209+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:29:04.213+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:04.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.210 seconds
[2025-01-14T16:29:34.788+0000] {processor.py:186} INFO - Started process (PID=1225) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:34.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:29:34.794+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:29:34.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:34.880+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:29:34.876+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:29:34.881+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:29:34.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.206 seconds
[2025-01-14T16:30:05.383+0000] {processor.py:186} INFO - Started process (PID=1226) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:05.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:30:05.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:30:05.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:05.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:30:05.455+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:30:05.463+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:05.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.141 seconds
[2025-01-14T16:30:35.953+0000] {processor.py:186} INFO - Started process (PID=1227) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:35.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:30:35.958+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:30:35.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:36.030+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:30:36.023+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:30:36.032+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:30:36.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T16:31:06.953+0000] {processor.py:186} INFO - Started process (PID=1228) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:06.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:31:06.962+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:31:06.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:07.098+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:31:07.069+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:31:07.099+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:07.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.240 seconds
[2025-01-14T16:31:37.771+0000] {processor.py:186} INFO - Started process (PID=1229) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:37.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:31:37.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:31:37.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:37.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:31:37.861+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:31:37.865+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:31:37.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.169 seconds
[2025-01-14T16:32:08.318+0000] {processor.py:186} INFO - Started process (PID=1230) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:08.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:32:08.323+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:32:08.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:08.411+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:32:08.407+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:32:08.411+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:08.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.149 seconds
[2025-01-14T16:32:38.883+0000] {processor.py:186} INFO - Started process (PID=1231) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:38.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:32:38.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:32:38.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:38.971+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:32:38.967+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:32:38.972+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:32:39.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.160 seconds
[2025-01-14T16:33:09.477+0000] {processor.py:186} INFO - Started process (PID=1232) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:09.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:33:09.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:33:09.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:09.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:33:09.563+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:33:09.567+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:09.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.136 seconds
[2025-01-14T16:33:40.006+0000] {processor.py:186} INFO - Started process (PID=1233) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:40.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:33:40.011+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:33:40.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:40.112+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:33:40.108+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:33:40.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:33:40.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.178 seconds
[2025-01-14T16:34:10.567+0000] {processor.py:186} INFO - Started process (PID=1234) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:10.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:34:10.571+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:34:10.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:10.626+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:34:10.622+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:34:10.626+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:10.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.147 seconds
[2025-01-14T16:34:41.001+0000] {processor.py:186} INFO - Started process (PID=1235) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:41.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:34:41.018+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:34:41.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:41.072+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:34:41.069+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:34:41.073+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:34:41.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.135 seconds
[2025-01-14T16:35:11.650+0000] {processor.py:186} INFO - Started process (PID=1236) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:11.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:35:11.655+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:35:11.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:11.728+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:35:11.724+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:35:11.729+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:11.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.148 seconds
[2025-01-14T16:35:42.387+0000] {processor.py:186} INFO - Started process (PID=1237) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:42.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:35:42.393+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:35:42.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:42.464+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:35:42.460+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:35:42.464+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:35:42.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.152 seconds
[2025-01-14T16:36:12.897+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:12.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:36:12.903+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:36:12.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:12.992+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:36:12.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:36:12.992+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:13.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.152 seconds
[2025-01-14T16:36:43.462+0000] {processor.py:186} INFO - Started process (PID=1239) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:43.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:36:43.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:36:43.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:43.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:36:43.534+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:36:43.541+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:36:43.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.171 seconds
[2025-01-14T16:37:13.970+0000] {processor.py:186} INFO - Started process (PID=1240) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:13.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:37:13.975+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:37:13.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:14.040+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:37:14.036+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:37:14.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:14.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.147 seconds
[2025-01-14T16:37:44.632+0000] {processor.py:186} INFO - Started process (PID=1241) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:44.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:37:44.644+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:37:44.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:45.449+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:37:45.240+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:37:45.454+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:37:45.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.295 seconds
[2025-01-14T16:38:16.614+0000] {processor.py:186} INFO - Started process (PID=1242) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:16.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:38:16.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:38:16.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:16.705+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:38:16.695+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:38:16.706+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:16.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.158 seconds
[2025-01-14T16:38:47.307+0000] {processor.py:186} INFO - Started process (PID=1243) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:47.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:38:47.313+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:38:47.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:47.397+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:38:47.393+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:38:47.397+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:38:47.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.149 seconds
[2025-01-14T16:39:17.866+0000] {processor.py:186} INFO - Started process (PID=1244) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:17.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:39:17.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:39:17.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:17.935+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:39:17.929+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:39:17.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:17.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.120 seconds
[2025-01-14T16:39:48.528+0000] {processor.py:186} INFO - Started process (PID=1245) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:48.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:39:48.535+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:39:48.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:48.601+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:39:48.597+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:39:48.602+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:39:48.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.166 seconds
[2025-01-14T16:40:19.045+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:19.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:40:19.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:40:19.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:19.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:40:19.128+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:40:19.132+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:19.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.134 seconds
[2025-01-14T16:40:49.725+0000] {processor.py:186} INFO - Started process (PID=1247) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:49.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:40:49.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:40:49.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:49.859+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:40:49.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:40:49.861+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:40:49.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.218 seconds
[2025-01-14T16:41:20.198+0000] {processor.py:186} INFO - Started process (PID=1248) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:20.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:41:20.204+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:41:20.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:20.274+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:41:20.270+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:41:20.275+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:20.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.144 seconds
[2025-01-14T16:41:50.856+0000] {processor.py:186} INFO - Started process (PID=1249) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:50.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:41:50.860+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:41:50.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:50.920+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:41:50.916+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:41:50.920+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:41:50.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.124 seconds
[2025-01-14T16:42:21.598+0000] {processor.py:186} INFO - Started process (PID=1250) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:21.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:42:21.602+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:42:21.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:21.677+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:42:21.672+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:42:21.678+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:21.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.259 seconds
[2025-01-14T16:42:52.130+0000] {processor.py:186} INFO - Started process (PID=1251) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:52.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:42:52.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:42:52.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:52.225+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:42:52.220+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:42:52.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:42:52.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.188 seconds
[2025-01-14T16:43:22.849+0000] {processor.py:186} INFO - Started process (PID=1252) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:22.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:43:22.853+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:43:22.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:22.944+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:43:22.939+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:43:22.944+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:23.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.189 seconds
[2025-01-14T16:43:53.796+0000] {processor.py:186} INFO - Started process (PID=1253) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:53.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:43:53.800+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:43:53.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:53.924+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:43:53.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:43:53.925+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:43:54.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.308 seconds
[2025-01-14T16:44:25.004+0000] {processor.py:186} INFO - Started process (PID=1254) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:25.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:44:25.022+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:44:25.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:25.121+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:44:25.116+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:44:25.121+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:25.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.247 seconds
[2025-01-14T16:44:56.256+0000] {processor.py:186} INFO - Started process (PID=1255) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:56.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:44:56.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:44:56.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:56.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:44:56.344+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:44:56.350+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:44:56.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.208 seconds
[2025-01-14T16:45:26.774+0000] {processor.py:186} INFO - Started process (PID=1256) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:26.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:45:26.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:45:26.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:26.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:45:26.861+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:45:26.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:26.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.156 seconds
[2025-01-14T16:45:57.502+0000] {processor.py:186} INFO - Started process (PID=1257) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:57.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:45:57.508+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:45:57.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:57.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:45:57.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:45:57.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:45:57.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.162 seconds
[2025-01-14T16:46:28.141+0000] {processor.py:186} INFO - Started process (PID=1258) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:28.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:46:28.153+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:46:28.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:28.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:46:28.228+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:46:28.233+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:28.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.186 seconds
[2025-01-14T16:46:58.728+0000] {processor.py:186} INFO - Started process (PID=1259) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:58.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:46:58.734+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:46:58.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:58.804+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:46:58.800+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:46:58.805+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:46:58.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.184 seconds
[2025-01-14T16:47:29.269+0000] {processor.py:186} INFO - Started process (PID=1260) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:47:29.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:47:29.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:47:29.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:47:29.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:47:29.345+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:47:29.349+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:47:29.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.128 seconds
[2025-01-14T16:49:31.287+0000] {processor.py:186} INFO - Started process (PID=1261) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:49:31.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:49:31.291+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:49:31.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:49:31.362+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:49:31.358+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:49:31.363+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:49:31.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.139 seconds
[2025-01-14T16:50:01.899+0000] {processor.py:186} INFO - Started process (PID=1262) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:01.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:50:01.903+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:50:01.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:01.966+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:50:01.962+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:50:01.966+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:02.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T16:50:32.499+0000] {processor.py:186} INFO - Started process (PID=1263) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:32.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:50:32.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:50:32.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:32.583+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:50:32.579+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:50:32.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:50:32.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.191 seconds
[2025-01-14T16:51:02.866+0000] {processor.py:186} INFO - Started process (PID=1264) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:02.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:51:02.876+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:51:02.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:02.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:51:02.959+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:51:02.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:03.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.195 seconds
[2025-01-14T16:51:36.925+0000] {processor.py:186} INFO - Started process (PID=1265) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:36.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:51:36.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:51:36.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:38.170+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:51:37.993+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:51:38.184+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:51:38.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.591 seconds
[2025-01-14T16:52:20.587+0000] {processor.py:186} INFO - Started process (PID=1266) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:20.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:52:20.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:52:20.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:22.933+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:52:22.916+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:52:22.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:23.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.630 seconds
[2025-01-14T16:52:53.742+0000] {processor.py:186} INFO - Started process (PID=1267) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:53.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:52:53.751+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:52:53.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:53.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:52:53.853+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:52:53.858+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:52:53.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.215 seconds
[2025-01-14T16:53:28.381+0000] {processor.py:186} INFO - Started process (PID=1268) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:28.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:53:28.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:53:28.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:28.595+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:53:28.589+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:53:28.596+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:28.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.466 seconds
[2025-01-14T16:53:59.445+0000] {processor.py:186} INFO - Started process (PID=1269) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:59.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:53:59.450+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:53:59.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:59.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:53:59.526+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:53:59.531+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:53:59.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.184 seconds
[2025-01-14T16:54:29.999+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:54:30.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:54:30.008+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:54:30.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:54:30.081+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:54:30.077+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:54:30.082+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:54:30.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.158 seconds
[2025-01-14T16:55:00.671+0000] {processor.py:186} INFO - Started process (PID=1271) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:00.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:55:00.681+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:55:00.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:00.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:55:00.772+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:55:00.777+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:00.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.212 seconds
[2025-01-14T16:55:31.191+0000] {processor.py:186} INFO - Started process (PID=1272) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:31.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:55:31.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:55:31.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:31.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:55:31.273+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:55:31.278+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:55:31.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.152 seconds
[2025-01-14T16:56:01.736+0000] {processor.py:186} INFO - Started process (PID=1273) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:01.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:56:01.741+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:56:01.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:01.814+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:56:01.809+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:56:01.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:01.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.142 seconds
[2025-01-14T16:56:32.233+0000] {processor.py:186} INFO - Started process (PID=1274) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:32.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:56:32.238+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:56:32.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:32.322+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:56:32.317+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:56:32.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:56:32.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.144 seconds
[2025-01-14T16:57:02.884+0000] {processor.py:186} INFO - Started process (PID=1275) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:02.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:57:02.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:57:02.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:02.948+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:57:02.944+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:57:02.948+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:02.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.127 seconds
[2025-01-14T16:57:33.512+0000] {processor.py:186} INFO - Started process (PID=1276) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:33.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:57:33.516+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:57:33.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:33.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:57:33.574+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:57:33.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:57:33.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.145 seconds
[2025-01-14T16:58:04.090+0000] {processor.py:186} INFO - Started process (PID=1277) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:04.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:58:04.094+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:58:04.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:04.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:58:04.156+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:58:04.160+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:04.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.133 seconds
[2025-01-14T16:58:34.727+0000] {processor.py:186} INFO - Started process (PID=1278) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:34.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:58:34.735+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:58:34.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:34.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:58:34.802+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:58:34.811+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:58:34.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.169 seconds
[2025-01-14T16:59:05.391+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:05.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:59:05.395+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:59:05.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:05.461+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:59:05.457+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:59:05.462+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:05.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.138 seconds
[2025-01-14T16:59:36.018+0000] {processor.py:186} INFO - Started process (PID=1280) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:36.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T16:59:36.022+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:59:36.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:36.102+0000] {logging_mixin.py:190} INFO - [2025-01-14T16:59:36.098+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T16:59:36.103+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T16:59:36.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.168 seconds
[2025-01-14T17:00:06.613+0000] {processor.py:186} INFO - Started process (PID=1281) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:06.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:00:06.617+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:00:06.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:06.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:00:06.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:00:06.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:06.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.139 seconds
[2025-01-14T17:00:37.204+0000] {processor.py:186} INFO - Started process (PID=1282) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:37.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:00:37.213+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:00:37.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:37.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:00:37.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:00:37.288+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:00:37.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.156 seconds
[2025-01-14T17:01:07.915+0000] {processor.py:186} INFO - Started process (PID=1283) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:07.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:01:07.919+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:01:07.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:07.991+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:01:07.979+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:01:07.992+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:08.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.154 seconds
[2025-01-14T17:01:38.698+0000] {processor.py:186} INFO - Started process (PID=1284) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:38.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:01:38.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:01:38.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:38.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:01:38.775+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:01:38.779+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:01:38.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.141 seconds
[2025-01-14T17:02:09.380+0000] {processor.py:186} INFO - Started process (PID=1285) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:09.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:02:09.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:02:09.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:09.470+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:02:09.456+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:02:09.470+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:09.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.193 seconds
[2025-01-14T17:02:40.378+0000] {processor.py:186} INFO - Started process (PID=1286) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:40.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:02:40.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:02:40.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:40.634+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:02:40.611+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:02:40.641+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:02:40.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.462 seconds
[2025-01-14T17:03:11.095+0000] {processor.py:186} INFO - Started process (PID=1287) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:11.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:03:11.099+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:03:11.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:11.153+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:03:11.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:03:11.153+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:11.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.135 seconds
[2025-01-14T17:03:41.525+0000] {processor.py:186} INFO - Started process (PID=1288) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:41.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:03:41.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:03:41.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:41.620+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:03:41.616+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:03:41.621+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:03:41.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.181 seconds
[2025-01-14T17:04:12.491+0000] {processor.py:186} INFO - Started process (PID=1289) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:12.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:04:12.498+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:04:12.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:12.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:04:12.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:04:12.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:12.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.200 seconds
[2025-01-14T17:04:43.317+0000] {processor.py:186} INFO - Started process (PID=1290) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:43.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:04:43.322+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:04:43.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:43.393+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:04:43.389+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:04:43.393+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:04:43.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.156 seconds
[2025-01-14T17:05:14.191+0000] {processor.py:186} INFO - Started process (PID=1291) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:14.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:05:14.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:05:14.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:14.276+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:05:14.272+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:05:14.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:14.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.168 seconds
[2025-01-14T17:05:44.847+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:44.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:05:44.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:05:44.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:45.044+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:05:44.984+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:05:45.045+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:05:45.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.442 seconds
[2025-01-14T17:06:15.737+0000] {processor.py:186} INFO - Started process (PID=1293) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:15.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:06:15.745+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:06:15.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:15.839+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:06:15.834+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:06:15.839+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:15.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.174 seconds
[2025-01-14T17:06:46.410+0000] {processor.py:186} INFO - Started process (PID=1294) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:46.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:06:46.415+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:06:46.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:46.492+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:06:46.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:06:46.492+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:06:46.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.153 seconds
[2025-01-14T17:07:16.899+0000] {processor.py:186} INFO - Started process (PID=1295) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:16.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:07:16.904+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:07:16.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:16.960+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:07:16.956+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:07:16.961+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:17.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.120 seconds
[2025-01-14T17:07:47.515+0000] {processor.py:186} INFO - Started process (PID=1296) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:47.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:07:47.520+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:07:47.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:47.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:07:47.597+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:07:47.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:07:47.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.140 seconds
[2025-01-14T17:08:18.073+0000] {processor.py:186} INFO - Started process (PID=1297) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:18.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:08:18.077+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:08:18.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:18.141+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:08:18.137+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:08:18.141+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:18.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.145 seconds
[2025-01-14T17:08:48.599+0000] {processor.py:186} INFO - Started process (PID=1298) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:48.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:08:48.602+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:08:48.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:48.684+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:08:48.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:08:48.685+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:08:48.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.131 seconds
[2025-01-14T17:09:19.171+0000] {processor.py:186} INFO - Started process (PID=1299) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:19.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:09:19.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:09:19.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:19.376+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:09:19.373+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:09:19.377+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:19.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.258 seconds
[2025-01-14T17:09:49.866+0000] {processor.py:186} INFO - Started process (PID=1300) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:49.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:09:49.880+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:09:49.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:50.001+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:09:49.983+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:09:50.002+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:09:50.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.251 seconds
[2025-01-14T17:10:20.599+0000] {processor.py:186} INFO - Started process (PID=1301) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:10:20.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:10:20.603+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:10:20.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:10:20.719+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:10:20.714+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:10:20.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:10:20.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.197 seconds
[2025-01-14T17:11:53.434+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:11:53.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:11:53.550+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:11:53.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:11:54.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:11:54.839+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:11:54.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:11:55.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.002 seconds
[2025-01-14T17:12:25.703+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:25.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:12:25.723+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:12:25.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:25.851+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:12:25.845+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:12:25.851+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:25.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.286 seconds
[2025-01-14T17:12:56.436+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:56.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:12:56.448+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:12:56.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:56.592+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:12:56.585+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:12:56.593+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:12:56.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.274 seconds
[2025-01-14T17:13:27.067+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:27.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:13:27.088+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:13:27.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:27.156+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:13:27.152+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:13:27.156+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:27.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.171 seconds
[2025-01-14T17:13:57.549+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:57.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:13:57.553+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:13:57.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:57.622+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:13:57.612+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
  File "/opt/airflow/pipelines/aws_s3_pipeline.py", line 1, in <module>
    from etls.aws_etl import connect_to_s3, create_bucket_if_not_exist, upload_to_s3
  File "/opt/airflow/etls/aws_etl.py", line 1, in <module>
    from utils.constants import AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-14T17:13:57.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:13:57.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.206 seconds
[2025-01-14T17:14:28.389+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:14:28.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:14:28.401+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:14:28.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:14:33.094+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:14:33.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:14:33.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:14:33.270+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:14:33.270+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-14T17:14:33.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 4.944 seconds
[2025-01-14T17:15:04.029+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:04.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:15:04.040+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:04.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:05.243+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:05.274+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:05.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:15:05.294+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:05.294+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:15:05.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.304 seconds
[2025-01-14T17:15:35.796+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:35.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:15:35.807+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:35.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:36.916+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:15:36.958+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:36.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:15:36.982+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:15:36.982+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:15:36.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.227 seconds
[2025-01-14T17:16:07.351+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:07.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:16:07.359+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:07.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:08.337+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:08.371+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:08.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:16:08.398+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:08.398+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:16:08.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.083 seconds
[2025-01-14T17:16:38.970+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:38.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:16:38.990+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:38.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:39.876+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:16:39.923+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:39.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:16:39.943+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:16:39.943+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:16:39.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.004 seconds
[2025-01-14T17:17:10.578+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:10.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:17:10.585+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:10.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:11.472+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:11.504+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:11.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:17:11.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:11.522+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:17:11.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.976 seconds
[2025-01-14T17:17:42.020+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:42.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:17:42.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:42.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:42.900+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:17:42.942+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:42.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:17:42.989+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:17:42.989+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:17:43.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.003 seconds
[2025-01-14T17:18:13.717+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:13.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:18:13.725+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:13.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:14.954+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:15.012+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:15.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:18:15.038+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:15.037+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:18:15.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.365 seconds
[2025-01-14T17:18:45.289+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:45.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:18:45.301+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:45.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:46.249+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:18:46.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:46.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:18:46.301+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:18:46.300+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:18:46.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.067 seconds
[2025-01-14T17:19:17.035+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:17.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:19:17.043+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:17.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:18.127+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:18.193+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:18.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:19:18.221+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:18.221+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:19:18.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.220 seconds
[2025-01-14T17:19:48.573+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:48.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:19:48.587+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:48.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:50.360+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:19:50.412+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:50.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:19:50.434+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:19:50.434+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:19:50.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.903 seconds
[2025-01-14T17:20:21.215+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:21.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:20:21.233+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:21.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:22.583+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:22.628+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:22.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:20:22.651+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:22.651+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:20:22.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.478 seconds
[2025-01-14T17:20:53.263+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:53.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:20:53.275+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:53.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:54.275+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:20:54.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:54.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:20:54.339+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:20:54.339+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:20:54.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.114 seconds
[2025-01-14T17:21:24.899+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:24.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:21:24.916+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:24.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:26.030+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:26.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:26.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:21:26.135+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:26.135+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:21:26.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.303 seconds
[2025-01-14T17:21:56.416+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:56.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:21:56.423+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:56.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:57.530+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:21:57.566+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:57.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:21:57.586+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:21:57.586+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:21:57.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.196 seconds
[2025-01-14T17:22:28.195+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:22:28.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:22:28.210+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:22:28.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:22:29.163+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:22:29.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:22:29.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:22:29.215+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:22:29.215+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:22:29.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.064 seconds
[2025-01-14T17:22:59.706+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:22:59.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:22:59.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:22:59.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:23:00.685+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:23:00.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:23:00.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:23:00.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:23:00.731+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:23:00.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.055 seconds
[2025-01-14T17:23:31.467+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:23:31.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:23:31.477+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:23:31.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:23:32.287+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:23:32.375+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:23:32.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:23:32.413+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:23:32.413+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:23:32.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.989 seconds
[2025-01-14T17:24:03.163+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:03.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:24:03.171+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:03.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:04.134+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:04.186+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:04.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:24:04.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:04.218+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:24:04.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.104 seconds
[2025-01-14T17:24:34.798+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:34.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:24:34.811+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:34.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:35.726+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:24:35.757+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:35.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:24:35.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:24:35.776+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:24:35.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.017 seconds
[2025-01-14T17:25:06.486+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:06.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:25:06.493+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:06.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:07.595+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:07.639+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:07.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:25:07.658+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:07.658+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:25:07.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.205 seconds
[2025-01-14T17:25:38.268+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:38.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:25:38.279+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:38.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:39.192+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:25:39.226+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:39.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:25:39.247+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:25:39.247+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:25:39.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.021 seconds
[2025-01-14T17:26:09.950+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:09.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:26:09.974+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:09.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:10.907+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:10.960+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:10.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:26:10.979+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:10.979+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:26:10.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.059 seconds
[2025-01-14T17:26:41.596+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:41.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:26:41.612+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:41.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:42.680+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:26:42.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:42.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:26:42.752+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:26:42.751+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:26:42.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.185 seconds
[2025-01-14T17:27:13.129+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:13.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:27:13.142+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:13.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:14.109+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:14.145+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:14.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:27:14.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:14.172+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:27:14.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.079 seconds
[2025-01-14T17:27:44.832+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:44.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:27:44.839+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:44.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:46.082+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:27:46.126+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:46.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:27:46.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:27:46.146+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:27:46.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.368 seconds
[2025-01-14T17:28:16.452+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:16.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:28:16.462+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:16.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:17.493+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:17.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:17.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:28:17.550+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:17.550+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:28:17.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.130 seconds
[2025-01-14T17:28:48.397+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:48.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:28:48.404+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:48.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:49.557+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:28:49.604+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:49.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:28:49.627+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:28:49.626+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:28:49.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.260 seconds
[2025-01-14T17:29:20.023+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:20.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:29:20.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:20.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:21.199+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:21.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:21.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:29:21.280+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:21.280+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:29:21.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.325 seconds
[2025-01-14T17:29:51.644+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:51.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:29:51.653+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:51.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:52.458+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:29:52.489+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:52.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:29:52.518+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:29:52.518+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:29:52.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.926 seconds
[2025-01-14T17:30:23.080+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:23.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:30:23.091+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:23.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:23.977+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:24.026+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:24.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:30:24.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:24.047+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:30:24.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.998 seconds
[2025-01-14T17:30:54.501+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:54.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:30:54.510+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:54.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:55.411+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:30:55.439+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:55.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:30:55.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:30:55.456+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:30:55.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.985 seconds
[2025-01-14T17:31:26.000+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:26.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:31:26.007+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:26.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:26.801+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:26.830+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:26.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:31:26.847+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:26.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:31:26.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.874 seconds
[2025-01-14T17:31:57.498+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:57.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:31:57.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:57.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:58.310+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:31:58.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:58.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:31:58.365+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:31:58.365+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:31:58.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.899 seconds
[2025-01-14T17:32:29.107+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:32:29.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:32:29.115+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:32:29.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:32:30.005+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:32:30.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:32:30.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:32:30.065+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:32:30.065+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:32:30.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.987 seconds
[2025-01-14T17:33:00.766+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:00.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:33:00.793+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:00.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:02.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:02.295+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:02.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:33:02.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:02.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:33:02.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.591 seconds
[2025-01-14T17:33:33.155+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:33.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:33:33.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:33.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:34.170+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:33:34.224+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:34.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:33:34.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:33:34.248+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:33:34.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.158 seconds
[2025-01-14T17:34:04.942+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:04.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:34:04.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:04.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:05.952+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:05.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:05.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:34:06.001+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:06.001+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:34:06.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.099 seconds
[2025-01-14T17:34:36.757+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:36.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:34:36.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:36.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:37.650+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:34:37.687+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:37.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:34:37.709+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:34:37.709+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:34:37.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.015 seconds
[2025-01-14T17:35:08.323+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:08.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:35:08.333+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:08.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:09.312+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:09.352+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:09.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:35:09.380+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:09.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:35:09.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.088 seconds
[2025-01-14T17:35:39.855+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:39.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:35:39.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:39.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:40.759+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:35:40.792+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:40.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:35:40.818+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:35:40.818+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:35:40.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.028 seconds
[2025-01-14T17:36:11.368+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:11.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:36:11.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:11.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:12.334+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:12.374+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:12.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:36:12.397+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:12.397+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:36:12.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.063 seconds
[2025-01-14T17:36:42.933+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:42.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:36:42.943+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:42.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:43.830+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:36:43.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:43.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:36:43.913+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:36:43.913+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:36:43.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.030 seconds
[2025-01-14T17:37:14.459+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:14.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:37:14.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:14.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:15.392+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:15.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:15.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:37:15.453+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:15.453+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:37:15.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.022 seconds
[2025-01-14T17:37:46.087+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:46.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:37:46.095+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:46.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:46.928+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:37:46.964+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:46.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:37:46.982+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:37:46.982+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:37:46.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.924 seconds
[2025-01-14T17:38:17.577+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:17.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:38:17.586+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:17.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:18.619+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:18.681+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:18.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:38:18.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:18.703+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:38:18.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.187 seconds
[2025-01-14T17:38:49.060+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:49.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:38:49.084+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:49.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:49.915+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:38:49.943+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:49.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:38:49.968+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:38:49.968+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:38:49.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.951 seconds
[2025-01-14T17:39:20.672+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:20.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:39:20.680+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:20.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:21.551+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:21.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:21.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:39:21.641+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:21.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:39:21.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.008 seconds
[2025-01-14T17:39:52.159+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:52.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:39:52.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:52.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:53.071+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:39:53.116+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:53.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:39:53.135+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:39:53.135+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:39:53.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.008 seconds
[2025-01-14T17:40:23.667+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:23.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:40:23.675+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:23.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:24.535+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:24.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:24.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:40:24.589+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:24.589+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:40:24.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.949 seconds
[2025-01-14T17:40:55.139+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:55.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:40:55.147+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:55.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:56.013+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:40:56.053+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:56.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:40:56.072+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:40:56.072+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:40:56.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.978 seconds
[2025-01-14T17:41:26.640+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:26.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:41:26.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:26.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:27.494+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:27.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:27.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:41:27.547+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:27.547+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:41:27.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.930 seconds
[2025-01-14T17:41:58.107+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:58.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:41:58.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:58.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:58.987+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:41:59.031+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:59.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:41:59.049+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:41:59.049+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:41:59.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.983 seconds
[2025-01-14T17:42:29.575+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:42:29.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:42:29.583+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:42:29.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:42:30.448+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:42:30.478+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:42:30.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:42:30.497+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:42:30.497+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:42:30.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.949 seconds
[2025-01-14T17:43:01.129+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:01.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:43:01.136+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:01.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:02.014+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:02.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:02.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:43:02.063+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:02.063+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:43:02.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.978 seconds
[2025-01-14T17:43:32.620+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:32.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:43:32.628+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:32.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:33.680+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:43:33.725+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:33.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:43:33.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:43:33.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:43:33.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.158 seconds
[2025-01-14T17:44:04.068+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:04.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:44:04.076+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:04.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:04.888+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:04.914+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:04.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:44:04.933+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:04.933+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:44:04.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.896 seconds
[2025-01-14T17:44:35.406+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:35.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:44:35.419+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:35.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:36.296+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:44:36.336+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:36.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:44:36.355+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:44:36.355+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:44:36.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.981 seconds
[2025-01-14T17:45:06.903+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:06.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:45:06.910+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:06.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:07.809+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:07.844+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:07.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:45:07.867+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:07.867+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:45:07.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.993 seconds
[2025-01-14T17:45:38.406+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:38.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:45:38.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:38.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:39.347+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:45:39.408+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:39.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:45:39.437+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:45:39.437+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:45:39.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.061 seconds
[2025-01-14T17:46:09.960+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:09.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:46:09.968+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:09.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:10.764+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:10.794+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:10.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:46:10.812+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:10.812+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:46:10.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.880 seconds
[2025-01-14T17:46:41.484+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:41.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:46:41.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:41.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:42.810+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:46:42.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:42.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:46:42.883+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:46:42.883+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:46:42.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.500 seconds
[2025-01-14T17:47:13.596+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:13.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:47:13.604+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:13.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:14.491+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:14.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:14.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:47:14.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:14.563+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:47:14.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.008 seconds
[2025-01-14T17:47:45.095+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:45.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:47:45.105+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:45.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:46.023+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:47:46.080+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:46.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:47:46.114+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:47:46.114+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:47:46.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.066 seconds
[2025-01-14T17:48:16.530+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:16.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:48:16.538+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:16.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:17.361+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:17.392+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:17.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:48:17.412+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:17.412+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:48:17.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.918 seconds
[2025-01-14T17:48:47.893+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:47.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:48:47.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:47.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:48.731+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:48:48.769+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:48.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:48:48.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:48:48.789+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:48:48.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.928 seconds
[2025-01-14T17:49:19.346+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:19.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:49:19.357+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:19.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:20.276+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:20.324+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:20.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:49:20.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:20.344+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:49:20.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.044 seconds
[2025-01-14T17:49:50.804+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:50.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:49:50.811+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:50.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:51.666+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:49:51.697+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:51.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:49:51.718+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:49:51.717+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:49:51.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.953 seconds
[2025-01-14T17:50:22.264+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:22.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:50:22.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:22.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:23.154+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:23.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:23.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:50:23.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:23.212+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:50:23.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.994 seconds
[2025-01-14T17:50:53.696+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:53.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:50:53.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:53.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:54.636+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:50:54.669+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:54.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:50:54.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:50:54.703+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:50:54.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.047 seconds
[2025-01-14T17:51:25.181+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:25.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:51:25.188+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:25.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:26.037+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:26.083+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:26.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:51:26.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:26.101+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:51:26.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.951 seconds
[2025-01-14T17:51:56.680+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:56.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:51:56.687+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:56.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:57.610+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:51:57.665+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:57.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:51:57.691+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:51:57.690+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:51:57.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.045 seconds
[2025-01-14T17:52:28.241+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:52:28.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:52:28.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:52:28.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:52:29.183+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:52:29.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:52:29.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:52:29.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:52:29.241+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:52:29.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.028 seconds
[2025-01-14T17:52:59.754+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:52:59.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:52:59.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:52:59.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:53:00.692+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:53:00.743+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:53:00.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:53:00.770+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:53:00.770+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:53:00.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.058 seconds
[2025-01-14T17:53:31.260+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:53:31.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:53:31.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:53:31.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:53:32.149+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:53:32.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:53:32.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:53:32.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:53:32.197+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:53:32.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.972 seconds
[2025-01-14T17:54:02.887+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:02.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:54:02.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:02.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:03.825+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:03.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:03.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:54:03.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:03.897+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:54:03.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.038 seconds
[2025-01-14T17:54:34.530+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:34.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:54:34.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:34.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:35.434+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:54:35.479+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:35.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:54:35.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:54:35.531+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:54:35.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.035 seconds
[2025-01-14T17:55:06.142+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:06.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:55:06.150+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:06.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:07.035+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:07.067+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:07.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:55:07.086+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:07.086+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:55:07.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.969 seconds
[2025-01-14T17:55:37.686+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:37.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:55:37.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:37.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:38.599+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:55:38.680+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:38.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:55:38.705+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:55:38.705+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:55:38.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.048 seconds
[2025-01-14T17:56:09.181+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:09.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:56:09.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:09.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:10.001+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:10.033+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:10.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:56:10.053+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:10.053+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:56:10.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.900 seconds
[2025-01-14T17:56:40.569+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:40.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:56:40.577+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:40.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:41.382+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:56:41.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:41.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:56:41.451+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:56:41.451+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:56:41.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.908 seconds
[2025-01-14T17:57:12.102+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:12.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:57:12.111+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:12.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:13.004+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:13.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:13.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:57:13.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:13.074+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:57:13.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.001 seconds
[2025-01-14T17:57:43.670+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:43.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:57:43.677+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:43.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:44.547+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:57:44.595+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:44.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:57:44.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:57:44.615+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:57:44.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.974 seconds
[2025-01-14T17:58:15.234+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:15.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:58:15.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:15.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:16.105+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:16.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:16.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:58:16.158+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:16.158+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:58:16.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.968 seconds
[2025-01-14T17:58:46.631+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:46.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:58:46.654+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:46.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:47.648+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:58:47.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:47.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:58:47.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:58:47.713+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:58:47.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.108 seconds
[2025-01-14T17:59:18.173+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:18.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:59:18.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:18.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:19.027+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:19.070+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:19.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:59:19.091+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:19.091+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:59:19.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.949 seconds
[2025-01-14T17:59:49.603+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:49.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T17:59:49.608+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:49.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:50.487+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T17:59:50.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:50.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T17:59:50.560+0000] {logging_mixin.py:190} INFO - [2025-01-14T17:59:50.560+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T17:59:50.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.983 seconds
[2025-01-14T18:00:21.132+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:21.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:00:21.144+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:21.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:22.003+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:22.030+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:22.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:00:22.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:22.047+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:00:22.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.959 seconds
[2025-01-14T18:00:52.547+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:52.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:00:52.553+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:52.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:53.416+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:00:53.442+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:53.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:00:53.459+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:00:53.459+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:00:53.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.936 seconds
[2025-01-14T18:01:23.984+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:23.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:01:23.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:23.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:24.906+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:24.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:24.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:01:24.967+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:24.966+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:01:24.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.030 seconds
[2025-01-14T18:01:55.445+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:55.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:01:55.451+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:55.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:56.466+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:01:56.497+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:56.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:01:56.518+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:01:56.518+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:01:56.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.100 seconds
[2025-01-14T18:02:26.985+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:26.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:02:26.994+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:26.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:27.825+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:27.854+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:27.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:02:27.874+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:27.874+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:02:27.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.942 seconds
[2025-01-14T18:02:58.481+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:58.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:02:58.490+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:58.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:59.396+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:02:59.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:59.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:02:59.448+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:02:59.448+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:02:59.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.009 seconds
[2025-01-14T18:03:22.081+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:03:22.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:03:22.089+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:03:22.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:03:23.068+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:03:23.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:03:23.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:03:23.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:03:23.164+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:03:23.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.132 seconds
[2025-01-14T18:04:11.913+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:11.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:04:11.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:11.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:14.622+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:14.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:14.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:04:14.768+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:14.768+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:04:14.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.937 seconds
[2025-01-14T18:04:45.499+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:45.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:04:45.519+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:45.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:47.420+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:04:47.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:47.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:04:47.520+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:04:47.520+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:04:47.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.070 seconds
[2025-01-14T18:05:18.020+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:18.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:05:18.029+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:18.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:19.050+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:19.085+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:19.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:05:19.112+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:19.112+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:05:19.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.128 seconds
[2025-01-14T18:05:49.502+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:49.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:05:49.519+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:49.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:50.291+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:05:50.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:50.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:05:50.371+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:05:50.371+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:05:50.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.897 seconds
[2025-01-14T18:06:20.924+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:20.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:06:20.932+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:20.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:21.781+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:21.820+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:21.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:06:21.836+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:21.836+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:06:21.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.938 seconds
[2025-01-14T18:06:52.353+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:52.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:06:52.360+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:52.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:53.081+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:06:53.121+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:53.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:06:53.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:06:53.137+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:06:53.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.815 seconds
[2025-01-14T18:07:23.621+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:23.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:07:23.629+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:23.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:24.423+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:24.477+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:24.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:07:24.556+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:24.555+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:07:24.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.008 seconds
[2025-01-14T18:07:55.118+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:55.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:07:55.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:55.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:55.968+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:07:56.006+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:56.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:07:56.030+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:07:56.030+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:07:56.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.937 seconds
[2025-01-14T18:08:26.595+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:26.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:08:26.603+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:26.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:27.404+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:27.433+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:27.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:08:27.450+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:27.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:08:27.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.883 seconds
[2025-01-14T18:08:58.105+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:58.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:08:58.114+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:58.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:59.041+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:08:59.094+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:59.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:08:59.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:08:59.117+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:08:59.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.048 seconds
[2025-01-14T18:09:30.258+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:09:30.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:09:30.270+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:09:30.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:09:31.328+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:09:31.359+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:09:31.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:09:31.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:09:31.387+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:09:31.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.174 seconds
[2025-01-14T18:10:01.742+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:01.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:10:01.752+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:01.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:02.561+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:02.588+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:02.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:10:02.605+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:02.605+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:10:02.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.894 seconds
[2025-01-14T18:10:33.143+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:33.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:10:33.150+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:33.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:33.940+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:10:33.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:33.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:10:33.999+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:10:33.999+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:10:34.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.885 seconds
[2025-01-14T18:11:04.567+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:04.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:11:04.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:04.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:05.409+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:05.433+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:05.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:11:05.461+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:05.461+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:11:05.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.958 seconds
[2025-01-14T18:11:36.092+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:36.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:11:36.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:36.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:36.880+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:11:36.912+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:36.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:11:36.931+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:11:36.931+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:11:36.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.875 seconds
[2025-01-14T18:12:07.611+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:07.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:12:07.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:07.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:08.505+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:08.542+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:08.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:12:08.565+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:08.565+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:12:08.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.005 seconds
[2025-01-14T18:12:39.144+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:39.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:12:39.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:39.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:39.962+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:12:40.000+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:40.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:12:40.018+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:12:40.018+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:12:40.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.925 seconds
[2025-01-14T18:13:10.559+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:10.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:13:10.573+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:10.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:11.371+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:11.399+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:11.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:13:11.423+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:11.423+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:13:11.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.892 seconds
[2025-01-14T18:13:41.976+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:41.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:13:41.985+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:41.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:42.715+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:13:42.740+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:42.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:13:42.757+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:13:42.757+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:13:42.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.808 seconds
[2025-01-14T18:14:13.306+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:13.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:14:13.315+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:13.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:14.082+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:14.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:14.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:14:14.130+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:14.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:14:14.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.853 seconds
[2025-01-14T18:14:44.697+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:44.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:14:44.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:44.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:45.527+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:14:45.551+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:45.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:14:45.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:14:45.567+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:14:45.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.900 seconds
[2025-01-14T18:15:16.046+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:16.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:15:16.053+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:16.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:16.859+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:16.884+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:16.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:15:16.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:16.900+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:15:16.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.896 seconds
[2025-01-14T18:15:47.433+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:47.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:15:47.443+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:47.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:48.374+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:15:48.434+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:48.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:15:48.454+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:15:48.454+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:15:48.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.050 seconds
[2025-01-14T18:16:18.882+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:18.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:16:18.900+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:18.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:19.687+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:19.716+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:19.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:16:19.732+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:19.732+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:16:19.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.887 seconds
[2025-01-14T18:16:50.238+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:50.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:16:50.246+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:50.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:51.033+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:16:51.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:51.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:16:51.073+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:16:51.073+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:16:51.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.869 seconds
[2025-01-14T18:17:21.573+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:21.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:17:21.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:21.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:22.471+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:22.500+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:22.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:17:22.518+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:22.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:17:22.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.001 seconds
[2025-01-14T18:17:53.061+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:53.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:17:53.068+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:53.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:53.864+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:17:53.890+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:53.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:17:53.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:17:53.908+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:17:53.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.890 seconds
[2025-01-14T18:18:24.566+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:18:24.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T18:18:24.601+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:18:24.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:18:26.027+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T18:18:26.085+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:18:26.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T18:18:26.129+0000] {logging_mixin.py:190} INFO - [2025-01-14T18:18:26.129+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T18:18:26.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.671 seconds
[2025-01-14T20:00:14.608+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:00:14.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:00:14.616+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:00:14.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:00:18.998+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:00:19.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:00:19.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:00:19.281+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:00:19.280+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:00:19.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 4.774 seconds
[2025-01-14T20:01:03.896+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:03.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:01:03.907+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:03.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:04.883+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:04.931+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:04.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:01:04.950+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:04.950+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:01:04.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.094 seconds
[2025-01-14T20:01:35.499+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:35.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:01:35.509+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:35.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:36.324+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:01:36.355+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:36.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:01:36.372+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:01:36.372+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:01:36.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.903 seconds
[2025-01-14T20:02:07.068+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:07.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:02:07.079+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:07.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:07.800+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:07.829+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:07.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:02:07.852+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:07.852+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:02:07.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.815 seconds
[2025-01-14T20:02:38.355+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:38.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:02:38.364+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:38.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:39.090+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:02:39.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:39.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:02:39.143+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:02:39.143+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:02:39.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.819 seconds
[2025-01-14T20:03:09.612+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:09.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:03:09.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:09.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:10.399+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:10.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:10.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:03:10.446+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:10.446+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:03:10.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.861 seconds
[2025-01-14T20:03:40.894+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:40.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:03:40.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:40.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:41.688+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:03:41.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:41.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:03:41.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:03:41.747+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:03:41.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.906 seconds
[2025-01-14T20:04:12.289+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:12.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:04:12.298+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:12.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:13.072+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:13.100+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:13.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:04:13.116+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:13.116+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:04:13.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.881 seconds
[2025-01-14T20:04:43.607+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:43.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:04:43.616+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:43.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:44.437+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:04:44.462+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:44.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:04:44.479+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:04:44.478+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:04:44.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.915 seconds
[2025-01-14T20:05:14.998+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:15.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:05:15.007+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:15.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:15.819+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:15.848+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:15.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:05:15.866+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:15.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:05:15.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.898 seconds
[2025-01-14T20:05:46.366+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:46.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:05:46.376+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:46.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:47.116+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:05:47.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:47.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:05:47.180+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:05:47.180+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:05:47.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.863 seconds
[2025-01-14T20:06:17.697+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:17.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:06:17.706+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:17.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:18.433+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:18.461+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:18.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:06:18.478+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:18.477+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:06:18.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.834 seconds
[2025-01-14T20:06:48.922+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:48.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:06:48.948+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:48.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:49.690+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:06:49.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:49.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:06:49.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:06:49.747+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:06:49.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.856 seconds
[2025-01-14T20:07:19.997+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:19.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:07:20.008+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:20.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:20.820+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:20.846+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:20.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:07:20.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:20.873+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:07:20.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.902 seconds
[2025-01-14T20:07:51.393+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:51.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:07:51.403+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:51.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:52.196+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:07:52.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:52.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:07:52.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:07:52.254+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:07:52.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.915 seconds
[2025-01-14T20:08:22.800+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:22.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:08:22.817+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:22.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:23.593+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:23.630+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:23.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:08:23.647+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:23.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:08:23.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.887 seconds
[2025-01-14T20:08:54.171+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:54.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:08:54.183+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:54.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:54.932+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:08:54.958+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:54.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:08:54.973+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:08:54.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:08:54.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T20:09:25.499+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:25.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:09:25.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:25.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:26.230+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:26.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:26.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:09:26.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:26.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:09:26.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.807 seconds
[2025-01-14T20:09:56.802+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:56.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:09:56.812+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:56.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:57.577+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:09:57.603+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:57.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:09:57.619+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:09:57.619+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:09:57.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.869 seconds
[2025-01-14T20:10:28.142+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:10:28.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:10:28.150+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:10:28.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:10:28.919+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:10:28.946+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:10:28.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:10:28.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:10:28.963+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:10:28.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.850 seconds
[2025-01-14T20:10:59.499+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:10:59.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:10:59.525+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:10:59.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:11:00.338+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:11:00.383+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:11:00.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:11:00.404+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:11:00.404+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:11:00.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.938 seconds
[2025-01-14T20:11:30.904+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:11:30.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:11:30.912+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:11:30.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:11:31.684+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:11:31.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:11:31.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:11:31.746+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:11:31.746+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:11:31.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-14T20:12:02.282+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:02.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:12:02.290+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:02.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:03.067+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:03.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:03.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:12:03.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:03.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:12:03.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.885 seconds
[2025-01-14T20:12:33.659+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:33.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:12:33.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:33.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:34.492+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:12:34.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:34.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:12:34.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:12:34.530+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:12:34.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.902 seconds
[2025-01-14T20:13:05.086+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:05.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:13:05.096+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:05.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:05.910+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:05.949+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:05.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:13:05.968+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:05.968+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:13:05.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.912 seconds
[2025-01-14T20:13:36.509+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:36.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:13:36.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:36.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:37.242+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:13:37.277+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:37.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:13:37.295+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:13:37.295+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:13:37.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-14T20:14:07.813+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:07.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:14:07.822+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:07.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:08.539+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:08.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:08.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:14:08.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:08.584+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:14:08.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.800 seconds
[2025-01-14T20:14:39.087+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:39.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:14:39.111+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:39.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:39.892+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:14:39.917+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:39.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:14:39.933+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:14:39.932+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:14:39.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.876 seconds
[2025-01-14T20:15:10.448+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:10.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:15:10.457+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:10.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:11.213+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:11.239+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:11.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:15:11.254+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:11.254+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:15:11.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-14T20:15:41.749+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:41.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:15:41.759+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:41.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:42.556+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:15:42.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:42.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:15:42.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:15:42.600+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:15:42.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.880 seconds
[2025-01-14T20:16:13.117+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:13.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:16:13.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:13.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:13.893+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:13.918+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:13.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:16:13.935+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:13.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:16:13.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.867 seconds
[2025-01-14T20:16:44.480+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:44.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:16:44.489+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:44.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:45.212+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:16:45.246+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:45.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:16:45.262+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:16:45.262+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:16:45.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.814 seconds
[2025-01-14T20:17:15.761+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:15.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:17:15.771+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:15.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:16.566+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:16.594+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:16.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:17:16.612+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:16.612+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:17:16.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.880 seconds
[2025-01-14T20:17:47.129+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:47.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:17:47.140+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:47.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:47.919+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:17:47.942+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:47.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:17:47.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:17:47.961+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:17:47.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-14T20:18:18.507+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:18.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:18:18.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:18.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:19.329+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:19.357+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:19.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:18:19.376+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:19.376+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:18:19.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.922 seconds
[2025-01-14T20:18:49.839+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:49.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:18:49.848+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:49.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:50.631+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:18:50.656+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:50.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:18:50.674+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:18:50.673+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:18:50.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.864 seconds
[2025-01-14T20:19:21.167+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:21.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:19:21.177+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:21.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:21.947+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:21.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:21.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:19:22.004+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:22.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:19:22.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.883 seconds
[2025-01-14T20:19:52.461+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:52.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:19:52.482+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:52.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:53.384+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:19:53.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:53.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:19:53.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:19:53.511+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:19:53.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.088 seconds
[2025-01-14T20:20:23.999+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:24.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:20:24.009+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:24.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:24.777+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:24.819+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:24.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:20:24.839+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:24.839+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:20:24.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.878 seconds
[2025-01-14T20:20:55.327+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:55.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:20:55.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:55.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:56.019+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:20:56.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:56.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:20:56.073+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:20:56.072+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:20:56.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.778 seconds
[2025-01-14T20:21:26.616+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:26.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:21:26.639+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:26.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:27.361+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:27.392+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:27.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:21:27.409+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:27.409+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:21:27.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.821 seconds
[2025-01-14T20:21:58.044+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:58.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:21:58.054+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:58.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:58.741+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:21:58.767+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:58.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:21:58.791+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:21:58.791+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:21:58.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-14T20:22:29.421+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:22:29.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:22:29.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:22:29.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:22:30.429+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:22:30.476+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:22:30.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:22:30.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:22:30.494+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:22:30.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.119 seconds
[2025-01-14T20:23:00.933+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:00.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:23:00.942+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:00.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:01.703+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:01.727+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:01.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:23:01.743+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:01.743+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:23:01.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.838 seconds
[2025-01-14T20:23:32.222+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:32.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:23:32.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:32.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:33.025+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:23:33.090+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:33.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:23:33.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:23:33.138+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:23:33.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.968 seconds
[2025-01-14T20:24:03.713+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:03.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:24:03.722+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:03.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:04.496+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:04.545+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:04.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:24:04.565+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:04.565+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:24:04.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.906 seconds
[2025-01-14T20:24:35.147+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:35.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:24:35.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:35.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:35.894+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:24:35.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:35.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:24:35.950+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:24:35.950+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:24:35.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.849 seconds
[2025-01-14T20:25:06.474+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:06.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:25:06.482+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:06.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:07.220+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:07.256+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:07.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:25:07.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:07.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:25:07.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.847 seconds
[2025-01-14T20:25:37.828+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:37.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:25:37.837+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:37.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:38.597+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:25:38.624+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:38.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:25:38.653+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:25:38.653+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:25:38.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.859 seconds
[2025-01-14T20:26:09.159+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:09.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:26:09.188+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:09.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:09.937+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:09.967+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:09.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:26:09.985+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:09.985+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:26:09.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.857 seconds
[2025-01-14T20:26:40.545+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:40.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:26:40.556+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:40.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:41.328+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:26:41.363+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:41.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:26:41.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:26:41.385+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:26:41.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.883 seconds
[2025-01-14T20:27:11.967+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:11.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:27:11.976+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:11.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:12.713+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:12.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:12.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:27:12.782+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:12.782+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:27:12.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.880 seconds
[2025-01-14T20:27:43.352+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:43.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:27:43.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:43.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:44.060+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:27:44.089+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:44.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:27:44.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:27:44.113+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:27:44.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.790 seconds
[2025-01-14T20:28:14.648+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:14.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:28:14.658+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:14.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:15.370+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:15.394+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:15.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:28:15.410+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:15.410+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:28:15.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.815 seconds
[2025-01-14T20:28:45.899+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:45.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:28:45.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:45.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:46.674+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:28:46.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:46.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:28:46.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:28:46.720+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:28:46.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.852 seconds
[2025-01-14T20:29:17.245+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:17.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:29:17.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:17.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:17.989+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:18.027+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:18.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:29:18.044+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:18.044+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:29:18.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.837 seconds
[2025-01-14T20:29:48.515+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:48.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:29:48.525+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:48.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:49.236+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:29:49.271+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:49.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:29:49.288+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:29:49.287+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:29:49.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.801 seconds
[2025-01-14T20:30:19.809+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:19.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:30:19.818+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:19.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:20.546+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:20.579+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:20.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:30:20.597+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:20.597+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:30:20.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.837 seconds
[2025-01-14T20:30:51.097+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:51.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:30:51.105+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:51.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:51.829+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:30:51.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:51.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:30:51.886+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:30:51.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:30:51.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.817 seconds
[2025-01-14T20:31:22.411+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:22.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:31:22.421+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:22.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:23.186+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:23.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:23.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:31:23.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:23.228+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:31:23.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.875 seconds
[2025-01-14T20:31:53.719+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:53.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:31:53.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:53.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:54.471+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:31:54.497+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:54.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:31:54.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:31:54.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:31:54.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.844 seconds
[2025-01-14T20:32:25.086+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:25.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:32:25.095+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:25.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:25.996+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:26.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:26.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:32:26.077+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:26.077+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:32:26.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.036 seconds
[2025-01-14T20:32:56.640+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:56.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:32:56.649+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:56.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:57.420+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:32:57.464+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:57.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:32:57.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:32:57.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:32:57.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.878 seconds
[2025-01-14T20:33:27.973+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:33:27.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:33:27.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:33:27.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:33:28.713+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:33:28.744+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:33:28.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:33:28.769+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:33:28.769+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:33:28.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-14T20:33:59.275+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:33:59.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:33:59.286+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:33:59.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:34:00.091+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:34:00.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:34:00.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:34:00.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:34:00.155+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:34:00.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.931 seconds
[2025-01-14T20:34:30.650+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:34:30.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:34:30.660+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:34:30.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:34:31.413+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:34:31.443+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:34:31.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:34:31.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:34:31.462+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:34:31.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.850 seconds
[2025-01-14T20:35:01.975+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:01.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:35:01.998+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:01.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:02.983+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:03.053+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:03.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:35:03.090+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:03.090+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:35:03.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.179 seconds
[2025-01-14T20:35:33.570+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:33.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:35:33.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:33.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:34.431+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:35:34.473+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:34.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:35:34.490+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:35:34.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:35:34.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.949 seconds
[2025-01-14T20:36:05.048+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:05.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:36:05.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:05.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:05.801+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:05.832+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:05.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:36:05.862+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:05.862+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:36:05.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.860 seconds
[2025-01-14T20:36:36.360+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:36.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:36:36.373+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:36.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:37.113+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:36:37.159+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:37.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:36:37.176+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:36:37.176+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:36:37.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-14T20:37:07.673+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:07.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:37:07.685+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:07.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:08.487+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:08.516+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:08.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:37:08.535+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:08.535+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:37:08.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.922 seconds
[2025-01-14T20:37:39.056+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:39.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:37:39.066+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:39.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:39.813+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:37:39.852+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:39.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:37:39.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:37:39.868+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:37:39.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.863 seconds
[2025-01-14T20:38:10.444+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:10.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:38:10.455+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:10.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:11.187+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:11.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:11.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:38:11.240+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:11.240+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:38:11.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.829 seconds
[2025-01-14T20:38:41.752+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:41.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:38:41.761+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:41.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:42.512+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:38:42.540+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:42.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:38:42.558+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:38:42.558+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:38:42.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.836 seconds
[2025-01-14T20:39:13.097+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:13.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:39:13.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:13.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:13.868+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:13.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:13.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:39:13.919+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:13.919+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:39:13.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.863 seconds
[2025-01-14T20:39:44.423+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:44.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:39:44.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:44.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:45.142+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:39:45.185+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:45.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:39:45.213+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:39:45.213+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:39:45.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.829 seconds
[2025-01-14T20:40:15.683+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:15.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:40:15.694+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:15.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:16.451+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:16.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:16.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:40:16.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:16.526+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:40:16.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.905 seconds
[2025-01-14T20:40:47.098+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:47.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:40:47.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:47.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:47.876+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:40:47.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:47.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:40:47.994+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:40:47.994+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:40:48.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.954 seconds
[2025-01-14T20:41:18.524+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:18.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:41:18.538+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:18.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:19.385+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:19.414+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:19.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:41:19.431+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:19.431+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:41:19.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.950 seconds
[2025-01-14T20:41:49.856+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:49.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:41:49.862+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:49.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:50.626+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:41:50.652+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:50.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:41:50.669+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:41:50.669+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:41:50.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.845 seconds
[2025-01-14T20:42:21.196+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:21.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:42:21.205+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:21.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:21.942+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:21.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:21.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:42:21.998+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:21.998+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:42:22.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.848 seconds
[2025-01-14T20:42:52.470+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:52.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:42:52.478+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:52.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:53.224+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:42:53.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:53.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:42:53.285+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:42:53.285+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:42:53.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.845 seconds
[2025-01-14T20:43:23.742+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:23.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:43:23.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:23.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:24.484+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:24.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:24.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:43:24.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:24.543+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:43:24.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.827 seconds
[2025-01-14T20:43:54.990+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:54.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:43:54.997+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:54.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:55.688+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:43:55.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:55.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:43:55.726+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:43:55.726+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:43:55.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-14T20:44:26.176+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:26.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:44:26.185+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:26.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:26.913+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:26.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:26.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:44:26.956+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:26.955+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:44:26.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.809 seconds
[2025-01-14T20:44:57.091+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:57.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:44:57.098+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:57.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:57.851+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:44:57.903+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:57.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:44:57.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:44:57.922+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:44:57.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.857 seconds
[2025-01-14T20:45:28.390+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:45:28.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:45:28.398+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:45:28.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:45:29.159+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:45:29.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:45:29.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:45:29.198+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:45:29.198+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:45:29.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.874 seconds
[2025-01-14T20:45:59.711+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:45:59.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:45:59.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:45:59.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:46:00.528+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:46:00.553+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:46:00.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:46:00.573+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:46:00.573+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:46:00.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.895 seconds
[2025-01-14T20:46:31.092+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:46:31.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:46:31.100+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:46:31.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:46:31.849+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:46:31.876+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:46:31.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:46:31.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:46:31.897+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:46:31.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.858 seconds
[2025-01-14T20:47:02.451+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:02.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:47:02.471+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:02.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:03.383+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:03.416+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:03.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:47:03.437+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:03.437+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:47:03.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.025 seconds
[2025-01-14T20:47:34.034+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:34.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:47:34.044+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:34.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:34.841+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:47:34.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:34.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:47:34.888+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:47:34.888+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:47:34.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.899 seconds
[2025-01-14T20:48:05.408+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:05.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:48:05.417+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:05.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:06.163+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:06.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:06.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:48:06.215+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:06.215+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:48:06.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.837 seconds
[2025-01-14T20:48:36.695+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:36.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:48:36.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:36.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:37.435+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:48:37.471+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:37.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:48:37.492+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:48:37.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:48:37.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.836 seconds
[2025-01-14T20:49:07.917+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:07.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:49:07.946+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:07.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:08.685+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:08.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:08.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:49:08.736+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:08.736+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:49:08.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.850 seconds
[2025-01-14T20:49:39.475+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:39.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:49:39.486+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:39.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:40.208+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:49:40.238+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:40.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:49:40.261+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:49:40.260+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:49:40.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.823 seconds
[2025-01-14T20:50:10.775+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:10.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:50:10.784+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:10.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:11.500+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:11.533+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:11.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:50:11.560+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:11.560+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:50:11.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.819 seconds
[2025-01-14T20:50:42.059+0000] {processor.py:186} INFO - Started process (PID=281) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:42.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:50:42.069+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:42.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:43.082+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:50:43.108+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:43.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:50:43.123+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:50:43.123+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:50:43.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.095 seconds
[2025-01-14T20:51:13.740+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:13.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:51:13.752+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:13.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:14.504+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:14.529+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:14.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:51:14.546+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:14.545+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:51:14.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.837 seconds
[2025-01-14T20:51:45.213+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:45.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:51:45.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:45.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:45.951+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:51:45.986+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:45.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:51:46.004+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:51:46.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:51:46.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.818 seconds
[2025-01-14T20:52:16.545+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:16.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:52:16.553+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:16.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:17.338+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:17.360+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:17.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:52:17.386+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:17.386+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:52:17.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.870 seconds
[2025-01-14T20:52:47.916+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:47.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:52:47.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:47.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:48.710+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:52:48.733+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:48.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:52:48.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:52:48.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:52:48.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-14T20:53:19.290+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:19.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:53:19.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:19.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:20.077+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:20.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:20.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:53:20.126+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:20.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:53:20.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.866 seconds
[2025-01-14T20:53:50.659+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:50.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:53:50.666+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:50.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:51.356+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:53:51.380+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:51.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:53:51.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:53:51.395+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:53:51.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-14T20:54:22.092+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:22.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:54:22.109+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:22.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:23.210+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:23.250+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:23.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:54:23.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:23.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:54:23.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.359 seconds
[2025-01-14T20:54:53.580+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:53.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:54:53.595+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:53.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:54.404+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:54:54.446+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:54.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:54:54.465+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:54:54.464+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:54:54.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.941 seconds
[2025-01-14T20:55:25.044+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:25.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:55:25.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:25.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:25.790+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:25.825+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:25.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:55:25.847+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:25.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:55:25.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.835 seconds
[2025-01-14T20:55:56.600+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:56.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:55:56.614+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:56.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:57.529+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:55:57.592+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:57.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:55:57.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:55:57.620+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:55:57.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.085 seconds
[2025-01-14T20:56:28.258+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:56:28.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:56:28.267+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:56:28.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:56:29.076+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:56:29.115+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:56:29.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:56:29.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:56:29.132+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:56:29.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.908 seconds
[2025-01-14T20:56:59.677+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:56:59.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:56:59.700+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:56:59.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:57:00.578+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:57:00.616+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:57:00.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:57:00.641+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:57:00.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:57:00.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.013 seconds
[2025-01-14T20:57:31.187+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:57:31.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:57:31.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:57:31.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:57:31.949+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:57:31.987+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:57:31.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:57:32.004+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:57:32.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:57:32.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.870 seconds
[2025-01-14T20:58:02.551+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:02.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:58:02.572+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:02.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:03.530+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:03.585+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:03.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:58:03.609+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:03.608+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:58:03.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.087 seconds
[2025-01-14T20:58:34.272+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:34.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:58:34.281+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:34.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:35.457+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:58:35.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:35.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:58:35.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:58:35.523+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:58:35.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.278 seconds
[2025-01-14T20:59:05.917+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:05.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:59:05.933+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:05.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:06.743+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:06.785+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:06.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:59:06.881+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:06.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:59:06.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.033 seconds
[2025-01-14T20:59:37.383+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:37.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T20:59:37.403+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:37.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:38.216+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T20:59:38.243+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:38.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T20:59:38.261+0000] {logging_mixin.py:190} INFO - [2025-01-14T20:59:38.261+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T20:59:38.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.916 seconds
[2025-01-14T21:00:08.922+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:08.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:00:08.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:08.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:09.652+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:09.695+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:09.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:00:09.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:09.713+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:00:09.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.825 seconds
[2025-01-14T21:00:40.347+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:40.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:00:40.356+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:40.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:41.086+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:00:41.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:41.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:00:41.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:00:41.155+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:00:41.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.858 seconds
[2025-01-14T21:01:11.809+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:11.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:01:11.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:11.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:12.514+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:12.565+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:12.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:01:12.603+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:12.603+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:01:12.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-14T21:01:43.157+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:43.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:01:43.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:43.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:43.906+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:01:43.936+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:43.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:01:43.977+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:01:43.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:01:43.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.865 seconds
[2025-01-14T21:02:14.543+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:14.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:02:14.558+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:14.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:15.322+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:15.354+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:15.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:02:15.372+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:15.372+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:02:15.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.895 seconds
[2025-01-14T21:02:45.882+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:45.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:02:45.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:45.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:46.618+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:02:46.643+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:46.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:02:46.660+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:02:46.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:02:46.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.836 seconds
[2025-01-14T21:03:17.176+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:17.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:03:17.202+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:17.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:17.937+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:17.969+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:17.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:03:17.993+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:17.993+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:03:18.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T21:03:48.473+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:48.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:03:48.482+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:48.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:49.266+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:03:49.307+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:49.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:03:49.324+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:03:49.324+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:03:49.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.892 seconds
[2025-01-14T21:04:19.840+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:19.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:04:19.855+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:19.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:20.601+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:20.629+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:20.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:04:20.645+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:20.645+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:04:20.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.856 seconds
[2025-01-14T21:04:51.186+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:51.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:04:51.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:51.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:52.379+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:04:52.415+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:52.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:04:52.452+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:04:52.451+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:04:52.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.298 seconds
[2025-01-14T21:05:22.840+0000] {processor.py:186} INFO - Started process (PID=337) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:22.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:05:22.847+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:22.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:23.555+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:23.581+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:23.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:05:23.598+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:23.598+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:05:23.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.788 seconds
[2025-01-14T21:05:54.148+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:54.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:05:54.158+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:54.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:54.865+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:05:54.892+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:54.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:05:54.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:05:54.908+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:05:54.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-14T21:06:25.430+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:25.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:06:25.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:25.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:26.160+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:26.185+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:26.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:06:26.202+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:26.201+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:06:26.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.801 seconds
[2025-01-14T21:06:56.701+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:56.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:06:56.712+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:56.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:57.451+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:06:57.480+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:57.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:06:57.498+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:06:57.497+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:06:57.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T21:07:28.055+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:07:28.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:07:28.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:07:28.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:07:28.813+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:07:28.840+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:07:28.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:07:28.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:07:28.865+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:07:28.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-14T21:07:59.395+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:07:59.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:07:59.406+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:07:59.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:08:00.280+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:08:00.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:08:00.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:08:00.336+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:08:00.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:08:00.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.974 seconds
[2025-01-14T21:08:30.844+0000] {processor.py:186} INFO - Started process (PID=349) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:08:30.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:08:30.855+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:08:30.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:08:31.545+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:08:31.601+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:08:31.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:08:31.631+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:08:31.630+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:08:31.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.819 seconds
[2025-01-14T21:09:02.169+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:02.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:09:02.175+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:02.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:02.887+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:02.919+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:02.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:09:02.935+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:02.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:09:02.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.793 seconds
[2025-01-14T21:09:33.432+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:33.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:09:33.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:33.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:34.257+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:09:34.292+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:34.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:09:34.312+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:09:34.312+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:09:34.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.929 seconds
[2025-01-14T21:10:04.821+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:04.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:10:04.841+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:04.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:05.581+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:05.613+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:05.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:10:05.630+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:05.630+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:10:05.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.851 seconds
[2025-01-14T21:10:36.129+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:36.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:10:36.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:36.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:36.876+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:10:36.919+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:36.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:10:36.937+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:10:36.937+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:10:36.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.851 seconds
[2025-01-14T21:11:07.469+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:07.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:11:07.475+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:07.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:08.204+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:08.234+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:08.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:11:08.251+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:08.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:11:08.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.816 seconds
[2025-01-14T21:11:38.685+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:38.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:11:38.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:38.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:39.422+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:11:39.447+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:39.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:11:39.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:11:39.463+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:11:39.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.802 seconds
[2025-01-14T21:12:10.186+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:10.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:12:10.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:10.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:10.971+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:11.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:11.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:12:11.090+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:11.090+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:12:11.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.038 seconds
[2025-01-14T21:12:41.719+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:41.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:12:41.733+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:41.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:42.584+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:12:42.630+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:42.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:12:42.650+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:12:42.650+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:12:42.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.991 seconds
[2025-01-14T21:13:13.162+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:13.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:13:13.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:13.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:13.599+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:13.634+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:13.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:13:13.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:13.646+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:13:13.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.517 seconds
[2025-01-14T21:13:44.135+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:44.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:13:44.140+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:44.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:44.749+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:13:44.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:44.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:13:44.775+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:13:44.775+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:13:44.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.659 seconds
[2025-01-14T21:14:15.078+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:15.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:14:15.085+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:15.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:15.601+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:15.619+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:15.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:14:15.641+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:15.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:14:15.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.587 seconds
[2025-01-14T21:14:46.156+0000] {processor.py:186} INFO - Started process (PID=373) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:46.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:14:46.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:46.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:46.634+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:14:46.652+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:46.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:14:46.662+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:14:46.662+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:14:46.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.531 seconds
[2025-01-14T21:15:16.968+0000] {processor.py:186} INFO - Started process (PID=375) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:16.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:15:16.974+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:16.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:17.464+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:17.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:17.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:15:17.495+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:17.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:15:17.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.575 seconds
[2025-01-14T21:15:47.979+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:47.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:15:47.993+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:47.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:48.453+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:15:48.500+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:48.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:15:48.556+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:15:48.555+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:15:48.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.631 seconds
[2025-01-14T21:16:19.136+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:19.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:16:19.148+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:19.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:19.670+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:19.715+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:19.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:16:19.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:19.730+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:16:19.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.626 seconds
[2025-01-14T21:16:50.523+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:50.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:16:50.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:50.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:51.166+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:16:51.199+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:51.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:16:51.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:16:51.211+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:16:51.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.710 seconds
[2025-01-14T21:17:21.793+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:21.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:17:21.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:21.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:22.330+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:22.367+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:22.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:17:22.390+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:22.389+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:17:22.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.633 seconds
[2025-01-14T21:17:52.884+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:52.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:17:52.890+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:52.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:53.351+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:17:53.373+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:53.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:17:53.384+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:17:53.384+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:17:53.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.541 seconds
[2025-01-14T21:18:23.794+0000] {processor.py:186} INFO - Started process (PID=387) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:23.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:18:23.799+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:23.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:24.266+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:24.289+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:24.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:18:24.304+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:24.304+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:18:24.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.527 seconds
[2025-01-14T21:18:54.397+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:54.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:18:54.406+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:54.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:55.038+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:18:55.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:55.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:18:55.067+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:18:55.067+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:18:55.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.688 seconds
[2025-01-14T21:19:25.200+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:25.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:19:25.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:25.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:25.669+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:25.691+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:25.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:19:25.707+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:25.707+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:19:25.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.534 seconds
[2025-01-14T21:19:55.907+0000] {processor.py:186} INFO - Started process (PID=393) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:55.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:19:55.913+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:55.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:56.377+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:19:56.419+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:56.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:19:56.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:19:56.432+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:19:56.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.544 seconds
[2025-01-14T21:20:26.593+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:26.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:20:26.613+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:26.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:27.066+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:27.104+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:27.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:20:27.115+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:27.114+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:20:27.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.542 seconds
[2025-01-14T21:20:57.384+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:57.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:20:57.393+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:57.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:57.916+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:20:57.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:57.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:20:57.953+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:20:57.953+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:20:57.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.589 seconds
[2025-01-14T21:21:28.443+0000] {processor.py:186} INFO - Started process (PID=399) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:28.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:21:28.452+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:28.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:28.903+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:28.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:28.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:21:28.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:28.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:21:28.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-14T21:21:59.317+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:59.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:21:59.322+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:59.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:59.830+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:21:59.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:59.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:21:59.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:21:59.870+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:21:59.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.574 seconds
[2025-01-14T21:22:30.335+0000] {processor.py:186} INFO - Started process (PID=403) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:22:30.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:22:30.341+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:22:30.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:22:30.782+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:22:30.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:22:30.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:22:30.822+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:22:30.821+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:22:30.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-14T21:23:01.291+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:01.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:23:01.297+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:01.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:01.750+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:01.767+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:01.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:23:01.777+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:01.777+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:23:01.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-14T21:23:32.099+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:32.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:23:32.104+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:32.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:32.563+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:23:32.580+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:32.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:23:32.590+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:23:32.590+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:23:32.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-14T21:24:03.062+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:03.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:24:03.069+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:03.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:03.520+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:03.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:03.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:24:03.547+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:03.547+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:24:03.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-14T21:24:34.034+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:34.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:24:34.039+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:34.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:34.488+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:24:34.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:34.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:24:34.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:24:34.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:24:34.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-14T21:25:04.925+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:04.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:25:04.932+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:04.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:05.412+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:05.452+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:05.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:25:05.462+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:05.462+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:25:05.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.556 seconds
[2025-01-14T21:25:35.973+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:35.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:25:35.978+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:35.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:36.539+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:25:36.570+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:36.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:25:36.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:25:36.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:25:36.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.640 seconds
[2025-01-14T21:26:07.103+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:07.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:26:07.108+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:07.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:07.879+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:07.898+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:07.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:26:07.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:07.921+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:26:07.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.891 seconds
[2025-01-14T21:26:38.381+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:38.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:26:38.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:38.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:38.887+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:26:38.906+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:38.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:26:38.916+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:26:38.916+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:26:38.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.554 seconds
[2025-01-14T21:27:09.120+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:09.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:27:09.126+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:09.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:09.597+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:09.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:09.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:27:09.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:09.625+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:27:09.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.523 seconds
[2025-01-14T21:27:40.071+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:40.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:27:40.076+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:40.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:40.532+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:27:40.554+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:40.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:27:40.564+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:27:40.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:27:40.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-14T21:28:11.065+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:11.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:28:11.069+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:11.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:11.566+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:11.591+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:11.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:28:11.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:11.609+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:28:11.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.564 seconds
[2025-01-14T21:28:42.004+0000] {processor.py:186} INFO - Started process (PID=427) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:42.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:28:42.009+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:42.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:42.484+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:28:42.510+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:42.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:28:42.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:28:42.521+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:28:42.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.533 seconds
[2025-01-14T21:29:13.027+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:13.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:29:13.033+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:13.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:13.493+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:13.510+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:13.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:29:13.520+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:13.520+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:29:13.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.512 seconds
[2025-01-14T21:29:43.667+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:43.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:29:43.672+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:43.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:44.138+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:29:44.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:44.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:29:44.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:29:44.164+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:29:44.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-14T21:30:14.397+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:30:14.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:30:14.409+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:30:14.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:30:14.943+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:30:14.974+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:30:14.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:30:14.991+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:30:14.990+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:30:15.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.658 seconds
[2025-01-14T21:32:50.554+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:32:50.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:32:50.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:32:50.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:32:51.162+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:32:51.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:32:51.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:32:51.204+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:32:51.204+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:32:51.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.681 seconds
[2025-01-14T21:33:22.229+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:22.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:33:22.234+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:22.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:22.756+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:22.792+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:22.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:33:22.812+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:22.812+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:33:22.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.611 seconds
[2025-01-14T21:33:53.549+0000] {processor.py:186} INFO - Started process (PID=439) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:53.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:33:53.554+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:53.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:54.062+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:33:54.094+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:54.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:33:54.105+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:33:54.105+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:33:54.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.574 seconds
[2025-01-14T21:34:24.275+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:24.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:34:24.280+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:24.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:24.732+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:24.751+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:24.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:34:24.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:24.762+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:34:24.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.514 seconds
[2025-01-14T21:34:55.087+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:55.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:34:55.096+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:55.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:55.597+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:34:55.626+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:55.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:34:55.638+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:34:55.638+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:34:55.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.579 seconds
[2025-01-14T21:35:26.148+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:26.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:35:26.152+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:26.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:26.632+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:26.669+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:26.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:35:26.681+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:26.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:35:26.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.551 seconds
[2025-01-14T21:35:57.106+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:57.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:35:57.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:57.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:57.567+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:35:57.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:57.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:35:57.595+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:35:57.594+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:35:57.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-14T21:36:28.050+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:28.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:36:28.054+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:28.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:28.503+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:28.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:28.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:36:28.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:28.532+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:36:28.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-14T21:36:58.985+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:58.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:36:58.988+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:58.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:59.430+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:36:59.462+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:59.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:36:59.472+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:36:59.472+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:36:59.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-14T21:37:29.908+0000] {processor.py:186} INFO - Started process (PID=453) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:37:29.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:37:29.914+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:37:29.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:37:30.377+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:37:30.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:37:30.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:37:30.406+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:37:30.406+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:37:30.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.545 seconds
[2025-01-14T21:38:00.814+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:00.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:38:00.818+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:00.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:01.270+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:01.304+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:01.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:38:01.314+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:01.314+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:38:01.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.530 seconds
[2025-01-14T21:38:31.771+0000] {processor.py:186} INFO - Started process (PID=457) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:31.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:38:31.777+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:31.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:32.233+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:38:32.253+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:32.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:38:32.266+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:38:32.266+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:38:32.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.514 seconds
[2025-01-14T21:39:02.599+0000] {processor.py:186} INFO - Started process (PID=459) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:39:02.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:39:02.605+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:39:02.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:39:04.009+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:39:04.056+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:39:04.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:39:04.072+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:39:04.072+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:39:04.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.495 seconds
[2025-01-14T21:41:54.837+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:41:54.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:41:54.842+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:41:54.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:41:55.267+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:41:55.292+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:41:55.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:41:55.302+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:41:55.302+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:41:55.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.484 seconds
[2025-01-14T21:46:03.601+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:03.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:46:03.609+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:03.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:05.628+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:05.669+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:05.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:46:05.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:05.688+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:46:05.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.125 seconds
[2025-01-14T21:46:36.262+0000] {processor.py:186} INFO - Started process (PID=465) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:36.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:46:36.269+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:36.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:37.045+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:46:37.136+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:37.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:46:37.216+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:46:37.216+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:46:37.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.004 seconds
[2025-01-14T21:47:07.829+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:07.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:47:07.834+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:07.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:08.601+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:08.637+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:08.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:47:08.657+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:08.657+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:47:08.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.851 seconds
[2025-01-14T21:47:39.202+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:39.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:47:39.209+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:39.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:39.936+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:47:39.978+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:39.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:47:39.995+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:47:39.995+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:47:40.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.818 seconds
[2025-01-14T21:48:10.266+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:48:10.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:48:10.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:48:10.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:48:11.071+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:48:11.119+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:48:11.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:48:11.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:48:11.138+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:48:11.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.899 seconds
[2025-01-14T21:52:35.560+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:52:35.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:52:35.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:52:35.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:52:36.305+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:52:36.332+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:52:36.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:52:36.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:52:36.348+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:52:36.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.816 seconds
[2025-01-14T21:53:06.890+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:06.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:53:06.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:06.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:07.595+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:07.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:07.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:53:07.637+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:07.637+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:53:07.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.776 seconds
[2025-01-14T21:53:38.158+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:38.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:53:38.167+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:38.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:39.181+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:53:39.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:39.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:53:39.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:53:39.242+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:53:39.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.112 seconds
[2025-01-14T21:54:09.713+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:09.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:54:09.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:09.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:10.425+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:10.450+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:10.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:54:10.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:10.467+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:54:10.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.777 seconds
[2025-01-14T21:54:40.936+0000] {processor.py:186} INFO - Started process (PID=481) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:40.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:54:40.942+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:40.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:41.720+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:54:41.763+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:41.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:54:41.780+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:54:41.780+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:54:41.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.866 seconds
[2025-01-14T21:55:12.249+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:12.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:55:12.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:12.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:12.690+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:12.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:12.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:55:12.721+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:12.721+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:55:12.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-14T21:55:42.889+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:42.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:55:42.904+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:42.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:43.350+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:55:43.369+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:43.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:55:43.379+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:55:43.379+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:55:43.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-14T21:56:13.607+0000] {processor.py:186} INFO - Started process (PID=487) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:13.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:56:13.614+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:13.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:14.072+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:14.096+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:14.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:56:14.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:14.107+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:56:14.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.547 seconds
[2025-01-14T21:56:44.557+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:44.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:56:44.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:44.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:45.018+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:56:45.048+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:45.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:56:45.060+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:56:45.060+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:56:45.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-14T21:57:15.464+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:15.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:57:15.469+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:15.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:15.903+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:15.920+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:15.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:57:15.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:15.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:57:15.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-14T21:57:46.446+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:46.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:57:46.450+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:46.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:46.912+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:57:46.929+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:46.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:57:46.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:57:46.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:57:46.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-14T21:58:17.362+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:17.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:58:17.370+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:17.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:17.849+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:17.864+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:17.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:58:17.874+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:17.874+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:58:17.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.531 seconds
[2025-01-14T21:58:48.384+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:48.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:58:48.389+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:48.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:48.850+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:58:48.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:48.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:58:48.881+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:58:48.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:58:48.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-14T21:59:19.345+0000] {processor.py:186} INFO - Started process (PID=499) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:19.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:59:19.351+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:19.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:19.774+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:19.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:19.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:59:19.797+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:19.796+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:59:19.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.496 seconds
[2025-01-14T21:59:50.259+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:50.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T21:59:50.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:50.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:50.776+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T21:59:50.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:50.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T21:59:50.811+0000] {logging_mixin.py:190} INFO - [2025-01-14T21:59:50.811+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T21:59:50.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.576 seconds
[2025-01-14T22:00:21.229+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:21.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:00:21.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:21.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:21.687+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:21.705+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:21.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:00:21.722+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:21.722+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:00:21.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-14T22:00:52.132+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:52.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:00:52.136+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:52.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:52.591+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:00:52.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:52.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:00:52.620+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:00:52.620+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:00:52.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-14T22:01:23.079+0000] {processor.py:186} INFO - Started process (PID=507) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:23.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:01:23.085+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:23.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:23.525+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:23.541+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:23.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:01:23.551+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:23.551+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:01:23.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-14T22:01:53.952+0000] {processor.py:186} INFO - Started process (PID=509) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:53.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:01:53.956+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:53.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:54.392+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:01:54.408+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:54.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:01:54.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:01:54.428+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:01:54.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-14T22:02:24.919+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:24.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:02:24.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:24.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:25.370+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:25.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:25.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:02:25.395+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:25.395+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:02:25.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.494 seconds
[2025-01-14T22:02:55.806+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:55.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:02:55.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:55.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:56.265+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:02:56.283+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:56.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:02:56.293+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:02:56.293+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:02:56.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-14T22:03:26.710+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:26.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:03:26.715+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:26.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:27.170+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:27.187+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:27.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:03:27.196+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:27.196+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:03:27.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-14T22:03:57.652+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:57.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:03:57.658+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:57.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:58.107+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:03:58.129+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:58.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:03:58.140+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:03:58.140+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:03:58.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-14T22:04:28.562+0000] {processor.py:186} INFO - Started process (PID=519) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:28.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:04:28.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:28.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:29.022+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:29.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:29.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:04:29.062+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:29.062+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:04:29.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.519 seconds
[2025-01-14T22:04:59.489+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:59.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:04:59.496+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:59.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:59.945+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:04:59.977+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:59.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:04:59.987+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:04:59.987+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:04:59.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.515 seconds
[2025-01-14T22:05:30.387+0000] {processor.py:186} INFO - Started process (PID=523) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:05:30.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:05:30.393+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:05:30.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:05:30.837+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:05:30.855+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:05:30.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:05:30.864+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:05:30.864+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:05:30.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.498 seconds
[2025-01-14T22:06:01.329+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:01.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:06:01.333+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:01.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:01.763+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:01.797+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:01.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:06:01.807+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:01.807+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:06:01.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.496 seconds
[2025-01-14T22:06:32.284+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:32.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:06:32.288+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:32.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:32.747+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:06:32.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:32.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:06:32.775+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:06:32.775+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:06:32.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.515 seconds
[2025-01-14T22:07:03.155+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:03.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:07:03.159+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:03.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:03.607+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:03.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:03.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:07:03.635+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:03.635+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:07:03.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-14T22:07:34.078+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:34.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:07:34.083+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:34.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:34.505+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:07:34.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:34.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:07:34.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:07:34.531+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:07:34.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.468 seconds
[2025-01-14T22:08:05.022+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:05.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:08:05.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:05.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:05.470+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:05.486+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:05.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:08:05.495+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:05.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:08:05.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-14T22:08:35.763+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:35.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:08:35.768+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:35.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:36.242+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:08:36.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:36.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:08:36.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:08:36.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:08:36.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-14T22:09:06.751+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:06.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:09:06.756+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:06.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:07.209+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:07.225+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:07.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:09:07.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:07.235+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:09:07.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-14T22:09:37.662+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:37.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:09:37.667+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:37.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:38.109+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:09:38.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:38.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:09:38.135+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:09:38.135+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:09:38.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-14T22:10:08.582+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:08.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:10:08.588+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:08.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:09.045+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:09.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:09.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:10:09.087+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:09.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:10:09.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.546 seconds
[2025-01-14T22:10:39.556+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:39.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:10:39.562+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:39.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:40.005+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:10:40.022+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:40.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:10:40.032+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:10:40.032+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:10:40.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.511 seconds
[2025-01-14T22:11:10.513+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:10.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:11:10.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:10.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:10.953+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:10.970+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:10.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:11:10.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:10.980+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:11:10.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.494 seconds
[2025-01-14T22:11:41.393+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:41.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:11:41.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:41.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:41.854+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:11:41.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:41.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:11:41.880+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:11:41.880+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:11:41.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-14T22:12:12.304+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:12.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:12:12.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:12.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:12.790+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:12.806+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:12.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:12:12.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:12.816+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:12:12.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.530 seconds
[2025-01-14T22:12:43.231+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:43.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:12:43.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:43.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:43.701+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:12:43.736+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:43.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:12:43.747+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:12:43.747+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:12:43.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.543 seconds
[2025-01-14T22:13:14.172+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:14.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:13:14.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:14.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:14.611+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:14.626+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:14.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:13:14.647+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:14.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:13:14.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-14T22:13:45.042+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:45.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:13:45.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:45.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:45.501+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:13:45.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:45.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:13:45.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:13:45.527+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:13:45.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-14T22:14:15.894+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:15.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:14:15.909+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:15.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:16.360+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:16.386+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:16.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:14:16.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:16.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:14:16.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-14T22:14:46.868+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:46.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:14:46.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:46.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:47.293+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:14:47.320+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:47.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:14:47.330+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:14:47.330+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:14:47.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.484 seconds
[2025-01-14T22:15:17.748+0000] {processor.py:186} INFO - Started process (PID=561) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:17.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:15:17.758+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:17.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:18.254+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:18.270+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:18.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:15:18.282+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:18.282+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:15:18.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
[2025-01-14T22:15:48.731+0000] {processor.py:186} INFO - Started process (PID=563) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:48.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:15:48.735+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:48.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:49.192+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:15:49.209+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:49.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:15:49.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:15:49.218+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:15:49.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-14T22:16:19.649+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:19.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:16:19.655+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:19.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:20.099+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:20.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:20.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:16:20.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:20.132+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:16:20.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-14T22:16:50.516+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:50.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:16:50.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:50.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:50.965+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:16:50.999+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:50.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:16:51.011+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:16:51.011+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:16:51.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.527 seconds
[2025-01-14T22:17:21.465+0000] {processor.py:186} INFO - Started process (PID=569) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:21.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:17:21.472+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:21.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:21.930+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:21.945+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:21.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:17:21.955+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:21.955+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:17:21.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-14T22:17:52.447+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:52.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:17:52.454+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:52.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:52.883+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:17:52.905+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:52.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:17:52.915+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:17:52.915+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:17:52.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.489 seconds
[2025-01-14T22:18:23.342+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:23.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:18:23.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:23.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:23.798+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:23.814+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:23.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:18:23.826+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:23.826+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:18:23.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-14T22:18:54.313+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:54.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:18:54.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:54.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:54.749+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:18:54.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:54.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:18:54.777+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:18:54.777+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:18:54.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.505 seconds
[2025-01-14T22:19:25.238+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:25.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:19:25.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:25.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:25.686+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:25.700+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:25.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:19:25.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:25.711+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:19:25.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-14T22:19:56.176+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:56.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:19:56.180+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:56.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:56.618+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:19:56.636+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:56.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:19:56.647+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:19:56.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:19:56.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-14T22:20:27.065+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:27.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:20:27.070+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:27.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:27.525+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:27.544+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:27.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:20:27.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:27.555+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:20:27.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-14T22:20:57.994+0000] {processor.py:186} INFO - Started process (PID=583) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:57.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:20:58.013+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:58.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:58.431+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:20:58.449+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:58.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:20:58.460+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:20:58.460+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:20:58.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-14T22:21:29.465+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:21:29.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:21:29.476+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:21:29.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:21:30.240+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:21:30.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:21:30.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:21:30.295+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:21:30.295+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:21:30.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.861 seconds
[2025-01-14T22:32:21.575+0000] {processor.py:186} INFO - Started process (PID=587) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:21.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:32:21.583+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:21.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:22.331+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:22.357+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:22.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:32:22.374+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:22.374+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:32:22.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-14T22:32:52.912+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:52.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:32:52.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:52.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:53.634+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:32:53.658+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:53.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:32:53.677+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:32:53.677+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:32:53.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.816 seconds
[2025-01-14T22:33:24.188+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:24.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:33:24.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:24.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:24.968+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:24.995+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:24.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:33:25.014+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:25.014+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:33:25.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.850 seconds
[2025-01-14T22:33:55.503+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:55.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:33:55.511+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:55.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:56.271+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:33:56.300+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:56.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:33:56.325+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:33:56.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:33:56.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T22:34:26.848+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:26.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:34:26.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:26.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:28.349+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:28.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:28.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:34:28.421+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:28.421+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:34:28.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.599 seconds
[2025-01-14T22:34:58.593+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:58.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:34:58.613+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:58.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:59.340+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:34:59.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:59.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:34:59.396+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:34:59.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:34:59.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.829 seconds
[2025-01-14T22:35:29.903+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:35:29.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:35:29.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:35:29.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:35:30.751+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:35:30.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:35:30.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:35:30.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:35:30.796+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:35:30.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.927 seconds
[2025-01-14T22:36:01.304+0000] {processor.py:186} INFO - Started process (PID=601) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:01.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:36:01.311+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:01.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:02.065+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:02.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:02.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:36:02.122+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:02.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:36:02.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.845 seconds
[2025-01-14T22:36:32.329+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:32.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:36:32.339+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:32.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:33.182+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:36:33.233+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:33.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:36:33.251+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:36:33.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:36:33.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.967 seconds
[2025-01-14T22:37:03.782+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:03.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:37:03.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:03.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:04.520+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:04.564+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:04.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:37:04.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:04.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:37:04.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.828 seconds
[2025-01-14T22:37:35.099+0000] {processor.py:186} INFO - Started process (PID=607) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:35.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:37:35.116+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:35.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:35.964+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:37:36.020+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:36.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:37:36.041+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:37:36.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:37:36.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.968 seconds
[2025-01-14T22:38:06.671+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:06.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:38:06.684+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:06.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:07.439+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:07.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:07.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:38:07.482+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:07.482+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:38:07.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T22:38:38.008+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:38.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:38:38.015+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:38.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:38.741+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:38:38.769+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:38.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:38:38.785+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:38:38.785+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:38:38.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.802 seconds
[2025-01-14T22:39:09.230+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:09.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:39:09.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:09.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:09.986+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:10.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:10.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:39:10.045+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:10.045+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:39:10.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.843 seconds
[2025-01-14T22:39:40.464+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:40.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:39:40.471+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:40.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:41.219+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:39:41.259+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:41.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:39:41.275+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:39:41.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:39:41.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.834 seconds
[2025-01-14T22:40:11.723+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:11.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:40:11.755+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:11.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:12.512+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:12.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:12.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:40:12.554+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:12.554+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:40:12.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.854 seconds
[2025-01-14T22:40:43.007+0000] {processor.py:186} INFO - Started process (PID=619) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:43.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:40:43.014+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:43.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:43.773+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:40:43.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:43.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:40:43.817+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:40:43.817+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:40:43.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.837 seconds
[2025-01-14T22:41:14.267+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:14.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:41:14.274+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:14.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:15.026+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:15.050+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:15.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:41:15.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:15.075+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:41:15.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.833 seconds
[2025-01-14T22:41:45.381+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:45.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:41:45.390+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:45.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:46.118+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:41:46.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:46.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:41:46.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:41:46.165+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:41:46.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.821 seconds
[2025-01-14T22:42:16.660+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:16.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:42:16.667+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:16.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:17.871+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:17.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:17.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:42:17.977+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:17.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:42:17.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.349 seconds
[2025-01-14T22:42:48.255+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:48.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:42:48.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:48.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:48.972+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:42:49.011+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:49.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:42:49.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:42:49.028+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:42:49.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.799 seconds
[2025-01-14T22:43:19.478+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:19.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:43:19.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:19.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:20.200+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:20.243+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:20.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:43:20.260+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:20.260+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:43:20.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.811 seconds
[2025-01-14T22:43:50.762+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:50.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:43:50.771+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:50.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:51.466+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:43:51.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:51.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:43:51.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:43:51.530+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:43:51.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.821 seconds
[2025-01-14T22:44:21.998+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:22.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:44:22.005+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:22.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:22.718+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:22.746+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:22.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:44:22.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:22.762+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:44:22.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-14T22:44:53.028+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:53.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:44:53.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:53.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:53.758+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:44:53.784+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:53.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:44:53.800+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:44:53.800+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:44:53.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-14T22:45:24.316+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:24.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:45:24.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:24.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:25.053+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:25.093+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:25.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:45:25.119+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:25.119+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:45:25.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-14T22:45:55.580+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:55.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:45:55.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:55.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:56.357+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:45:56.402+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:56.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:45:56.419+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:45:56.418+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:45:56.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.868 seconds
[2025-01-14T22:46:26.912+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:26.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:46:26.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:26.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:27.669+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:27.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:27.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:46:27.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:27.713+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:46:27.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.825 seconds
[2025-01-14T22:46:58.198+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:58.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:46:58.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:58.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:58.938+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:46:58.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:58.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:46:58.979+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:46:58.979+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:46:58.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.820 seconds
[2025-01-14T22:47:29.485+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:47:29.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:47:29.493+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:47:29.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:47:30.255+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:47:30.279+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:47:30.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:47:30.307+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:47:30.307+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:47:30.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-14T22:48:00.389+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:00.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:48:00.395+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:00.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:01.138+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:01.161+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:01.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:48:01.191+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:01.191+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:48:01.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-14T22:48:31.612+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:31.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:48:31.619+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:31.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:32.515+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:48:32.566+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:32.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:48:32.586+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:48:32.586+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:48:32.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.000 seconds
[2025-01-14T22:49:03.093+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:03.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:49:03.100+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:03.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:03.846+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:03.869+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:03.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:49:03.885+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:03.884+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:49:03.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.824 seconds
[2025-01-14T22:49:34.473+0000] {processor.py:186} INFO - Started process (PID=653) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:34.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:49:34.480+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:34.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:35.270+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:49:35.309+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:35.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:49:35.325+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:49:35.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:49:35.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.878 seconds
[2025-01-14T22:50:05.872+0000] {processor.py:186} INFO - Started process (PID=655) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:05.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:50:05.885+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:05.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:06.645+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:06.670+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:06.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:50:06.686+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:06.686+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:50:06.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.853 seconds
[2025-01-14T22:50:37.265+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:37.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:50:37.273+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:37.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:38.024+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:50:38.050+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:38.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:50:38.068+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:50:38.068+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:50:38.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.843 seconds
[2025-01-14T22:51:08.617+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:08.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:51:08.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:08.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:09.564+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:09.590+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:09.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:51:09.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:09.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:51:09.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.015 seconds
[2025-01-14T22:51:40.189+0000] {processor.py:186} INFO - Started process (PID=661) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:40.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:51:40.196+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:40.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:40.959+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:51:40.999+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:40.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:51:41.016+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:51:41.016+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:51:41.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.875 seconds
[2025-01-14T22:52:11.531+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:11.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:52:11.538+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:11.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:12.277+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:12.302+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:12.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:52:12.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:12.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:52:12.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.809 seconds
[2025-01-14T22:52:42.905+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:42.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:52:42.913+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:42.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:43.648+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:52:43.672+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:43.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:52:43.689+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:52:43.689+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:52:43.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.809 seconds
[2025-01-14T22:53:14.234+0000] {processor.py:186} INFO - Started process (PID=667) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:14.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:53:14.240+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:14.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:14.942+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:14.966+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:14.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:53:14.983+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:14.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:53:14.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.785 seconds
[2025-01-14T22:53:45.610+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:45.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:53:45.618+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:45.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:46.323+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:53:46.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:46.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:53:46.380+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:53:46.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:53:46.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.799 seconds
[2025-01-14T22:54:16.981+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:16.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:54:16.990+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:16.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:17.705+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:17.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:17.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:54:17.747+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:17.747+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:54:17.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.822 seconds
[2025-01-14T22:54:48.295+0000] {processor.py:186} INFO - Started process (PID=673) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:48.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:54:48.303+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:48.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:49.050+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:54:49.077+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:49.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:54:49.093+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:54:49.093+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:54:49.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.828 seconds
[2025-01-14T22:55:19.906+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:19.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:55:19.910+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:19.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:20.380+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:20.421+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:20.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:55:20.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:20.439+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:55:20.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.572 seconds
[2025-01-14T22:55:50.960+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:50.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:55:50.967+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:50.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:51.494+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:55:51.526+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:51.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:55:51.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:55:51.563+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:55:51.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.639 seconds
[2025-01-14T22:56:21.926+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:21.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:56:21.933+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:21.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:22.505+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:22.540+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:22.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:56:22.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:22.563+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:56:22.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.667 seconds
[2025-01-14T22:56:53.125+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:53.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:56:53.133+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:53.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:53.763+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:56:53.800+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:53.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:56:53.819+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:56:53.818+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:56:53.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.724 seconds
[2025-01-14T22:57:23.953+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:23.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:57:23.969+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:23.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:24.500+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:24.528+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:24.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:57:24.547+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:24.547+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:57:24.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.630 seconds
[2025-01-14T22:57:54.667+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:54.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:57:54.675+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:54.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:55.209+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:57:55.240+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:55.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:57:55.260+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:57:55.259+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:57:55.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.628 seconds
[2025-01-14T22:58:25.434+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:25.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:58:25.443+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:25.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:25.954+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:25.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:25.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:58:26.016+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:26.015+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:58:26.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.629 seconds
[2025-01-14T22:58:56.531+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:56.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:58:56.549+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:56.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:57.093+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:58:57.138+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:57.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:58:57.161+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:58:57.160+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:58:57.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.667 seconds
[2025-01-14T22:59:27.476+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:27.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:59:27.483+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:27.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:27.984+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:28.035+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:28.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:59:28.054+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:28.054+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:59:28.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.605 seconds
[2025-01-14T22:59:58.583+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:58.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T22:59:58.592+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:58.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:59.103+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T22:59:59.135+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:59.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T22:59:59.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T22:59:59.155+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T22:59:59.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.618 seconds
[2025-01-14T23:00:29.469+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:00:29.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:00:29.488+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:00:29.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:00:30.067+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:00:30.099+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:00:30.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:00:30.124+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:00:30.123+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:00:30.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.724 seconds
[2025-01-14T23:01:00.607+0000] {processor.py:186} INFO - Started process (PID=697) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:00.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:01:00.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:00.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:01.154+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:01.179+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:01.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:01:01.198+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:01.198+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:01:01.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.647 seconds
[2025-01-14T23:01:31.495+0000] {processor.py:186} INFO - Started process (PID=699) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:31.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:01:31.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:31.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:32.722+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:01:32.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:32.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:01:32.826+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:01:32.826+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:01:32.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.397 seconds
[2025-01-14T23:02:03.601+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:03.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:02:03.612+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:03.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:05.024+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:05.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:05.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:02:05.185+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:05.185+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:02:05.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.631 seconds
[2025-01-14T23:02:35.754+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:35.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:02:35.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:35.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:36.385+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:02:36.439+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:36.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:02:36.469+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:02:36.469+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:02:36.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.750 seconds
[2025-01-14T23:03:07.330+0000] {processor.py:186} INFO - Started process (PID=705) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:07.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:03:07.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:07.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:07.910+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:07.944+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:07.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:03:07.965+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:07.965+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:03:07.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.675 seconds
[2025-01-14T23:03:38.617+0000] {processor.py:186} INFO - Started process (PID=707) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:38.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:03:38.624+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:38.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:39.155+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:03:39.190+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:39.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:03:39.210+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:03:39.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:03:39.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.625 seconds
[2025-01-14T23:04:09.837+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:09.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:04:09.847+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:09.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:10.386+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:10.424+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:10.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:04:10.457+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:10.457+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:04:10.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.650 seconds
[2025-01-14T23:04:41.004+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:41.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:04:41.012+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:41.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:41.527+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:04:41.579+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:41.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:04:41.597+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:04:41.597+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:04:41.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.620 seconds
[2025-01-14T23:05:11.949+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:11.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:05:11.956+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:11.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:12.487+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:12.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:12.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:05:12.541+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:12.540+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:05:12.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.647 seconds
[2025-01-14T23:05:43.036+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:43.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:05:43.045+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:43.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:43.570+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:05:43.602+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:43.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:05:43.636+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:05:43.636+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:05:43.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.630 seconds
[2025-01-14T23:06:13.954+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:13.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:06:13.961+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:13.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:14.495+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:14.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:14.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:06:14.565+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:14.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:06:14.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.635 seconds
[2025-01-14T23:06:45.056+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:45.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:06:45.063+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:45.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:45.590+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:06:45.639+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:45.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:06:45.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:06:45.661+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:06:45.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.639 seconds
[2025-01-14T23:07:16.145+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:16.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:07:16.152+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:16.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:16.699+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:16.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:16.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:07:16.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:16.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:07:16.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.632 seconds
[2025-01-14T23:07:47.186+0000] {processor.py:186} INFO - Started process (PID=723) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:47.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:07:47.200+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:47.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:47.732+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:07:47.781+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:47.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:07:47.799+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:07:47.799+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:07:47.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.656 seconds
[2025-01-14T23:08:18.171+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:18.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:08:18.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:18.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:18.735+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:18.781+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:18.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:08:18.801+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:18.801+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:08:18.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.658 seconds
[2025-01-14T23:08:49.063+0000] {processor.py:186} INFO - Started process (PID=727) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:49.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:08:49.081+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:49.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:49.734+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:08:49.802+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:49.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:08:49.844+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:08:49.844+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:08:49.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.822 seconds
[2025-01-14T23:09:20.447+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:20.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:09:20.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:20.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:20.972+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:21.015+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:21.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:09:21.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:21.036+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:09:21.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.619 seconds
[2025-01-14T23:09:51.911+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:51.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:09:51.920+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:51.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:53.437+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:09:53.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:53.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:09:53.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:09:53.537+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:09:53.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.707 seconds
[2025-01-14T23:10:23.770+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:23.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:10:23.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:23.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:24.465+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:24.519+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:24.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:10:24.542+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:24.542+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:10:24.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.816 seconds
[2025-01-14T23:10:55.176+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:55.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:10:55.187+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:55.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:55.824+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:10:55.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:55.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:10:55.896+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:10:55.895+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:10:55.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.776 seconds
[2025-01-14T23:11:26.685+0000] {processor.py:186} INFO - Started process (PID=737) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:11:26.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:11:26.699+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:11:26.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:11:28.455+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:11:28.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:11:28.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:11:28.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:11:28.766+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:11:28.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.160 seconds
[2025-01-14T23:11:59.405+0000] {processor.py:186} INFO - Started process (PID=739) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:11:59.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:11:59.414+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:11:59.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:12:00.026+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:12:00.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:12:00.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:12:00.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:12:00.569+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:12:00.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.229 seconds
[2025-01-14T23:12:31.028+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:12:31.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:12:31.033+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:12:31.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:12:31.590+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:12:31.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:12:31.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:12:31.654+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:12:31.654+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:12:31.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.666 seconds
[2025-01-14T23:13:02.302+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:02.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:13:02.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:02.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:02.813+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:02.842+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:02.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:13:02.875+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:02.875+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:13:02.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.617 seconds
[2025-01-14T23:13:33.391+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:33.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:13:33.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:33.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:33.964+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:13:34.006+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:34.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:13:34.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:13:34.028+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:13:34.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.674 seconds
[2025-01-14T23:14:04.530+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:04.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:14:04.535+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:04.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:05.139+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:05.180+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:05.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:14:05.203+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:05.203+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:14:05.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.698 seconds
[2025-01-14T23:14:35.756+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:35.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:14:35.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:35.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:36.360+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:14:36.403+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:36.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:14:36.425+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:14:36.425+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:14:36.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.704 seconds
[2025-01-14T23:15:07.055+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:07.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:15:07.069+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:07.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:07.624+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:07.654+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:07.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:15:07.683+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:07.683+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:15:07.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.660 seconds
[2025-01-14T23:15:37.998+0000] {processor.py:186} INFO - Started process (PID=753) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:38.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:15:38.005+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:38.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:38.557+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:15:38.601+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:38.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:15:38.622+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:15:38.622+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:15:38.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.675 seconds
[2025-01-14T23:16:08.746+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:08.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:16:08.753+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:08.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:09.351+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:09.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:09.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:16:09.409+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:09.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:16:09.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.692 seconds
[2025-01-14T23:16:39.556+0000] {processor.py:186} INFO - Started process (PID=757) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:39.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:16:39.566+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:39.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:40.107+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:16:40.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:40.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:16:40.176+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:16:40.175+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:16:40.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.650 seconds
[2025-01-14T23:17:10.290+0000] {processor.py:186} INFO - Started process (PID=759) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:10.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:17:10.297+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:10.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:10.841+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:10.882+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:10.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:17:10.924+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:10.924+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:17:10.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.666 seconds
[2025-01-14T23:17:41.156+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:41.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:17:41.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:41.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:41.689+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:17:41.728+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:41.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:17:41.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:17:41.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:17:41.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.637 seconds
[2025-01-14T23:18:11.922+0000] {processor.py:186} INFO - Started process (PID=763) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:11.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:18:11.930+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:11.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:12.537+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:12.580+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:12.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:18:12.599+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:12.599+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:18:12.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.710 seconds
[2025-01-14T23:18:42.741+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:42.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:18:42.747+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:42.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:43.298+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:18:43.329+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:43.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:18:43.359+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:18:43.359+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:18:43.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.659 seconds
[2025-01-14T23:19:13.570+0000] {processor.py:186} INFO - Started process (PID=767) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:13.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:19:13.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:13.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:14.564+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:14.608+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:14.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:19:14.659+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:14.659+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:19:14.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.138 seconds
[2025-01-14T23:19:45.437+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:45.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:19:45.443+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:45.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:45.995+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:19:46.034+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:46.034+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:19:46.057+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:19:46.057+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:19:46.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.653 seconds
[2025-01-14T23:20:16.628+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:16.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:20:16.638+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:16.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:17.145+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:17.174+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:17.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:20:17.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:17.192+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:20:17.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.591 seconds
[2025-01-14T23:20:47.715+0000] {processor.py:186} INFO - Started process (PID=773) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:47.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:20:47.722+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:47.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:48.274+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:20:48.306+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:48.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:20:48.324+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:20:48.323+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:20:48.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.637 seconds
[2025-01-14T23:21:18.525+0000] {processor.py:186} INFO - Started process (PID=775) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:18.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:21:18.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:18.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:19.092+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:19.150+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:19.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:21:19.184+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:19.183+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:21:19.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.688 seconds
[2025-01-14T23:21:49.666+0000] {processor.py:186} INFO - Started process (PID=777) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:49.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:21:49.680+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:49.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:50.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:21:50.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:50.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:21:50.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:21:50.278+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:21:50.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.666 seconds
[2025-01-14T23:22:20.563+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:20.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:22:20.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:20.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:21.134+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:21.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:21.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:22:21.188+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:21.188+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:22:21.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.674 seconds
[2025-01-14T23:22:51.771+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:51.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:22:51.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:51.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:52.334+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:22:52.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:52.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:22:52.403+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:22:52.403+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:22:52.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.670 seconds
[2025-01-14T23:23:22.945+0000] {processor.py:186} INFO - Started process (PID=783) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:22.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:23:22.954+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:22.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:23.554+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:23.593+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:23.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:23:23.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:23.623+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:23:23.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.713 seconds
[2025-01-14T23:23:53.860+0000] {processor.py:186} INFO - Started process (PID=785) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:53.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:23:53.869+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:53.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:54.436+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:23:54.473+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:54.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:23:54.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:23:54.513+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:23:54.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.685 seconds
[2025-01-14T23:24:25.009+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:25.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:24:25.017+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:25.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:25.593+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:25.624+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:25.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:24:25.645+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:25.645+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:24:25.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.673 seconds
[2025-01-14T23:24:55.885+0000] {processor.py:186} INFO - Started process (PID=789) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:55.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:24:55.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:55.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:56.594+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:24:56.628+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:56.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:24:56.649+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:24:56.649+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:24:56.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.808 seconds
[2025-01-14T23:25:27.189+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:27.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:25:27.198+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:27.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:27.764+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:27.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:27.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:25:27.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:27.816+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:25:27.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.660 seconds
[2025-01-14T23:25:58.031+0000] {processor.py:186} INFO - Started process (PID=793) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:58.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:25:58.038+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:58.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:58.540+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:25:58.574+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:58.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:25:58.594+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:25:58.594+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:25:58.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.603 seconds
[2025-01-14T23:26:29.123+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:26:29.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:26:29.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:26:29.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:26:29.667+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:26:29.699+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:26:29.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:26:29.718+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:26:29.717+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:26:29.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.652 seconds
[2025-01-14T23:27:00.278+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:00.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:27:00.294+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:00.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:00.838+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:00.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:00.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:27:00.893+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:00.893+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:27:00.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.652 seconds
[2025-01-14T23:27:31.483+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:31.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:27:31.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:31.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:32.069+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:27:32.099+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:32.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:27:32.130+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:27:32.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:27:32.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.680 seconds
[2025-01-14T23:28:02.640+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:02.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:28:02.650+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:02.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:03.196+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:03.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:03.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:28:03.249+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:03.248+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:28:03.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.654 seconds
[2025-01-14T23:28:33.544+0000] {processor.py:186} INFO - Started process (PID=803) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:33.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:28:33.550+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:33.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:34.092+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:28:34.147+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:34.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:28:34.170+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:28:34.170+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:28:34.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.655 seconds
[2025-01-14T23:29:04.723+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:04.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:29:04.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:04.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:05.382+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:05.420+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:05.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:29:05.439+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:05.439+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:29:05.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.770 seconds
[2025-01-14T23:29:36.089+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:36.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:29:36.104+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:36.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:37.157+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:29:37.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:37.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:29:37.262+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:29:37.261+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:29:37.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.210 seconds
[2025-01-14T23:30:07.777+0000] {processor.py:186} INFO - Started process (PID=809) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:07.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:30:07.790+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:07.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:08.311+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:08.468+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:08.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:30:08.572+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:08.572+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:30:08.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.850 seconds
[2025-01-14T23:30:39.200+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:39.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:30:39.210+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:39.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:39.720+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:30:39.754+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:39.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:30:39.788+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:30:39.788+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:30:39.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.629 seconds
[2025-01-14T23:31:10.286+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:10.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:31:10.305+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:10.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:10.844+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:10.874+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:10.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:31:10.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:10.897+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:31:10.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.645 seconds
[2025-01-14T23:31:41.110+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:41.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:31:41.133+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:41.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:41.852+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:31:41.891+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:41.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:31:41.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:31:41.911+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:31:41.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.834 seconds
[2025-01-14T23:32:12.454+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:12.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:32:12.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:12.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:12.968+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:13.008+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:13.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:32:13.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:13.028+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:32:13.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.625 seconds
[2025-01-14T23:32:43.276+0000] {processor.py:186} INFO - Started process (PID=819) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:43.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:32:43.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:43.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:43.841+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:32:43.876+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:43.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:32:43.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:32:43.911+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:32:43.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.682 seconds
[2025-01-14T23:33:14.531+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:14.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:33:14.540+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:14.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:15.065+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:15.099+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:15.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:33:15.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:15.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:33:15.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.648 seconds
[2025-01-14T23:33:45.372+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:45.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:33:45.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:45.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:45.887+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:33:45.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:45.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:33:45.940+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:33:45.939+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:33:45.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.604 seconds
[2025-01-14T23:34:16.048+0000] {processor.py:186} INFO - Started process (PID=825) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:16.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:34:16.054+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:16.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:16.598+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:16.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:16.646+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:34:16.668+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:16.667+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:34:16.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.651 seconds
[2025-01-14T23:34:46.853+0000] {processor.py:186} INFO - Started process (PID=827) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:46.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:34:46.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:46.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:47.432+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:34:47.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:47.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:34:47.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:34:47.484+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:34:47.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.663 seconds
[2025-01-14T23:35:17.591+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:17.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:35:17.598+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:17.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:18.149+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:18.188+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:18.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:35:18.210+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:18.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:35:18.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.647 seconds
[2025-01-14T23:35:48.399+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:48.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:35:48.406+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:48.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:48.930+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:35:48.961+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:48.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:35:48.983+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:35:48.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:35:48.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.611 seconds
[2025-01-14T23:36:19.669+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:19.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:36:19.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:19.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:20.258+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:20.309+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:20.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:36:20.329+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:20.329+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:36:20.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-14T23:36:50.551+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:50.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:36:50.558+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:50.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:51.120+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:36:51.163+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:51.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:36:51.186+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:36:51.185+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:36:51.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.669 seconds
[2025-01-14T23:37:21.707+0000] {processor.py:186} INFO - Started process (PID=837) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:21.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:37:21.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:21.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:22.340+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:22.376+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:22.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:37:22.413+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:22.413+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:37:22.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.743 seconds
[2025-01-14T23:37:52.722+0000] {processor.py:186} INFO - Started process (PID=839) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:52.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:37:52.735+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:52.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:53.404+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:37:53.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:53.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:37:53.488+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:37:53.488+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:37:53.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.811 seconds
[2025-01-14T23:39:07.210+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:39:07.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-14T23:39:07.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:39:07.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:39:08.689+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-14T23:39:08.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:39:08.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T23:39:08.843+0000] {logging_mixin.py:190} INFO - [2025-01-14T23:39:08.843+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-14 00:00:00+00:00, run_after=2025-01-15 00:00:00+00:00
[2025-01-14T23:39:08.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.764 seconds
