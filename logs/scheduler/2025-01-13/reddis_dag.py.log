[2025-01-13T01:01:30.783+0000] {processor.py:186} INFO - Started process (PID=1671) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:01:30.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:01:30.787+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:01:30.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:01:31.167+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:01:31.430+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:01:31.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:01:35.653+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:01:35.653+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-12 00:00:00+00:00, run_after=2025-01-13 00:00:00+00:00
[2025-01-13T01:01:35.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 4.902 seconds
[2025-01-13T01:16:21.638+0000] {processor.py:186} INFO - Started process (PID=1673) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:21.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:16:21.654+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:21.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:22.990+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:23.145+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:23.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:16:23.202+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:23.202+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:16:23.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.684 seconds
[2025-01-13T01:16:54.112+0000] {processor.py:186} INFO - Started process (PID=1675) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:54.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:16:54.118+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:54.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:54.561+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:16:54.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:54.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:16:54.659+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:16:54.659+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:16:54.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.600 seconds
[2025-01-13T01:17:25.404+0000] {processor.py:186} INFO - Started process (PID=1677) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:25.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:17:25.423+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:25.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:25.924+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:26.120+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:26.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:17:26.225+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:26.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:17:26.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.919 seconds
[2025-01-13T01:17:56.786+0000] {processor.py:186} INFO - Started process (PID=1679) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:56.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:17:56.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:56.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:57.172+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:17:57.213+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:57.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:17:57.235+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:17:57.235+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:17:57.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-13T01:18:27.878+0000] {processor.py:186} INFO - Started process (PID=1681) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:27.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:18:27.884+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:27.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:28.280+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:28.314+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:28.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:18:28.337+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:28.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:18:28.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-13T01:18:58.699+0000] {processor.py:186} INFO - Started process (PID=1683) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:58.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:18:58.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:58.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:59.089+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:18:59.119+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:59.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:18:59.146+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:18:59.145+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:18:59.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T01:19:29.536+0000] {processor.py:186} INFO - Started process (PID=1685) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:19:29.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:19:29.540+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:19:29.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:19:29.919+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:19:29.951+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:19:29.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:19:29.974+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:19:29.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:19:29.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.485 seconds
[2025-01-13T01:20:00.462+0000] {processor.py:186} INFO - Started process (PID=1687) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:00.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:20:00.465+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:00.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:00.844+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:00.876+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:00.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:20:00.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:00.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:20:00.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.466 seconds
[2025-01-13T01:20:31.327+0000] {processor.py:186} INFO - Started process (PID=1689) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:31.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:20:31.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:31.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:31.699+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:20:31.727+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:31.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:20:31.761+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:20:31.761+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:20:31.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.462 seconds
[2025-01-13T01:21:02.305+0000] {processor.py:186} INFO - Started process (PID=1691) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:02.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:21:02.309+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:02.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:02.718+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:02.749+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:02.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:21:02.784+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:02.784+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:21:02.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.509 seconds
[2025-01-13T01:21:33.224+0000] {processor.py:186} INFO - Started process (PID=1693) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:33.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:21:33.227+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:33.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:33.611+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:21:33.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:33.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:21:33.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:21:33.665+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:21:33.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.469 seconds
[2025-01-13T01:22:04.055+0000] {processor.py:186} INFO - Started process (PID=1695) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:04.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:22:04.059+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:04.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:04.457+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:04.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:04.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:22:04.527+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:04.527+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:22:04.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.500 seconds
[2025-01-13T01:22:35.035+0000] {processor.py:186} INFO - Started process (PID=1697) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:35.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:22:35.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:35.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:35.443+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:22:35.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:35.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:22:35.508+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:22:35.508+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:22:35.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T01:23:05.861+0000] {processor.py:186} INFO - Started process (PID=1699) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:05.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:23:05.864+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:05.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:06.251+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:06.297+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:06.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:23:06.319+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:06.319+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:23:06.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.486 seconds
[2025-01-13T01:23:36.817+0000] {processor.py:186} INFO - Started process (PID=1701) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:36.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:23:36.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:36.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:37.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:23:37.249+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:37.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:23:37.271+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:23:37.271+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:23:37.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T01:24:07.740+0000] {processor.py:186} INFO - Started process (PID=1703) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:07.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:24:07.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:07.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:08.152+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:08.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:08.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:24:08.210+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:08.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:24:08.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-13T01:24:38.590+0000] {processor.py:186} INFO - Started process (PID=1705) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:38.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:24:38.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:38.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:38.966+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:24:38.999+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:38.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:24:39.026+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:24:39.026+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:24:39.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T01:25:09.531+0000] {processor.py:186} INFO - Started process (PID=1707) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:09.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:25:09.535+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:09.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:09.935+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:09.985+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:09.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:25:10.007+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:10.007+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:25:10.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-13T01:25:40.319+0000] {processor.py:186} INFO - Started process (PID=1709) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:40.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:25:40.324+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:40.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:40.736+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:25:40.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:40.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:25:40.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:25:40.789+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:25:40.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-13T01:26:11.217+0000] {processor.py:186} INFO - Started process (PID=1711) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:11.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:26:11.221+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:11.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:11.598+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:11.630+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:11.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:26:11.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:11.666+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:26:11.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.478 seconds
[2025-01-13T01:26:42.173+0000] {processor.py:186} INFO - Started process (PID=1713) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:42.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:26:42.179+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:42.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:42.560+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:26:42.628+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:42.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:26:42.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:26:42.662+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:26:42.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.526 seconds
[2025-01-13T01:27:13.295+0000] {processor.py:186} INFO - Started process (PID=1715) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:13.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:27:13.300+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:13.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:13.682+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:13.716+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:13.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:27:13.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:13.754+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:27:13.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.509 seconds
[2025-01-13T01:27:44.264+0000] {processor.py:186} INFO - Started process (PID=1717) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:44.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:27:44.270+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:44.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:44.658+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:27:44.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:44.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:27:44.728+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:27:44.728+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:27:44.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-13T01:28:15.678+0000] {processor.py:186} INFO - Started process (PID=1719) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:28:15.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:28:15.714+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:28:15.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:28:33.437+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:28:33.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:28:33.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:28:33.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:28:33.757+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:28:33.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 22.416 seconds
[2025-01-13T01:29:05.468+0000] {processor.py:186} INFO - Started process (PID=1721) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:05.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:29:05.495+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:05.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:06.242+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:06.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:06.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:29:06.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:06.375+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:29:06.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.575 seconds
[2025-01-13T01:29:37.078+0000] {processor.py:186} INFO - Started process (PID=1723) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:37.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:29:37.086+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:37.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:37.590+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:29:37.657+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:37.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:29:37.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:29:37.684+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:29:37.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.647 seconds
[2025-01-13T01:30:08.302+0000] {processor.py:186} INFO - Started process (PID=1725) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:08.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:30:08.306+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:08.305+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:08.803+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:08.897+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:08.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:30:09.016+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:09.015+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:30:09.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.760 seconds
[2025-01-13T01:30:39.707+0000] {processor.py:186} INFO - Started process (PID=1727) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:39.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:30:39.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:39.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:40.123+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:30:40.156+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:40.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:30:40.177+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:30:40.177+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:30:40.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.529 seconds
[2025-01-13T01:31:10.643+0000] {processor.py:186} INFO - Started process (PID=1729) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:10.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:31:10.646+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:10.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:11.062+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:11.113+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:11.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:31:11.134+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:11.134+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:31:11.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.519 seconds
[2025-01-13T01:31:41.580+0000] {processor.py:186} INFO - Started process (PID=1731) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:41.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:31:41.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:41.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:41.958+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:31:42.008+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:42.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:31:42.042+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:31:42.042+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:31:42.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T01:32:12.524+0000] {processor.py:186} INFO - Started process (PID=1733) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:12.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:32:12.546+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:12.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:12.948+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:12.979+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:12.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:32:13.000+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:13.000+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:32:13.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.514 seconds
[2025-01-13T01:32:43.323+0000] {processor.py:186} INFO - Started process (PID=1735) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:43.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:32:43.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:43.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:43.744+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:32:43.776+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:43.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:32:43.799+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:32:43.799+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:32:43.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-13T01:33:14.286+0000] {processor.py:186} INFO - Started process (PID=1737) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:14.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:33:14.291+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:14.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:14.689+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:14.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:14.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:33:14.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:14.757+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:33:14.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-13T01:33:45.269+0000] {processor.py:186} INFO - Started process (PID=1739) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:45.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:33:45.280+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:45.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:45.696+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:33:45.731+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:45.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:33:45.752+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:33:45.752+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:33:45.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.538 seconds
[2025-01-13T01:34:16.238+0000] {processor.py:186} INFO - Started process (PID=1741) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:16.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:34:16.241+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:16.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:16.681+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:16.732+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:16.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:34:16.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:16.755+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:34:16.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.572 seconds
[2025-01-13T01:34:47.185+0000] {processor.py:186} INFO - Started process (PID=1743) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:47.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:34:47.189+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:47.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:47.592+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:34:47.629+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:47.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:34:47.654+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:34:47.654+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:34:47.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-13T01:35:18.181+0000] {processor.py:186} INFO - Started process (PID=1745) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:18.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:35:18.185+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:18.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:18.603+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:18.657+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:18.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:35:18.680+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:18.680+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:35:18.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T01:35:49.048+0000] {processor.py:186} INFO - Started process (PID=1747) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:49.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:35:49.052+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:49.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:49.473+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:35:49.508+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:49.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:35:49.529+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:35:49.529+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:35:49.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T01:36:19.975+0000] {processor.py:186} INFO - Started process (PID=1749) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:19.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:36:19.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:19.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:20.359+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:20.401+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:20.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:36:20.440+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:20.439+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:36:20.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T01:36:50.944+0000] {processor.py:186} INFO - Started process (PID=1751) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:50.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:36:50.948+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:50.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:51.374+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:36:51.417+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:51.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:36:51.443+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:36:51.442+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:36:51.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.526 seconds
[2025-01-13T01:37:21.882+0000] {processor.py:186} INFO - Started process (PID=1753) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:21.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:37:21.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:21.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:22.271+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:22.306+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:22.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:37:22.339+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:22.339+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:37:22.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T01:37:52.783+0000] {processor.py:186} INFO - Started process (PID=1755) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:52.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:37:52.788+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:52.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:53.168+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:37:53.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:53.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:37:53.233+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:37:53.232+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:37:53.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.475 seconds
[2025-01-13T01:38:23.647+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:23.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:38:23.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:23.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:24.086+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:24.128+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:24.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:38:24.151+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:24.151+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:38:24.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T01:38:54.645+0000] {processor.py:186} INFO - Started process (PID=1759) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:54.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:38:54.650+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:54.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:55.040+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:38:55.074+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:55.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:38:55.095+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:38:55.094+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:38:55.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.475 seconds
[2025-01-13T01:39:25.448+0000] {processor.py:186} INFO - Started process (PID=1761) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:25.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:39:25.456+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:25.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:25.860+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:25.893+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:25.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:39:25.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:25.914+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:39:25.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-13T01:39:56.319+0000] {processor.py:186} INFO - Started process (PID=1763) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:56.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:39:56.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:56.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:56.699+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:39:56.733+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:56.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:39:56.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:39:56.757+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:39:56.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.467 seconds
[2025-01-13T01:40:27.267+0000] {processor.py:186} INFO - Started process (PID=1765) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:27.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:40:27.271+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:27.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:27.671+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:27.701+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:27.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:40:27.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:27.734+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:40:27.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-13T01:40:58.288+0000] {processor.py:186} INFO - Started process (PID=1767) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:58.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:40:58.301+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:58.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:59.256+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:40:59.314+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:59.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:40:59.337+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:40:59.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:40:59.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.124 seconds
[2025-01-13T01:41:29.782+0000] {processor.py:186} INFO - Started process (PID=1769) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:41:29.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:41:29.785+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:41:29.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:41:30.155+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:41:30.186+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:41:30.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:41:30.214+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:41:30.214+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:41:30.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.471 seconds
[2025-01-13T01:42:00.860+0000] {processor.py:186} INFO - Started process (PID=1771) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:00.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:42:00.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:00.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:01.353+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:01.405+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:01.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:42:01.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:01.428+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:42:01.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.607 seconds
[2025-01-13T01:42:31.894+0000] {processor.py:186} INFO - Started process (PID=1773) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:31.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:42:31.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:31.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:32.258+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:42:32.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:32.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:42:32.315+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:42:32.315+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:42:32.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.448 seconds
[2025-01-13T01:43:02.710+0000] {processor.py:186} INFO - Started process (PID=1775) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:02.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:43:02.716+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:02.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:03.109+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:03.156+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:03.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:43:03.183+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:03.183+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:43:03.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-13T01:43:33.613+0000] {processor.py:186} INFO - Started process (PID=1777) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:33.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:43:33.617+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:33.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:33.994+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:43:34.025+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:34.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:43:34.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:43:34.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:43:34.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.465 seconds
[2025-01-13T01:44:04.523+0000] {processor.py:186} INFO - Started process (PID=1779) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:04.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:44:04.528+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:04.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:04.937+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:04.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:04.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:44:05.004+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:05.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:44:05.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-13T01:44:35.417+0000] {processor.py:186} INFO - Started process (PID=1781) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:35.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:44:35.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:35.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:35.807+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:44:35.837+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:35.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:44:35.859+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:44:35.859+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:44:35.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.485 seconds
[2025-01-13T01:45:06.306+0000] {processor.py:186} INFO - Started process (PID=1783) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:06.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:45:06.309+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:06.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:06.716+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:06.746+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:06.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:45:06.781+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:06.781+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:45:06.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.500 seconds
[2025-01-13T01:45:37.277+0000] {processor.py:186} INFO - Started process (PID=1785) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:37.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:45:37.281+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:37.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:37.691+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:45:37.722+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:37.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:45:37.745+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:45:37.745+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:45:37.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T01:46:08.193+0000] {processor.py:186} INFO - Started process (PID=1787) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:08.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:46:08.197+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:08.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:08.608+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:08.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:08.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:46:08.664+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:08.664+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:46:08.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.498 seconds
[2025-01-13T01:46:39.159+0000] {processor.py:186} INFO - Started process (PID=1789) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:39.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:46:39.162+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:39.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:39.569+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:46:39.602+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:39.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:46:39.623+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:46:39.623+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:46:39.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-13T01:47:10.013+0000] {processor.py:186} INFO - Started process (PID=1791) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:10.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:47:10.018+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:10.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:10.419+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:10.454+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:10.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:47:10.476+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:10.475+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:47:10.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.494 seconds
[2025-01-13T01:47:40.911+0000] {processor.py:186} INFO - Started process (PID=1793) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:40.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:47:40.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:40.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:41.292+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:47:41.322+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:41.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:47:41.343+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:47:41.343+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:47:41.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.472 seconds
[2025-01-13T01:48:11.879+0000] {processor.py:186} INFO - Started process (PID=1795) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:11.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:48:11.884+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:11.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:12.280+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:12.332+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:12.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:48:12.356+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:12.356+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:48:12.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.509 seconds
[2025-01-13T01:48:42.736+0000] {processor.py:186} INFO - Started process (PID=1797) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:42.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:48:42.740+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:42.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:43.148+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:48:43.194+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:43.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:48:43.229+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:48:43.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:48:43.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.533 seconds
[2025-01-13T01:49:13.835+0000] {processor.py:186} INFO - Started process (PID=1799) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:13.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:49:13.839+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:13.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:14.213+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:14.255+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:14.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:49:14.276+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:14.276+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:49:14.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.467 seconds
[2025-01-13T01:49:44.564+0000] {processor.py:186} INFO - Started process (PID=1801) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:44.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:49:44.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:44.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:44.972+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:49:45.003+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:45.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:49:45.037+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:49:45.037+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:49:45.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-13T01:50:15.484+0000] {processor.py:186} INFO - Started process (PID=1803) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:15.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:50:15.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:15.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:15.889+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:15.955+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:15.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:50:16.007+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:16.006+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:50:16.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.569 seconds
[2025-01-13T01:50:46.492+0000] {processor.py:186} INFO - Started process (PID=1805) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:46.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:50:46.496+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:46.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:46.917+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:50:46.948+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:46.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:50:46.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:50:46.971+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:50:46.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.505 seconds
[2025-01-13T01:51:17.450+0000] {processor.py:186} INFO - Started process (PID=1807) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:17.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:51:17.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:17.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:17.853+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:17.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:17.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:51:17.911+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:17.911+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:51:17.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-13T01:51:48.407+0000] {processor.py:186} INFO - Started process (PID=1809) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:48.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:51:48.410+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:48.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:48.776+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:51:48.818+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:48.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:51:48.843+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:51:48.842+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:51:48.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.464 seconds
[2025-01-13T01:52:19.345+0000] {processor.py:186} INFO - Started process (PID=1811) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:19.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:52:19.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:19.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:19.745+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:19.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:19.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:52:19.802+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:19.801+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:52:19.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.516 seconds
[2025-01-13T01:52:50.237+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:50.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:52:50.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:50.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:50.645+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:52:50.679+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:50.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:52:50.701+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:52:50.701+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:52:50.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-13T01:53:21.204+0000] {processor.py:186} INFO - Started process (PID=1815) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:21.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:53:21.209+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:21.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:21.613+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:21.659+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:21.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:53:21.681+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:21.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:53:21.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.530 seconds
[2025-01-13T01:53:52.145+0000] {processor.py:186} INFO - Started process (PID=1817) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:52.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:53:52.149+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:52.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:52.551+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:53:52.590+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:52.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:53:52.632+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:53:52.632+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:53:52.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.527 seconds
[2025-01-13T01:54:23.127+0000] {processor.py:186} INFO - Started process (PID=1819) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:23.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:54:23.132+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:23.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:23.537+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:23.590+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:23.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:54:23.613+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:23.613+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:54:23.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.537 seconds
[2025-01-13T01:54:54.005+0000] {processor.py:186} INFO - Started process (PID=1821) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:54.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:54:54.010+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:54.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:54.407+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:54:54.453+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:54.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:54:54.474+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:54:54.474+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:54:54.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T01:55:25.072+0000] {processor.py:186} INFO - Started process (PID=1823) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:25.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:55:25.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:25.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:25.459+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:25.492+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:25.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:55:25.513+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:25.513+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:55:25.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.471 seconds
[2025-01-13T01:55:55.834+0000] {processor.py:186} INFO - Started process (PID=1825) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:55.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:55:55.838+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:55.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:56.209+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:55:56.245+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:56.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:55:56.267+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:55:56.267+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:55:56.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.459 seconds
[2025-01-13T01:56:26.706+0000] {processor.py:186} INFO - Started process (PID=1827) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:26.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:56:26.710+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:26.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:27.112+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:27.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:27.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:56:27.192+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:27.192+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:56:27.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T01:56:57.662+0000] {processor.py:186} INFO - Started process (PID=1829) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:57.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:56:57.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:57.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:58.057+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:56:58.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:58.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:56:58.120+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:56:58.120+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:56:58.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.485 seconds
[2025-01-13T01:57:28.583+0000] {processor.py:186} INFO - Started process (PID=1831) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:28.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:57:28.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:28.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:28.966+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:29.004+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:29.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:57:29.032+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:29.031+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:57:29.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.491 seconds
[2025-01-13T01:57:59.510+0000] {processor.py:186} INFO - Started process (PID=1833) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:59.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:57:59.517+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:59.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:59.907+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:57:59.951+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:59.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:57:59.989+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:57:59.989+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:58:00.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.523 seconds
[2025-01-13T01:58:30.262+0000] {processor.py:186} INFO - Started process (PID=1835) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:58:30.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T01:58:30.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:58:30.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:58:30.655+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T01:58:30.707+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:58:30.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T01:58:30.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T01:58:30.735+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T01:58:30.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T02:43:45.272+0000] {processor.py:186} INFO - Started process (PID=1837) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:43:45.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:43:45.274+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:45.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:43:45.512+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:43:45.533+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:45.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:43:45.554+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:45.553+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:43:45.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.300 seconds
[2025-01-13T02:47:22.585+0000] {processor.py:186} INFO - Started process (PID=1839) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:22.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:47:22.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:22.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:23.247+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:23.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:23.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:23.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:23.340+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:23.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.805 seconds
[2025-01-13T02:47:53.748+0000] {processor.py:186} INFO - Started process (PID=1841) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:53.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:47:53.751+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:53.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:54.101+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:47:54.131+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:54.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:54.170+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:54.169+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:54.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.448 seconds
[2025-01-13T02:48:24.649+0000] {processor.py:186} INFO - Started process (PID=1843) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:24.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:48:24.653+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:24.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:25.052+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:25.102+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:25.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:25.131+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:25.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:25.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T02:48:55.656+0000] {processor.py:186} INFO - Started process (PID=1845) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:55.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:48:55.661+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:55.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:56.068+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:48:56.098+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:56.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:56.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:56.137+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:56.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.524 seconds
[2025-01-13T02:49:26.475+0000] {processor.py:186} INFO - Started process (PID=1847) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:26.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:49:26.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:26.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:26.926+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:26.972+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:26.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:26.995+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:26.994+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:27.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.558 seconds
[2025-01-13T02:49:57.485+0000] {processor.py:186} INFO - Started process (PID=1849) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:57.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:49:57.488+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:57.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:57.868+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:49:57.911+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:57.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:57.934+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:57.934+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:57.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.490 seconds
[2025-01-13T02:50:28.351+0000] {processor.py:186} INFO - Started process (PID=1851) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:28.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:50:28.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:28.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:28.792+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:28.832+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:28.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:50:28.855+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:28.854+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:50:28.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.559 seconds
[2025-01-13T02:50:59.428+0000] {processor.py:186} INFO - Started process (PID=1853) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:59.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:50:59.433+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:59.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:59.947+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:50:59.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:59.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:00.034+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:00.034+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:00.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.654 seconds
[2025-01-13T02:51:30.208+0000] {processor.py:186} INFO - Started process (PID=1855) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:51:30.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:51:30.212+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:30.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:51:30.625+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:51:30.668+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:30.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:30.696+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:30.695+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:30.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-13T02:52:01.038+0000] {processor.py:186} INFO - Started process (PID=1857) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:01.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:52:01.042+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:01.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:01.423+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:01.473+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:01.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:01.497+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:01.497+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:01.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.494 seconds
[2025-01-13T02:52:31.953+0000] {processor.py:186} INFO - Started process (PID=1859) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:31.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:52:31.958+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:31.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:32.379+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:52:32.414+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:32.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:32.435+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:32.435+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:32.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T02:53:02.856+0000] {processor.py:186} INFO - Started process (PID=1861) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:02.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:53:02.859+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:02.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:03.200+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:03.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:03.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:03.259+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:03.259+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:03.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.429 seconds
[2025-01-13T02:53:33.818+0000] {processor.py:186} INFO - Started process (PID=1863) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:33.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:53:33.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:33.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:34.207+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:53:34.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:34.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:34.279+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:34.278+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:34.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.500 seconds
[2025-01-13T02:54:04.830+0000] {processor.py:186} INFO - Started process (PID=1865) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:04.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:54:04.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:04.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:05.232+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:05.285+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:05.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:05.309+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:05.309+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:05.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T02:54:35.770+0000] {processor.py:186} INFO - Started process (PID=1867) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:35.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:54:35.774+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:35.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:36.166+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:54:36.204+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:36.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:36.240+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:36.240+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:36.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T02:55:06.674+0000] {processor.py:186} INFO - Started process (PID=1869) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:06.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:55:06.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:06.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:07.085+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:07.119+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:07.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:07.142+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:07.142+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:07.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-13T02:55:37.592+0000] {processor.py:186} INFO - Started process (PID=1871) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:37.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:55:37.596+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:37.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:37.971+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:55:38.009+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:38.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:38.048+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:38.048+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:38.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T02:56:08.601+0000] {processor.py:186} INFO - Started process (PID=1873) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:08.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:56:08.604+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:08.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:09.004+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:09.041+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:09.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:09.063+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:09.063+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:09.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T02:56:39.601+0000] {processor.py:186} INFO - Started process (PID=1875) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:39.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:56:39.605+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:39.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:40.015+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:56:40.048+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:40.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:40.070+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:40.070+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:40.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-13T02:57:10.511+0000] {processor.py:186} INFO - Started process (PID=1877) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:10.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:57:10.515+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:10.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:10.931+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:11.006+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:11.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:11.055+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:11.055+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:11.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.601 seconds
[2025-01-13T02:57:41.515+0000] {processor.py:186} INFO - Started process (PID=1879) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:41.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:57:41.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:41.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:41.918+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:57:41.951+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:41.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:41.986+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:41.986+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:41.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-13T02:58:12.381+0000] {processor.py:186} INFO - Started process (PID=1881) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:12.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:58:12.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:12.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:12.785+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:12.816+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:12.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:12.847+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:12.846+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:12.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T02:58:43.312+0000] {processor.py:186} INFO - Started process (PID=1883) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:43.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:58:43.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:43.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:43.702+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:58:43.745+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:43.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:43.775+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:43.775+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:43.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.493 seconds
[2025-01-13T02:59:14.327+0000] {processor.py:186} INFO - Started process (PID=1885) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:14.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:59:14.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:14.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:14.721+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:14.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:14.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:14.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:14.789+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:14.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T02:59:45.219+0000] {processor.py:186} INFO - Started process (PID=1887) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:45.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T02:59:45.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:45.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:45.607+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T02:59:45.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:45.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:45.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:45.667+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:45.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T03:00:16.136+0000] {processor.py:186} INFO - Started process (PID=1889) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:16.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:00:16.140+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:16.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:16.527+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:16.561+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:16.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:00:16.582+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:16.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:00:16.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.488 seconds
[2025-01-13T03:00:47.147+0000] {processor.py:186} INFO - Started process (PID=1891) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:47.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:00:47.152+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:47.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:47.537+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:00:47.571+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:47.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:00:47.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:47.593+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:00:47.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.494 seconds
[2025-01-13T03:01:18.098+0000] {processor.py:186} INFO - Started process (PID=1893) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:18.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:01:18.110+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:18.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:18.490+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:18.523+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:18.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:18.545+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:18.545+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:18.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T03:01:48.970+0000] {processor.py:186} INFO - Started process (PID=1895) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:48.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:01:48.974+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:48.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:49.357+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:01:49.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:49.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:49.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:49.427+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:49.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.485 seconds
[2025-01-13T03:02:19.902+0000] {processor.py:186} INFO - Started process (PID=1897) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:19.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:02:19.906+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:19.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:20.260+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:20.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:20.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:20.325+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:20.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:20.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.455 seconds
[2025-01-13T03:02:50.848+0000] {processor.py:186} INFO - Started process (PID=1899) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:50.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:02:50.853+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:50.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:51.258+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:02:51.296+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:51.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:51.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:51.323+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:51.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T03:03:21.771+0000] {processor.py:186} INFO - Started process (PID=1901) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:21.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:03:21.776+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:21.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:22.174+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:22.218+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:22.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:22.240+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:22.239+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:22.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-13T03:03:52.717+0000] {processor.py:186} INFO - Started process (PID=1903) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:52.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:03:52.722+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:52.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:53.141+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:03:53.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:53.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:53.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:53.196+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:53.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.511 seconds
[2025-01-13T03:04:23.640+0000] {processor.py:186} INFO - Started process (PID=1905) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:23.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:04:23.643+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:23.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:24.018+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:24.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:24.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:24.075+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:24.075+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:24.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.459 seconds
[2025-01-13T03:04:54.588+0000] {processor.py:186} INFO - Started process (PID=1907) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:54.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:04:54.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:54.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:54.972+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:04:55.029+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:55.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:55.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:55.054+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:55.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-13T03:05:25.431+0000] {processor.py:186} INFO - Started process (PID=1909) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:25.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:05:25.435+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:25.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:25.835+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:25.866+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:25.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:25.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:25.887+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:25.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-13T03:05:56.292+0000] {processor.py:186} INFO - Started process (PID=1911) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:56.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:05:56.296+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:56.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:56.693+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:05:56.723+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:56.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:56.765+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:56.765+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:56.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.505 seconds
[2025-01-13T03:06:27.259+0000] {processor.py:186} INFO - Started process (PID=1913) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:27.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:06:27.263+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:27.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:27.682+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:27.713+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:27.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:27.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:27.734+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:27.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T03:06:58.291+0000] {processor.py:186} INFO - Started process (PID=1915) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:58.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:06:58.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:58.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:58.663+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:06:58.694+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:58.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:58.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:58.716+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:59.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.534 seconds
[2025-01-13T03:07:30.128+0000] {processor.py:186} INFO - Started process (PID=1917) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:07:30.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:07:30.133+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:30.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:07:30.549+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:07:30.585+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:30.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:07:30.607+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:30.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:07:30.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T03:08:01.085+0000] {processor.py:186} INFO - Started process (PID=1919) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:01.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:08:01.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:01.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:01.474+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:01.523+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:01.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:01.567+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:01.567+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:01.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-13T03:08:32.121+0000] {processor.py:186} INFO - Started process (PID=1921) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:32.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:08:32.125+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:32.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:32.548+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:08:32.594+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:32.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:32.629+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:32.629+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:32.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.542 seconds
[2025-01-13T03:09:03.159+0000] {processor.py:186} INFO - Started process (PID=1923) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:03.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:09:03.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:03.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:03.542+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:03.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:03.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:03.599+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:03.599+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:03.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.479 seconds
[2025-01-13T03:09:34.074+0000] {processor.py:186} INFO - Started process (PID=1925) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:34.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:09:34.081+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:34.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:34.528+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:09:34.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:34.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:34.597+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:34.597+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:34.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.900 seconds
[2025-01-13T03:10:05.462+0000] {processor.py:186} INFO - Started process (PID=1927) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:05.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:10:05.467+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:05.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:05.869+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:05.912+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:05.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:05.935+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:05.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:05.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T03:10:36.447+0000] {processor.py:186} INFO - Started process (PID=1929) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:36.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:10:36.451+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:36.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:36.896+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:10:37.035+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:37.034+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:37.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:37.062+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:37.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.651 seconds
[2025-01-13T03:11:07.391+0000] {processor.py:186} INFO - Started process (PID=1931) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:07.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:11:07.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:07.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:07.771+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:07.805+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:07.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:07.826+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:07.826+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:07.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.472 seconds
[2025-01-13T03:11:38.321+0000] {processor.py:186} INFO - Started process (PID=1933) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:38.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:11:38.326+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:38.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:38.727+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:11:38.773+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:38.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:38.797+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:38.797+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:38.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-13T03:12:09.218+0000] {processor.py:186} INFO - Started process (PID=1935) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:09.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:12:09.221+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:09.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:09.653+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:09.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:09.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:09.718+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:09.718+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:10.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-13T03:12:40.521+0000] {processor.py:186} INFO - Started process (PID=1937) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:40.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:12:40.526+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:40.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:40.924+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:12:40.959+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:40.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:40.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:40.998+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:41.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T03:13:11.475+0000] {processor.py:186} INFO - Started process (PID=1939) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:11.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:13:11.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:11.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:11.876+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:11.913+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:11.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:13:11.935+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:11.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:13:11.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.488 seconds
[2025-01-13T03:13:42.437+0000] {processor.py:186} INFO - Started process (PID=1941) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:42.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:13:42.441+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:42.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:42.815+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:13:42.869+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:42.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:13:42.891+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:42.891+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:13:42.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-13T03:14:13.304+0000] {processor.py:186} INFO - Started process (PID=1943) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:13.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:14:13.316+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:13.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:13.705+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:13.738+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:13.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:13.760+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:13.760+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:13.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.490 seconds
[2025-01-13T03:14:44.299+0000] {processor.py:186} INFO - Started process (PID=1945) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:44.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:14:44.311+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:44.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:44.826+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:14:44.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:44.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:44.897+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:44.896+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:45.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.900 seconds
[2025-01-13T03:15:15.696+0000] {processor.py:186} INFO - Started process (PID=1947) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:15.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:15:15.706+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:15.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:16.105+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:16.159+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:16.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:16.181+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:16.181+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:16.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T03:15:46.506+0000] {processor.py:186} INFO - Started process (PID=1949) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:46.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:15:46.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:46.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:46.907+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:15:46.943+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:46.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:46.974+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:46.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:46.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-13T03:16:17.444+0000] {processor.py:186} INFO - Started process (PID=1951) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:17.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:16:17.448+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:17.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:17.828+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:17.862+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:17.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:17.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:17.883+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:17.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.467 seconds
[2025-01-13T03:16:48.373+0000] {processor.py:186} INFO - Started process (PID=1953) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:48.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:16:48.378+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:48.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:48.773+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:16:48.810+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:48.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:48.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:48.842+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:48.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T03:17:19.445+0000] {processor.py:186} INFO - Started process (PID=1955) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:19.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:17:19.451+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:19.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:19.856+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:19.908+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:19.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:19.934+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:19.934+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:20.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.833 seconds
[2025-01-13T03:17:50.739+0000] {processor.py:186} INFO - Started process (PID=1957) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:50.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:17:50.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:50.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:51.197+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:17:51.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:51.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:51.278+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:51.277+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:51.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.573 seconds
[2025-01-13T03:18:21.821+0000] {processor.py:186} INFO - Started process (PID=1959) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:21.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:18:21.825+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:21.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:22.186+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:22.227+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:22.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:22.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:22.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:22.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.462 seconds
[2025-01-13T03:18:52.732+0000] {processor.py:186} INFO - Started process (PID=1961) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:52.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:18:52.736+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:52.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:53.106+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:18:53.140+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:53.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:53.175+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:53.174+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:53.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.472 seconds
[2025-01-13T03:19:23.651+0000] {processor.py:186} INFO - Started process (PID=1963) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:23.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:19:23.657+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:23.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:24.071+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:24.119+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:24.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:24.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:24.140+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:24.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.536 seconds
[2025-01-13T03:19:54.614+0000] {processor.py:186} INFO - Started process (PID=1965) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:54.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:19:54.617+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:54.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:55.028+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:19:55.058+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:55.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:55.088+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:55.088+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:55.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T03:20:25.836+0000] {processor.py:186} INFO - Started process (PID=1967) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:25.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:20:25.839+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:25.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:26.241+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:26.276+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:26.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:20:26.299+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:26.299+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:20:26.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.488 seconds
[2025-01-13T03:20:56.917+0000] {processor.py:186} INFO - Started process (PID=1969) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:56.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:20:56.921+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:56.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:57.333+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:20:57.368+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:57.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:20:57.400+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:20:57.400+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:20:57.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.516 seconds
[2025-01-13T03:21:27.850+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:27.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:21:27.854+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:27.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:28.248+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:28.280+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:28.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:21:28.301+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:28.300+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:21:28.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.480 seconds
[2025-01-13T03:21:58.764+0000] {processor.py:186} INFO - Started process (PID=1973) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:58.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:21:58.768+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:58.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:59.157+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:21:59.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:59.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:21:59.230+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:21:59.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:21:59.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.500 seconds
[2025-01-13T03:22:29.686+0000] {processor.py:186} INFO - Started process (PID=1975) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:22:29.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:22:29.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:22:29.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:22:30.096+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:22:30.128+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:22:30.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:22:30.150+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:22:30.150+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:22:30.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.729 seconds
[2025-01-13T03:23:00.887+0000] {processor.py:186} INFO - Started process (PID=1977) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:00.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:23:00.892+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:00.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:01.310+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:01.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:01.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:23:01.371+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:01.370+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:23:01.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T03:23:31.631+0000] {processor.py:186} INFO - Started process (PID=1979) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:31.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:23:31.636+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:31.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:32.022+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:23:32.073+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:32.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:23:32.096+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:23:32.095+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:23:32.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T03:24:02.534+0000] {processor.py:186} INFO - Started process (PID=1981) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:02.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:24:02.538+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:02.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:03.011+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:03.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:03.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:24:03.088+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:03.088+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:24:03.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.583 seconds
[2025-01-13T03:24:33.620+0000] {processor.py:186} INFO - Started process (PID=1983) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:33.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:24:33.624+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:33.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:33.983+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:24:34.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:34.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:24:34.055+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:24:34.055+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:24:34.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.466 seconds
[2025-01-13T03:25:04.503+0000] {processor.py:186} INFO - Started process (PID=1985) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:04.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:25:04.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:04.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:04.886+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:04.934+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:04.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:25:04.958+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:04.958+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:25:05.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T03:25:35.550+0000] {processor.py:186} INFO - Started process (PID=1987) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:35.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:25:35.576+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:35.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:35.949+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:25:35.995+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:35.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:25:36.017+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:25:36.017+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:25:36.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-13T03:26:06.428+0000] {processor.py:186} INFO - Started process (PID=1989) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:06.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:26:06.432+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:06.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:06.856+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:06.889+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:06.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:26:06.929+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:06.929+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:26:06.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.530 seconds
[2025-01-13T03:26:37.436+0000] {processor.py:186} INFO - Started process (PID=1991) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:37.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:26:37.440+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:37.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:37.852+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:26:37.886+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:37.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:26:37.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:26:37.907+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:26:37.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-13T03:27:08.196+0000] {processor.py:186} INFO - Started process (PID=1993) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:08.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:27:08.201+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:08.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:08.626+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:08.657+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:08.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:27:08.679+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:08.678+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:27:08.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.514 seconds
[2025-01-13T03:27:38.807+0000] {processor.py:186} INFO - Started process (PID=1995) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:38.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:27:38.820+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:38.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:39.252+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:27:39.286+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:39.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:27:39.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:27:39.322+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:27:39.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.805 seconds
[2025-01-13T03:28:10.053+0000] {processor.py:186} INFO - Started process (PID=1997) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:10.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:28:10.058+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:10.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:10.461+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:10.511+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:10.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:28:10.751+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:10.751+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:28:10.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T03:28:40.861+0000] {processor.py:186} INFO - Started process (PID=1999) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:40.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:28:40.864+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:40.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:41.252+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:28:41.286+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:41.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:28:41.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:28:41.308+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:28:41.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.474 seconds
[2025-01-13T03:29:11.678+0000] {processor.py:186} INFO - Started process (PID=2001) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:11.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:29:11.682+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:11.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:12.104+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:12.138+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:12.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:29:12.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:12.172+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:29:12.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T03:29:42.613+0000] {processor.py:186} INFO - Started process (PID=2003) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:42.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:29:42.621+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:42.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:43.046+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:29:43.093+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:43.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:29:43.116+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:29:43.115+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:29:43.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.540 seconds
[2025-01-13T03:30:13.501+0000] {processor.py:186} INFO - Started process (PID=2005) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:13.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:30:13.504+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:13.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:13.913+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:13.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:13.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:30:13.966+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:13.965+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:30:14.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.735 seconds
[2025-01-13T03:30:44.715+0000] {processor.py:186} INFO - Started process (PID=2007) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:44.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:30:44.719+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:44.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:45.114+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:30:45.147+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:45.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:30:45.423+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:30:45.423+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:30:45.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.766 seconds
[2025-01-13T03:31:15.933+0000] {processor.py:186} INFO - Started process (PID=2009) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:15.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:31:15.939+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:15.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:16.361+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:16.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:16.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:31:16.433+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:16.433+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:31:16.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.547 seconds
[2025-01-13T03:31:46.745+0000] {processor.py:186} INFO - Started process (PID=2011) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:46.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:31:46.748+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:46.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:47.156+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:31:47.193+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:47.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:31:47.216+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:31:47.216+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:31:47.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.498 seconds
[2025-01-13T03:32:17.727+0000] {processor.py:186} INFO - Started process (PID=2013) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:17.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:32:17.732+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:17.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:18.147+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:18.197+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:18.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:32:18.220+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:18.220+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:32:18.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T03:32:48.663+0000] {processor.py:186} INFO - Started process (PID=2015) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:48.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:32:48.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:48.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:49.066+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:32:49.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:49.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:32:49.135+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:32:49.134+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:32:49.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.873 seconds
[2025-01-13T03:33:20.006+0000] {processor.py:186} INFO - Started process (PID=2017) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:20.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:33:20.011+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:20.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:20.398+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:20.450+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:20.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:33:20.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:20.717+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:33:20.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.755 seconds
[2025-01-13T03:33:51.203+0000] {processor.py:186} INFO - Started process (PID=2019) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:51.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:33:51.211+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:51.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:51.617+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:33:51.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:51.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:33:51.679+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:33:51.678+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:33:51.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-13T03:34:21.848+0000] {processor.py:186} INFO - Started process (PID=2021) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:21.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:34:21.854+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:21.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:22.259+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:22.294+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:22.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:34:22.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:22.316+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:34:22.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-13T03:34:52.829+0000] {processor.py:186} INFO - Started process (PID=2023) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:52.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:34:52.836+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:52.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:53.254+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:34:53.299+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:53.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:34:53.325+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:34:53.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:34:53.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T03:35:23.883+0000] {processor.py:186} INFO - Started process (PID=2025) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:23.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:35:23.889+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:23.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:24.286+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:24.332+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:24.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:35:24.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:24.355+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:35:24.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.758 seconds
[2025-01-13T03:35:55.082+0000] {processor.py:186} INFO - Started process (PID=2027) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:55.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:35:55.087+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:55.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:55.464+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:35:55.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:55.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:35:55.773+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:35:55.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:35:55.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T03:36:26.108+0000] {processor.py:186} INFO - Started process (PID=2029) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:26.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:36:26.120+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:26.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:26.507+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:26.560+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:26.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:36:26.584+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:26.584+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:36:26.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-13T03:36:57.011+0000] {processor.py:186} INFO - Started process (PID=2031) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:57.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:36:57.015+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:57.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:57.390+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:36:57.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:57.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:36:57.443+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:36:57.443+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:36:57.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.490 seconds
[2025-01-13T03:37:27.895+0000] {processor.py:186} INFO - Started process (PID=2033) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:27.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:37:27.900+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:27.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:28.318+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:28.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:28.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:37:28.368+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:28.368+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:37:28.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-13T03:37:58.801+0000] {processor.py:186} INFO - Started process (PID=2035) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:58.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:37:58.807+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:58.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:59.194+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:37:59.226+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:59.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:37:59.248+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:37:59.248+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:37:59.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.739 seconds
[2025-01-13T03:38:29.979+0000] {processor.py:186} INFO - Started process (PID=2037) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:38:29.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:38:29.985+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:38:29.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:38:30.389+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:38:30.422+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:38:30.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:38:30.832+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:38:30.832+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:38:30.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.891 seconds
[2025-01-13T03:39:01.316+0000] {processor.py:186} INFO - Started process (PID=2039) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:01.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:39:01.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:01.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:01.696+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:01.728+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:01.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:39:01.764+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:01.764+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:39:01.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T03:39:31.961+0000] {processor.py:186} INFO - Started process (PID=2041) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:31.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:39:31.966+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:31.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:32.348+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:39:32.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:32.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:39:32.406+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:39:32.406+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:39:32.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T03:40:02.629+0000] {processor.py:186} INFO - Started process (PID=2043) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:02.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:40:02.633+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:02.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:03.039+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:03.082+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:03.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:40:03.103+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:03.102+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:40:03.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.497 seconds
[2025-01-13T03:40:33.555+0000] {processor.py:186} INFO - Started process (PID=2045) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:33.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:40:33.560+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:33.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:33.949+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:40:33.992+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:33.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:40:34.019+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:40:34.018+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:40:34.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.755 seconds
[2025-01-13T03:41:04.616+0000] {processor.py:186} INFO - Started process (PID=2047) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:04.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:41:04.624+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:04.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:05.023+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:05.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:05.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:41:05.311+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:05.311+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:41:05.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.751 seconds
[2025-01-13T03:41:35.803+0000] {processor.py:186} INFO - Started process (PID=2049) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:35.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:41:35.809+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:35.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:36.228+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:41:36.263+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:36.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:41:36.285+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:41:36.285+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:41:36.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.533 seconds
[2025-01-13T03:42:06.524+0000] {processor.py:186} INFO - Started process (PID=2051) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:06.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:42:06.531+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:06.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:06.943+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:06.976+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:06.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:42:06.997+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:06.997+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:42:07.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.541 seconds
[2025-01-13T03:42:37.165+0000] {processor.py:186} INFO - Started process (PID=2053) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:37.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:42:37.170+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:37.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:37.561+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:42:37.597+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:37.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:42:37.620+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:42:37.620+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:42:37.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.484 seconds
[2025-01-13T03:43:07.881+0000] {processor.py:186} INFO - Started process (PID=2055) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:07.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:43:07.886+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:07.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:08.283+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:08.313+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:08.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:43:08.333+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:08.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:43:08.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T03:43:38.980+0000] {processor.py:186} INFO - Started process (PID=2057) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:38.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:43:38.990+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:38.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:39.430+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:43:39.470+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:39.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:43:39.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:43:39.691+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:43:39.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.741 seconds
[2025-01-13T03:44:09.829+0000] {processor.py:186} INFO - Started process (PID=2059) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:09.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:44:09.851+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:09.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:10.215+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:10.244+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:10.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:44:10.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:10.493+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:44:10.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.693 seconds
[2025-01-13T03:44:40.962+0000] {processor.py:186} INFO - Started process (PID=2061) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:40.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:44:40.967+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:40.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:41.376+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:44:41.415+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:41.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:44:41.436+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:44:41.436+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:44:41.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.505 seconds
[2025-01-13T03:45:11.885+0000] {processor.py:186} INFO - Started process (PID=2063) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:11.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:45:11.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:11.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:12.256+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:12.296+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:12.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:45:12.319+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:12.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:45:12.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.463 seconds
[2025-01-13T03:45:42.963+0000] {processor.py:186} INFO - Started process (PID=2065) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:42.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:45:42.968+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:42.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:43.338+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:45:43.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:43.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:45:43.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:45:43.394+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:45:43.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.684 seconds
[2025-01-13T03:46:14.132+0000] {processor.py:186} INFO - Started process (PID=2067) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:14.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:46:14.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:14.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:14.554+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:14.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:14.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:46:14.886+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:14.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:46:14.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.786 seconds
[2025-01-13T03:46:45.397+0000] {processor.py:186} INFO - Started process (PID=2069) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:45.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:46:45.402+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:45.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:45.799+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:46:45.845+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:45.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:46:46.094+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:46:46.093+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:46:46.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T03:47:16.581+0000] {processor.py:186} INFO - Started process (PID=2071) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:16.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:47:16.587+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:16.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:16.954+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:16.986+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:16.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:47:17.012+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:17.012+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:47:17.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.471 seconds
[2025-01-13T03:47:47.507+0000] {processor.py:186} INFO - Started process (PID=2073) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:47.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:47:47.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:47.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:47.981+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:47:48.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:48.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:47:48.045+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:47:48.045+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:47:48.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.587 seconds
[2025-01-13T03:48:18.589+0000] {processor.py:186} INFO - Started process (PID=2075) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:18.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:48:18.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:18.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:18.982+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:19.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:19.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:48:19.053+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:19.053+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:48:19.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T03:48:49.809+0000] {processor.py:186} INFO - Started process (PID=2077) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:49.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:48:49.813+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:49.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:50.256+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:48:50.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:50.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:48:50.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:48:50.583+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:48:50.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.823 seconds
[2025-01-13T03:49:20.723+0000] {processor.py:186} INFO - Started process (PID=2079) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:20.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:49:20.727+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:20.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:21.124+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:21.167+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:21.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:49:21.424+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:21.423+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:49:21.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.729 seconds
[2025-01-13T03:49:52.016+0000] {processor.py:186} INFO - Started process (PID=2081) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:52.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:49:52.020+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:52.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:52.461+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:49:52.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:52.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:49:52.545+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:49:52.545+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:49:52.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.561 seconds
[2025-01-13T03:50:26.093+0000] {processor.py:186} INFO - Started process (PID=2083) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:50:26.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:50:26.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:50:26.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:50:28.155+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:50:28.539+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:50:28.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:50:28.596+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:50:28.596+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:50:28.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.579 seconds
[2025-01-13T03:50:59.510+0000] {processor.py:186} INFO - Started process (PID=2085) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:50:59.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:50:59.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:50:59.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:51:00.117+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:51:00.183+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:51:00.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:51:00.220+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:51:00.220+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:51:00.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.480 seconds
[2025-01-13T03:51:31.567+0000] {processor.py:186} INFO - Started process (PID=2087) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:51:31.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:51:31.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:51:31.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:51:32.049+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:51:32.105+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:51:32.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:51:32.827+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:51:32.826+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:51:32.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.305 seconds
[2025-01-13T03:52:03.068+0000] {processor.py:186} INFO - Started process (PID=2089) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:03.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:52:03.074+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:03.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:03.486+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:03.524+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:03.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:52:03.829+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:03.829+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:52:03.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.794 seconds
[2025-01-13T03:52:34.337+0000] {processor.py:186} INFO - Started process (PID=2091) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:34.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:52:34.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:34.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:34.762+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:52:34.822+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:34.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:52:34.845+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:52:34.844+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:52:34.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.549 seconds
[2025-01-13T03:53:05.211+0000] {processor.py:186} INFO - Started process (PID=2093) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:05.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:53:05.217+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:05.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:05.635+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:05.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:05.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:53:05.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:05.702+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:53:05.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T03:53:36.221+0000] {processor.py:186} INFO - Started process (PID=2095) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:36.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:53:36.226+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:36.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:36.609+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:53:36.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:36.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:53:36.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:53:36.690+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:53:36.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.780 seconds
[2025-01-13T03:54:07.150+0000] {processor.py:186} INFO - Started process (PID=2097) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:07.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:54:07.155+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:07.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:07.554+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:07.586+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:07.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:54:07.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:07.862+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:54:07.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.744 seconds
[2025-01-13T03:54:38.454+0000] {processor.py:186} INFO - Started process (PID=2099) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:38.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:54:38.459+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:38.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:38.879+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:54:38.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:38.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:54:39.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:54:39.188+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:54:39.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-13T03:55:09.386+0000] {processor.py:186} INFO - Started process (PID=2101) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:09.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:55:09.391+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:09.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:10.014+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:10.061+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:10.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:55:10.087+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:10.086+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:55:10.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.731 seconds
[2025-01-13T03:55:40.797+0000] {processor.py:186} INFO - Started process (PID=2103) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:40.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:55:40.803+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:40.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:41.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:55:41.245+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:41.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:55:41.276+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:55:41.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:55:41.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T03:56:11.672+0000] {processor.py:186} INFO - Started process (PID=2105) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:11.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:56:11.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:11.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:12.066+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:12.117+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:12.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:56:12.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:12.141+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:56:12.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.771 seconds
[2025-01-13T03:56:42.748+0000] {processor.py:186} INFO - Started process (PID=2107) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:42.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:56:42.755+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:42.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:43.165+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:56:43.200+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:43.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:56:43.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:56:43.455+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:56:43.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T03:57:13.912+0000] {processor.py:186} INFO - Started process (PID=2109) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:13.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:57:13.916+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:13.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:14.303+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:14.334+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:14.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:57:14.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:14.635+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:57:14.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.745 seconds
[2025-01-13T03:57:44.852+0000] {processor.py:186} INFO - Started process (PID=2111) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:44.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:57:44.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:44.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:45.716+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:57:46.104+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:46.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:57:46.122+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:57:46.122+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:57:46.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.298 seconds
[2025-01-13T03:58:16.338+0000] {processor.py:186} INFO - Started process (PID=2113) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:16.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:58:16.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:16.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:16.737+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:16.774+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:16.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:58:16.808+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:16.808+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:58:16.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.515 seconds
[2025-01-13T03:58:47.123+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:47.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:58:47.127+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:47.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:47.535+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:58:47.587+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:47.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:58:47.609+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:58:47.609+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:58:47.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.760 seconds
[2025-01-13T03:59:18.355+0000] {processor.py:186} INFO - Started process (PID=2117) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:18.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:59:18.367+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:18.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:18.760+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:18.799+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:18.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:59:19.075+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:19.075+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:59:19.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.758 seconds
[2025-01-13T03:59:49.559+0000] {processor.py:186} INFO - Started process (PID=2119) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:49.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T03:59:49.565+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:49.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:49.996+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T03:59:50.028+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:50.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:59:50.302+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:59:50.302+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:59:50.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.770 seconds
[2025-01-13T04:00:20.812+0000] {processor.py:186} INFO - Started process (PID=2121) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:20.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:00:20.818+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:20.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:21.235+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:21.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:21.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:00:21.535+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:21.535+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:00:21.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-13T04:00:51.720+0000] {processor.py:186} INFO - Started process (PID=2123) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:51.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:00:51.726+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:51.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:52.157+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:00:52.203+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:52.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:00:52.250+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:00:52.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:00:52.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.585 seconds
[2025-01-13T04:01:22.748+0000] {processor.py:186} INFO - Started process (PID=2125) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:22.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:01:22.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:22.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:23.128+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:23.175+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:23.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:01:23.198+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:23.198+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:01:23.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.820 seconds
[2025-01-13T04:01:54.011+0000] {processor.py:186} INFO - Started process (PID=2127) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:54.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:01:54.016+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:54.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:54.390+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:01:54.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:54.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:01:54.722+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:01:54.722+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:01:54.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.774 seconds
[2025-01-13T04:02:24.981+0000] {processor.py:186} INFO - Started process (PID=2129) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:24.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:02:24.996+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:24.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:25.369+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:25.418+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:25.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:02:25.692+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:25.692+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:02:25.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.748 seconds
[2025-01-13T04:02:56.224+0000] {processor.py:186} INFO - Started process (PID=2131) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:56.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:02:56.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:56.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:56.653+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:02:56.909+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:56.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:02:56.926+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:02:56.926+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:02:56.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.730 seconds
[2025-01-13T04:03:27.423+0000] {processor.py:186} INFO - Started process (PID=2133) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:27.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:03:27.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:27.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:27.855+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:27.895+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:27.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:03:27.919+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:27.919+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:03:27.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.543 seconds
[2025-01-13T04:03:58.208+0000] {processor.py:186} INFO - Started process (PID=2135) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:58.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:03:58.212+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:58.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:58.613+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:03:58.644+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:58.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:03:58.682+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:03:58.682+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:03:58.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.804 seconds
[2025-01-13T04:04:29.531+0000] {processor.py:186} INFO - Started process (PID=2137) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:04:29.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:04:29.540+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:04:29.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:04:31.492+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:04:31.572+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:04:31.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:04:31.962+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:04:31.961+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:04:31.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.509 seconds
[2025-01-13T04:05:02.371+0000] {processor.py:186} INFO - Started process (PID=2139) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:02.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:05:02.376+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:02.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:02.769+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:02.800+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:02.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:05:03.093+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:03.093+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:05:03.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T04:05:33.630+0000] {processor.py:186} INFO - Started process (PID=2141) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:33.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:05:33.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:33.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:34.207+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:05:34.618+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:34.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:05:34.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:05:34.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:05:34.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.082 seconds
[2025-01-13T04:06:05.033+0000] {processor.py:186} INFO - Started process (PID=2143) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:05.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:06:05.037+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:05.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:05.444+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:05.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:05.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:06:05.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:05.511+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:06:05.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.509 seconds
[2025-01-13T04:06:36.099+0000] {processor.py:186} INFO - Started process (PID=2145) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:36.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:06:36.104+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:36.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:36.494+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:06:36.542+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:36.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:06:36.564+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:06:36.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:06:36.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.753 seconds
[2025-01-13T04:07:07.242+0000] {processor.py:186} INFO - Started process (PID=2147) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:07.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:07:07.247+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:07.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:07.644+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:07.676+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:07.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:07:07.956+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:07.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:07:07.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.744 seconds
[2025-01-13T04:07:38.305+0000] {processor.py:186} INFO - Started process (PID=2149) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:38.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:07:38.309+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:38.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:38.759+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:07:38.814+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:38.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:07:39.134+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:07:39.134+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:07:39.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.856 seconds
[2025-01-13T04:08:09.738+0000] {processor.py:186} INFO - Started process (PID=2151) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:09.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:08:09.742+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:09.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:10.114+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:10.409+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:10.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:08:10.435+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:10.435+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:08:10.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.735 seconds
[2025-01-13T04:08:41.071+0000] {processor.py:186} INFO - Started process (PID=2153) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:41.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:08:41.075+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:41.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:41.450+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:08:41.497+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:41.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:08:41.520+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:08:41.520+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:08:41.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T04:09:11.981+0000] {processor.py:186} INFO - Started process (PID=2155) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:11.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:09:11.985+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:11.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:12.385+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:12.468+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:12.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:09:12.496+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:12.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:09:12.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-13T04:09:42.977+0000] {processor.py:186} INFO - Started process (PID=2157) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:42.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:09:42.982+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:42.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:43.377+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:09:43.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:43.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:09:43.681+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:09:43.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:09:43.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.734 seconds
[2025-01-13T04:10:14.227+0000] {processor.py:186} INFO - Started process (PID=2159) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:14.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:10:14.232+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:14.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:14.617+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:14.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:14.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:10:14.928+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:14.928+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:10:14.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.735 seconds
[2025-01-13T04:10:45.269+0000] {processor.py:186} INFO - Started process (PID=2161) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:45.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:10:45.273+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:45.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:45.668+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:10:45.993+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:45.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:10:46.010+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:10:46.009+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:10:46.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.770 seconds
[2025-01-13T04:11:16.944+0000] {processor.py:186} INFO - Started process (PID=2163) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:11:16.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:11:16.949+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:11:16.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:11:17.501+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:11:17.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:11:17.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:11:17.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:11:17.610+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:11:17.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.715 seconds
[2025-01-13T04:55:41.438+0000] {processor.py:186} INFO - Started process (PID=2165) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:55:41.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:55:41.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:55:41.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:55:41.868+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:55:41.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:55:41.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:55:41.928+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:55:41.928+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:55:41.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T04:56:12.893+0000] {processor.py:186} INFO - Started process (PID=2167) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:12.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:56:12.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:12.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:13.305+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:13.341+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:13.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:56:13.367+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:13.367+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:56:13.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.975 seconds
[2025-01-13T04:56:44.429+0000] {processor.py:186} INFO - Started process (PID=2169) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:44.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:56:44.433+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:44.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:44.850+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:56:44.886+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:44.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:56:45.162+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:56:45.162+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:56:45.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.760 seconds
[2025-01-13T04:57:16.191+0000] {processor.py:186} INFO - Started process (PID=2171) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:16.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:57:16.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:16.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:16.612+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:16.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:16.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:57:16.973+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:16.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:57:16.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.810 seconds
[2025-01-13T04:57:47.597+0000] {processor.py:186} INFO - Started process (PID=2173) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:47.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:57:47.612+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:47.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:48.258+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:57:48.566+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:48.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:57:48.585+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:57:48.585+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:57:48.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.036 seconds
[2025-01-13T04:58:19.148+0000] {processor.py:186} INFO - Started process (PID=2175) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:19.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:58:19.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:19.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:19.520+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:19.551+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:19.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:58:19.572+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:19.572+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:58:19.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.469 seconds
[2025-01-13T04:58:50.158+0000] {processor.py:186} INFO - Started process (PID=2177) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:50.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:58:50.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:50.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:50.605+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:58:50.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:50.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:58:50.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:58:50.677+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:58:50.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.787 seconds
[2025-01-13T04:59:21.430+0000] {processor.py:186} INFO - Started process (PID=2179) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:21.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:59:21.434+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:21.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:21.804+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:21.837+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:21.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:59:22.149+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:22.149+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:59:22.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.746 seconds
[2025-01-13T04:59:52.286+0000] {processor.py:186} INFO - Started process (PID=2181) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:52.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T04:59:52.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:52.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:52.712+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T04:59:52.761+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:52.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T04:59:53.016+0000] {logging_mixin.py:190} INFO - [2025-01-13T04:59:53.016+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T04:59:53.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.759 seconds
[2025-01-13T05:00:23.586+0000] {processor.py:186} INFO - Started process (PID=2183) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:23.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:00:23.602+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:23.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:24.074+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:24.334+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:24.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:00:24.351+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:24.351+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:00:24.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.796 seconds
[2025-01-13T05:00:54.452+0000] {processor.py:186} INFO - Started process (PID=2185) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:54.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:00:54.457+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:54.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:55.108+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:00:55.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:55.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:00:55.187+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:00:55.187+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:00:55.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T05:01:25.399+0000] {processor.py:186} INFO - Started process (PID=2187) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:25.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:01:25.403+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:25.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:25.786+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:25.817+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:25.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:01:25.838+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:25.838+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:01:26.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.711 seconds
[2025-01-13T05:01:57.052+0000] {processor.py:186} INFO - Started process (PID=2189) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:57.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:01:57.056+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:57.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:57.454+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:01:57.491+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:57.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:01:57.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:01:57.788+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:01:57.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.785 seconds
[2025-01-13T05:02:28.347+0000] {processor.py:186} INFO - Started process (PID=2191) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:02:28.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:02:28.351+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:02:28.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:02:28.734+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:02:28.765+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:02:28.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:02:29.023+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:02:29.022+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:02:29.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T05:02:59.635+0000] {processor.py:186} INFO - Started process (PID=2193) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:02:59.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:02:59.639+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:02:59.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:03:00.059+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:03:00.335+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:03:00.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:03:00.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:03:00.351+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:03:00.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T05:03:30.865+0000] {processor.py:186} INFO - Started process (PID=2195) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:03:30.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:03:30.870+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:03:30.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:03:31.320+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:03:31.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:03:31.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:03:31.394+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:03:31.394+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:03:31.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.562 seconds
[2025-01-13T05:04:02.046+0000] {processor.py:186} INFO - Started process (PID=2197) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:02.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:04:02.049+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:02.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:02.517+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:02.552+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:02.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:04:02.573+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:02.573+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:04:02.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.892 seconds
[2025-01-13T05:04:33.567+0000] {processor.py:186} INFO - Started process (PID=2199) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:33.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:04:33.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:33.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:34.078+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:04:34.125+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:34.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:04:34.422+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:04:34.421+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:04:34.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.888 seconds
[2025-01-13T05:05:04.997+0000] {processor.py:186} INFO - Started process (PID=2201) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:04.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:05:05.000+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:04.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:05.438+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:05.473+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:05.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:05:05.737+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:05.736+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:05:05.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.764 seconds
[2025-01-13T05:05:36.294+0000] {processor.py:186} INFO - Started process (PID=2203) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:36.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:05:36.302+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:36.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:36.719+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:05:36.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:36.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:05:36.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:05:36.997+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:05:37.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.737 seconds
[2025-01-13T05:06:07.511+0000] {processor.py:186} INFO - Started process (PID=2205) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:07.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:06:07.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:07.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:08.108+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:08.239+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:08.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:06:08.262+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:08.262+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:06:08.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.783 seconds
[2025-01-13T05:06:38.795+0000] {processor.py:186} INFO - Started process (PID=2207) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:38.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:06:38.800+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:38.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:39.203+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:06:39.240+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:39.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:06:39.276+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:06:39.276+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:06:39.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.798 seconds
[2025-01-13T05:07:10.075+0000] {processor.py:186} INFO - Started process (PID=2209) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:10.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:07:10.081+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:10.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:10.477+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:10.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:10.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:07:10.859+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:10.859+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:07:10.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-13T05:07:41.328+0000] {processor.py:186} INFO - Started process (PID=2211) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:41.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:07:41.333+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:41.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:41.876+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:07:41.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:41.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:07:42.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:07:42.348+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:07:42.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.068 seconds
[2025-01-13T05:08:12.811+0000] {processor.py:186} INFO - Started process (PID=2213) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:12.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:08:12.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:12.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:13.214+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:13.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:13.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:08:13.511+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:13.511+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:08:13.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.729 seconds
[2025-01-13T05:08:44.067+0000] {processor.py:186} INFO - Started process (PID=2215) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:44.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:08:44.074+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:44.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:44.730+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:08:44.817+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:44.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:08:44.870+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:08:44.869+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:08:44.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-13T05:09:15.391+0000] {processor.py:186} INFO - Started process (PID=2217) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:15.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:09:15.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:15.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:15.803+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:15.850+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:15.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:09:15.875+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:15.875+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:09:16.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.807 seconds
[2025-01-13T05:09:46.817+0000] {processor.py:186} INFO - Started process (PID=2219) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:46.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:09:46.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:46.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:47.278+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:09:47.332+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:47.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:09:47.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:09:47.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:09:47.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.876 seconds
[2025-01-13T05:10:18.269+0000] {processor.py:186} INFO - Started process (PID=2221) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:18.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:10:18.274+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:18.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:18.675+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:18.707+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:18.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:10:18.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:18.979+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:10:19.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T05:10:49.549+0000] {processor.py:186} INFO - Started process (PID=2223) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:49.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:10:49.556+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:49.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:49.944+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:10:50.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:50.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:10:50.268+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:10:50.267+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:10:50.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.756 seconds
[2025-01-13T05:11:20.825+0000] {processor.py:186} INFO - Started process (PID=2225) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:20.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:11:20.828+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:20.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:21.477+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:21.504+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:21.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:11:21.521+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:21.521+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:11:21.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.728 seconds
[2025-01-13T05:11:51.667+0000] {processor.py:186} INFO - Started process (PID=2227) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:51.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:11:51.673+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:51.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:52.256+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:11:52.310+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:52.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:11:52.337+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:11:52.337+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:11:52.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.090 seconds
[2025-01-13T05:12:23.177+0000] {processor.py:186} INFO - Started process (PID=2229) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:23.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:12:23.181+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:23.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:23.583+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:23.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:23.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:12:23.986+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:23.985+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:12:24.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.857 seconds
[2025-01-13T05:12:54.497+0000] {processor.py:186} INFO - Started process (PID=2231) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:54.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:12:54.539+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:54.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:54.968+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:12:55.007+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:55.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:12:55.304+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:12:55.304+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:12:55.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.857 seconds
[2025-01-13T05:13:25.757+0000] {processor.py:186} INFO - Started process (PID=2233) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:25.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:13:25.762+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:25.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:26.173+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:26.493+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:26.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:13:26.521+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:26.520+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:13:26.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.794 seconds
[2025-01-13T05:13:57.079+0000] {processor.py:186} INFO - Started process (PID=2235) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:57.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:13:57.085+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:57.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:57.757+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:13:57.787+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:57.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:13:57.805+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:13:57.805+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:13:57.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T05:14:28.379+0000] {processor.py:186} INFO - Started process (PID=2237) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:14:28.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:14:28.384+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:14:28.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:14:29.012+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:14:29.075+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:14:29.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:14:29.102+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:14:29.102+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:14:29.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.140 seconds
[2025-01-13T05:15:00.121+0000] {processor.py:186} INFO - Started process (PID=2239) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:00.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:15:00.126+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:00.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:00.552+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:00.602+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:00.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:15:00.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:00.879+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:15:00.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.795 seconds
[2025-01-13T05:15:31.359+0000] {processor.py:186} INFO - Started process (PID=2241) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:31.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:15:31.363+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:31.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:31.784+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:15:31.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:31.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:15:32.123+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:15:32.122+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:15:32.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.818 seconds
[2025-01-13T05:16:02.713+0000] {processor.py:186} INFO - Started process (PID=2243) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:02.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:16:02.718+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:02.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:03.120+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:03.393+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:03.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:16:03.410+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:03.410+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:16:03.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T05:16:34.015+0000] {processor.py:186} INFO - Started process (PID=2245) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:34.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:16:34.020+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:34.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:34.642+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:16:34.668+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:34.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:16:34.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:16:34.687+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:16:34.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.700 seconds
[2025-01-13T05:17:05.258+0000] {processor.py:186} INFO - Started process (PID=2247) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:05.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:17:05.272+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:05.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:05.686+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:05.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:05.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:17:05.785+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:05.784+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:17:06.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.849 seconds
[2025-01-13T05:17:36.206+0000] {processor.py:186} INFO - Started process (PID=2249) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:36.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:17:36.210+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:36.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:36.581+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:17:36.616+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:36.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:17:36.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:17:36.901+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:17:36.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T05:18:07.403+0000] {processor.py:186} INFO - Started process (PID=2251) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:07.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:18:07.418+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:07.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:07.821+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:07.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:07.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:18:08.157+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:08.156+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:18:08.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.783 seconds
[2025-01-13T05:18:38.322+0000] {processor.py:186} INFO - Started process (PID=2253) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:38.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:18:38.327+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:38.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:38.770+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:18:39.072+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:39.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:18:39.090+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:18:39.090+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:18:39.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.800 seconds
[2025-01-13T05:19:09.541+0000] {processor.py:186} INFO - Started process (PID=2255) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:09.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:19:09.545+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:09.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:10.153+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:10.179+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:10.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:19:10.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:10.196+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:19:10.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.688 seconds
[2025-01-13T05:19:40.366+0000] {processor.py:186} INFO - Started process (PID=2257) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:40.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:19:40.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:40.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:41.041+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:19:41.066+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:41.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:19:41.082+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:19:41.081+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:19:41.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.746 seconds
[2025-01-13T05:20:11.570+0000] {processor.py:186} INFO - Started process (PID=2259) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:11.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:20:11.575+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:11.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:11.939+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:11.987+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:11.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:20:12.277+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:12.277+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:20:12.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.739 seconds
[2025-01-13T05:20:42.778+0000] {processor.py:186} INFO - Started process (PID=2261) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:42.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:20:42.782+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:42.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:43.164+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:20:43.197+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:43.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:20:43.493+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:20:43.493+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:20:43.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-13T05:21:13.821+0000] {processor.py:186} INFO - Started process (PID=2263) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:13.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:21:13.829+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:13.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:14.226+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:14.632+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:14.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:21:14.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:14.667+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:21:14.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.930 seconds
[2025-01-13T05:21:45.173+0000] {processor.py:186} INFO - Started process (PID=2265) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:45.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:21:45.177+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:45.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:47.541+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:21:47.627+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:47.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:21:47.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:21:47.651+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:21:47.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.513 seconds
[2025-01-13T05:22:18.237+0000] {processor.py:186} INFO - Started process (PID=2267) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:18.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:22:18.243+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:18.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:18.936+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:18.970+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:18.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:22:18.988+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:18.988+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:22:18.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.785 seconds
[2025-01-13T05:22:49.540+0000] {processor.py:186} INFO - Started process (PID=2269) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:49.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:22:49.544+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:49.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:49.939+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:22:49.996+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:49.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:22:50.288+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:22:50.288+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:22:50.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.798 seconds
[2025-01-13T05:23:20.801+0000] {processor.py:186} INFO - Started process (PID=2271) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:20.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:23:20.804+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:20.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:21.160+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:21.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:21.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:23:21.475+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:21.475+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:23:21.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.706 seconds
[2025-01-13T05:23:52.059+0000] {processor.py:186} INFO - Started process (PID=2273) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:52.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:23:52.064+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:52.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:52.486+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:23:52.805+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:52.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:23:52.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:23:52.823+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:23:52.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.798 seconds
[2025-01-13T05:24:23.459+0000] {processor.py:186} INFO - Started process (PID=2275) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:23.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:24:23.463+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:23.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:24.155+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:24.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:24.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:24:24.219+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:24.219+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:24:24.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.788 seconds
[2025-01-13T05:24:54.720+0000] {processor.py:186} INFO - Started process (PID=2277) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:54.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:24:54.726+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:54.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:55.415+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:24:55.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:55.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:24:55.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:24:55.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:24:55.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.793 seconds
[2025-01-13T05:25:25.935+0000] {processor.py:186} INFO - Started process (PID=2279) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:25.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:25:25.940+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:25.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:26.337+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:26.389+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:26.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:25:26.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:26.670+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:25:26.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.766 seconds
[2025-01-13T05:25:56.882+0000] {processor.py:186} INFO - Started process (PID=2281) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:56.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:25:56.889+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:56.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:57.288+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:25:57.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:57.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:25:57.595+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:25:57.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:25:57.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.743 seconds
[2025-01-13T05:26:28.079+0000] {processor.py:186} INFO - Started process (PID=2283) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:28.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:26:28.085+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:28.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:28.457+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:28.739+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:28.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:26:28.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:28.756+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:26:28.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.722 seconds
[2025-01-13T05:26:59.004+0000] {processor.py:186} INFO - Started process (PID=2285) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:59.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:26:59.009+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:59.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:59.668+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:26:59.695+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:59.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:26:59.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:26:59.712+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:26:59.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.751 seconds
[2025-01-13T05:27:30.232+0000] {processor.py:186} INFO - Started process (PID=2287) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:27:30.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:27:30.238+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:27:30.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:27:30.872+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:27:30.916+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:27:30.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:27:30.932+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:27:30.932+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:27:30.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.740 seconds
[2025-01-13T05:28:01.450+0000] {processor.py:186} INFO - Started process (PID=2289) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:01.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:28:01.454+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:01.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:01.814+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:01.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:01.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:28:02.147+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:02.147+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:28:02.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-13T05:28:32.579+0000] {processor.py:186} INFO - Started process (PID=2291) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:32.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:28:32.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:32.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:32.972+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:28:33.027+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:33.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:28:33.272+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:28:33.271+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:28:33.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.720 seconds
[2025-01-13T05:29:03.581+0000] {processor.py:186} INFO - Started process (PID=2293) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:03.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:29:03.585+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:03.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:03.970+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:04.300+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:04.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:29:04.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:04.317+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:29:04.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-13T05:29:34.693+0000] {processor.py:186} INFO - Started process (PID=2295) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:34.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T05:29:34.711+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:34.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:35.872+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T05:29:35.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:35.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T05:29:35.931+0000] {logging_mixin.py:190} INFO - [2025-01-13T05:29:35.931+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T05:29:35.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.281 seconds
[2025-01-13T06:00:09.906+0000] {processor.py:186} INFO - Started process (PID=2297) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T06:00:09.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T06:00:09.909+0000] {logging_mixin.py:190} INFO - [2025-01-13T06:00:09.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T06:00:10.564+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T06:00:10.588+0000] {logging_mixin.py:190} INFO - [2025-01-13T06:00:10.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T06:00:10.604+0000] {logging_mixin.py:190} INFO - [2025-01-13T06:00:10.604+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T06:00:10.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.728 seconds
[2025-01-13T08:35:36.413+0000] {processor.py:186} INFO - Started process (PID=2299) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T08:35:36.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T08:35:36.416+0000] {logging_mixin.py:190} INFO - [2025-01-13T08:35:36.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T08:35:37.089+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T08:35:37.111+0000] {logging_mixin.py:190} INFO - [2025-01-13T08:35:37.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T08:35:37.129+0000] {logging_mixin.py:190} INFO - [2025-01-13T08:35:37.129+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T08:35:37.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.740 seconds
[2025-01-13T12:32:55.045+0000] {processor.py:186} INFO - Started process (PID=2301) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T12:32:55.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T12:32:55.049+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:55.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T12:32:55.438+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T12:32:55.466+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:55.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:32:55.769+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:55.768+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:32:55.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.749 seconds
[2025-01-13T15:00:03.472+0000] {processor.py:186} INFO - Started process (PID=2303) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:00:03.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:00:03.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:00:03.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:00:03.880+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:00:04.214+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:00:04.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:00:04.232+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:00:04.231+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:00:04.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.793 seconds
[2025-01-13T15:34:11.849+0000] {processor.py:186} INFO - Started process (PID=2305) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:11.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:34:11.854+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:11.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:12.214+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:12.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:12.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:34:12.500+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:12.500+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:34:12.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.687 seconds
[2025-01-13T15:34:42.963+0000] {processor.py:186} INFO - Started process (PID=2307) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:42.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:34:42.967+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:42.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:43.616+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:34:43.637+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:43.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:34:43.653+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:34:43.653+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:34:43.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T15:35:14.210+0000] {processor.py:186} INFO - Started process (PID=2309) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:14.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:35:14.213+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:14.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:14.863+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:14.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:14.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:35:14.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:14.907+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:35:14.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.728 seconds
[2025-01-13T15:35:45.117+0000] {processor.py:186} INFO - Started process (PID=2311) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:45.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:35:45.121+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:45.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:45.524+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:35:45.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:45.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:35:45.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:35:45.888+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:35:45.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.800 seconds
[2025-01-13T15:36:16.358+0000] {processor.py:186} INFO - Started process (PID=2313) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:36:16.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:36:16.364+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:36:16.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:36:16.775+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:36:17.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:36:17.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:36:17.097+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:36:17.097+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:36:17.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-13T15:44:10.208+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:10.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:44:10.215+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:10.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:11.074+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:11.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:11.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:44:11.536+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:11.536+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:44:11.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.397 seconds
[2025-01-13T15:44:41.679+0000] {processor.py:186} INFO - Started process (PID=2317) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:41.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:44:41.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:41.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:42.311+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:44:42.357+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:42.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:44:42.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:44:42.374+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:44:42.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.724 seconds
[2025-01-13T15:45:12.812+0000] {processor.py:186} INFO - Started process (PID=2319) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:12.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:45:12.816+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:12.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:13.484+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:13.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:13.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:45:13.523+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:13.523+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:45:13.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.735 seconds
[2025-01-13T15:45:43.792+0000] {processor.py:186} INFO - Started process (PID=2321) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:43.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:45:43.803+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:43.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:44.463+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:45:44.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:44.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:45:44.507+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:45:44.507+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:45:44.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.745 seconds
[2025-01-13T15:46:15.247+0000] {processor.py:186} INFO - Started process (PID=2323) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:15.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:46:15.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:15.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:15.795+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:15.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:15.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:46:16.292+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:16.291+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:46:16.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.079 seconds
[2025-01-13T15:46:46.905+0000] {processor.py:186} INFO - Started process (PID=2325) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:46.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:46:46.909+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:46.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:47.306+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:46:47.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:47.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:46:47.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:46:47.659+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:46:47.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.779 seconds
[2025-01-13T15:47:18.256+0000] {processor.py:186} INFO - Started process (PID=2327) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:18.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:47:18.264+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:18.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:18.869+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:18.908+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:18.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:47:18.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:18.927+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:47:18.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.700 seconds
[2025-01-13T15:47:49.579+0000] {processor.py:186} INFO - Started process (PID=2329) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:49.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:47:49.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:49.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:50.332+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:47:50.363+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:50.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:47:50.387+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:47:50.387+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:47:50.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.866 seconds
[2025-01-13T15:48:21.304+0000] {processor.py:186} INFO - Started process (PID=2331) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:21.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:48:21.310+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:48:21.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:22.104+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:48:22.099+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 34
    def transform_data(post_df: )
                                ^
SyntaxError: invalid syntax
[2025-01-13T15:48:22.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:22.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.877 seconds
[2025-01-13T15:48:52.739+0000] {processor.py:186} INFO - Started process (PID=2333) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:52.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:48:52.743+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:48:52.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:53.171+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:48:53.168+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 34
    def transform_data(post_df: )
                                ^
SyntaxError: invalid syntax
[2025-01-13T15:48:53.171+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:48:53.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T15:49:23.739+0000] {processor.py:186} INFO - Started process (PID=2335) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:23.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:49:23.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:49:23.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:24.123+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:49:24.119+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 34
    def transform_data(post_df: )
                                ^
SyntaxError: invalid syntax
[2025-01-13T15:49:24.124+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:24.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.434 seconds
[2025-01-13T15:49:54.393+0000] {processor.py:186} INFO - Started process (PID=2337) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:54.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:49:54.398+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:49:54.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:55.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:49:55.052+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 34
    def transform_data(post_df: )
                                ^
SyntaxError: invalid syntax
[2025-01-13T15:49:55.054+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:49:55.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.701 seconds
[2025-01-13T15:50:25.769+0000] {processor.py:186} INFO - Started process (PID=2339) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:25.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:50:25.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:50:25.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:27.036+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:50:27.033+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 38
    post_df['over_18'] = np.where((post_df[]))
                                           ^
SyntaxError: invalid syntax
[2025-01-13T15:50:27.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:27.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.397 seconds
[2025-01-13T15:50:57.846+0000] {processor.py:186} INFO - Started process (PID=2341) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:57.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:50:57.850+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:50:57.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:58.676+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:50:58.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 36, in <module>
    def transform_data(post_df: pd.Dataframe):
AttributeError: module 'pandas' has no attribute 'Dataframe'
[2025-01-13T15:50:58.676+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:50:58.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.908 seconds
[2025-01-13T15:51:29.447+0000] {processor.py:186} INFO - Started process (PID=2343) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:51:29.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:51:29.461+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:51:29.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:51:30.588+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:51:30.582+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 36, in <module>
    def transform_data(post_df: pd.Dataframe):
AttributeError: module 'pandas' has no attribute 'Dataframe'
[2025-01-13T15:51:30.589+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:51:30.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.241 seconds
[2025-01-13T15:52:01.311+0000] {processor.py:186} INFO - Started process (PID=2345) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:01.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:52:01.315+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:52:01.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:01.746+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:52:01.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 42
    def 
        ^
SyntaxError: invalid syntax
[2025-01-13T15:52:01.746+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:01.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.515 seconds
[2025-01-13T15:52:32.056+0000] {processor.py:186} INFO - Started process (PID=2347) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:32.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:52:32.060+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:52:32.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:32.760+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:52:32.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts
  File "/opt/airflow/etls/reddit_etl.py", line 47
    
    ^
IndentationError: expected an indented block
[2025-01-13T15:52:32.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:52:32.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T15:53:03.549+0000] {processor.py:186} INFO - Started process (PID=2349) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:03.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:53:03.561+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:03.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:04.250+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:04.445+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:04.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:53:04.463+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:04.463+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:53:04.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.948 seconds
[2025-01-13T15:53:35.109+0000] {processor.py:186} INFO - Started process (PID=2351) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:35.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:53:35.114+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:35.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:36.095+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:53:36.148+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:36.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:53:36.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:53:36.173+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:53:36.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.107 seconds
[2025-01-13T15:54:06.812+0000] {processor.py:186} INFO - Started process (PID=2353) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:54:06.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:54:06.817+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:54:06.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:54:07.468+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:54:07.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:54:07.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:54:07.531+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:54:07.531+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:54:07.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.749 seconds
[2025-01-13T15:55:22.395+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:22.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:55:22.432+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:22.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:23.894+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:23.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:23.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:55:24.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:24.039+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:55:24.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.737 seconds
[2025-01-13T15:55:54.687+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:54.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:55:54.720+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:54.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:56.190+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:55:56.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:56.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:55:56.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:55:56.307+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:55:56.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.695 seconds
[2025-01-13T15:56:26.783+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:56:26.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:56:26.792+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:56:26.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:56:28.656+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:56:28.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:56:28.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:56:28.726+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:56:28.726+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:56:28.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.989 seconds
[2025-01-13T15:56:59.075+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:56:59.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:56:59.095+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:56:59.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:57:01.373+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:57:01.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:57:01.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:57:01.541+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:57:01.540+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:57:01.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.524 seconds
[2025-01-13T15:57:32.217+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:57:32.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:57:32.231+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:57:32.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:57:33.108+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:57:33.149+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:57:33.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:57:33.183+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:57:33.183+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:57:33.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.010 seconds
[2025-01-13T15:58:04.110+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:04.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:58:04.118+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:04.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:04.884+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:04.917+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:04.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:58:04.935+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:04.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:58:04.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-13T15:58:35.602+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:35.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:58:35.612+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:35.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:36.387+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:58:36.422+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:36.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:58:36.444+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:58:36.444+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:58:36.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.876 seconds
[2025-01-13T15:59:07.127+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:07.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:59:07.138+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:07.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:07.898+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:07.923+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:07.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:59:07.947+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:07.946+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:59:07.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.866 seconds
[2025-01-13T15:59:38.569+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:38.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T15:59:38.577+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:38.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:39.337+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T15:59:39.382+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:39.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T15:59:39.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T15:59:39.421+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T15:59:39.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.898 seconds
[2025-01-13T16:00:10.235+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:10.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:00:10.244+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:00:10.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:10.970+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:11.023+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:00:11.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:00:11.045+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:00:11.044+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:00:11.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.840 seconds
[2025-01-13T16:00:41.851+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:41.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:00:41.858+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:00:41.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:41.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:00:41.923+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 19
    load_data_to_csv(post_df, f'{OUTPUT_PATH)
                                             ^
SyntaxError: EOL while scanning string literal
[2025-01-13T16:00:41.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:00:41.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.128 seconds
[2025-01-13T16:01:12.566+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:12.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:01:12.578+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:12.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:13.728+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:13.760+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:13.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:01:13.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:13.778+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:01:13.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.270 seconds
[2025-01-13T16:01:44.307+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:44.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:01:44.313+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:44.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:45.034+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:01:45.069+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:45.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:01:45.088+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:01:45.088+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:01:45.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.815 seconds
[2025-01-13T16:02:15.892+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:15.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:02:15.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:15.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:17.570+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:17.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:17.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:02:17.827+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:17.827+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:02:17.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.003 seconds
[2025-01-13T16:02:48.519+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:48.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:02:48.549+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:48.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:49.727+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:02:49.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:49.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:02:49.803+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:02:49.803+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:02:49.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.343 seconds
[2025-01-13T16:03:20.386+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:20.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:03:20.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:20.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:21.188+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:21.216+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:21.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:03:21.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:21.242+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:03:21.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.903 seconds
[2025-01-13T16:03:51.779+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:51.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:03:51.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:51.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:52.524+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:03:52.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:52.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:03:52.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:03:52.567+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:03:52.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.828 seconds
[2025-01-13T16:04:23.166+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:23.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:04:23.174+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:23.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:23.982+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:24.026+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:24.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:04:24.049+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:24.048+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:04:24.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.933 seconds
[2025-01-13T16:04:54.794+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:54.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:04:54.803+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:54.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:55.877+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:04:55.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:55.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:04:56.005+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:04:56.005+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:04:56.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.262 seconds
[2025-01-13T16:05:26.314+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:26.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:05:26.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:26.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:27.148+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:27.191+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:27.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:05:27.221+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:27.221+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:05:27.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.949 seconds
[2025-01-13T16:05:57.868+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:57.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:05:57.878+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:57.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:58.616+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:05:58.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:58.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:05:58.662+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:05:58.662+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:05:58.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.827 seconds
[2025-01-13T16:06:29.401+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:06:29.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:06:29.410+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:06:29.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:06:30.204+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:06:30.233+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:06:30.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:06:30.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:06:30.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:06:30.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.892 seconds
[2025-01-13T16:07:00.724+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:00.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:07:00.745+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:00.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:01.445+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:01.469+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:01.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:07:01.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:01.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:07:01.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.788 seconds
[2025-01-13T16:07:32.099+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:32.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:07:32.108+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:32.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:32.818+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:07:32.846+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:32.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:07:32.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:07:32.863+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:07:32.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.842 seconds
[2025-01-13T16:08:03.369+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:03.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:08:03.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:03.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:04.003+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:04.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:04.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:08:04.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:04.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:08:04.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.721 seconds
[2025-01-13T16:08:34.465+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:34.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:08:34.472+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:34.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:35.132+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:08:35.181+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:35.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:08:35.202+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:08:35.202+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:08:35.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-13T16:09:05.640+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:05.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:09:05.648+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:05.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:06.449+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:06.478+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:06.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:09:06.495+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:06.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:09:06.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.881 seconds
[2025-01-13T16:09:36.767+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:36.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:09:36.774+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:36.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:37.501+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:09:37.570+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:37.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:09:37.604+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:09:37.603+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:09:37.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.868 seconds
[2025-01-13T16:10:08.223+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:08.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:10:08.232+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:08.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:08.991+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:09.013+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:09.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:10:09.030+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:09.029+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:10:09.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.845 seconds
[2025-01-13T16:10:39.608+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:39.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:10:39.621+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:39.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:40.273+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:10:40.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:40.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:10:40.318+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:10:40.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:10:40.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.748 seconds
[2025-01-13T16:11:10.911+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:10.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:11:10.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:10.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:11.967+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:12.025+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:12.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:11:12.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:12.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:11:12.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.188 seconds
[2025-01-13T16:11:42.632+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:42.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:11:42.646+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:42.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:44.055+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:11:44.165+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:44.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:11:44.222+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:11:44.222+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:11:44.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.652 seconds
[2025-01-13T16:12:14.737+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:14.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:12:14.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:14.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:15.638+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:15.665+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:15.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:12:15.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:15.684+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:12:15.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.981 seconds
[2025-01-13T16:12:45.844+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:45.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:12:45.855+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:45.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:46.770+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:12:46.807+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:46.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:12:46.831+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:12:46.831+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:12:46.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.026 seconds
[2025-01-13T16:13:17.340+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:17.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:13:17.346+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:17.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:18.038+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:18.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:18.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:13:18.081+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:18.080+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:13:18.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T16:13:48.573+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:48.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:13:48.581+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:48.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:49.293+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:13:49.322+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:49.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:13:49.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:13:49.339+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:13:49.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.794 seconds
[2025-01-13T16:14:19.790+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:19.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:14:19.798+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:19.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:20.513+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:20.539+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:20.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:14:20.558+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:20.558+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:14:20.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.797 seconds
[2025-01-13T16:14:51.034+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:51.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:14:51.041+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:51.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:51.788+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:14:51.827+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:51.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:14:51.869+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:14:51.868+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:14:51.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.888 seconds
[2025-01-13T16:15:22.398+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:22.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:15:22.408+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:22.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:23.086+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:23.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:23.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:15:23.158+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:23.158+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:15:23.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-13T16:15:53.610+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:53.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:15:53.620+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:53.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:54.408+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:15:54.661+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:54.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:15:54.700+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:15:54.700+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:15:54.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.123 seconds
[2025-01-13T16:16:25.167+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:25.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:16:25.175+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:25.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:25.925+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:25.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:25.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:16:26.001+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:26.001+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:16:26.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.878 seconds
[2025-01-13T16:16:56.662+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:56.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:16:56.676+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:56.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:57.480+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:16:57.527+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:57.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:16:57.554+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:16:57.554+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:16:57.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.929 seconds
[2025-01-13T16:17:28.110+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:17:28.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:17:28.134+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:17:28.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:17:28.723+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:17:28.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:17:28.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:17:28.774+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:17:28.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:17:28.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.689 seconds
[2025-01-13T16:17:59.371+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:17:59.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:17:59.382+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:17:59.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:18:00.090+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:18:00.152+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:18:00.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:18:00.177+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:18:00.176+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:18:00.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.848 seconds
[2025-01-13T16:18:30.686+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:18:30.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:18:30.695+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:18:30.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:18:31.365+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:18:31.390+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:18:31.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:18:31.407+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:18:31.407+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:18:31.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.774 seconds
[2025-01-13T16:19:01.881+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:01.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:19:01.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:01.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:02.534+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:02.570+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:02.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:19:02.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:02.591+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:19:02.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.763 seconds
[2025-01-13T16:19:33.067+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:33.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:19:33.076+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:33.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:33.772+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:19:33.798+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:33.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:19:33.820+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:19:33.819+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:19:33.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.802 seconds
[2025-01-13T16:20:04.061+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:04.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:20:04.069+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:04.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:04.731+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:04.763+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:04.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:20:04.788+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:04.788+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:20:04.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.758 seconds
[2025-01-13T16:20:35.323+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:35.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:20:35.341+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:35.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:36.655+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:20:36.688+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:36.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:20:36.709+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:20:36.708+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:20:36.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.440 seconds
[2025-01-13T16:21:07.208+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:07.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:21:07.216+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:07.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:07.807+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:07.832+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:07.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:21:07.850+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:07.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:21:07.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.667 seconds
[2025-01-13T16:21:38.320+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:38.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:21:38.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:38.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:39.023+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:21:39.044+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:39.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:21:39.065+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:21:39.065+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:21:39.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.773 seconds
[2025-01-13T16:22:09.573+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:09.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:22:09.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:09.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:10.208+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:10.230+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:10.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:22:10.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:10.255+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:22:10.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.715 seconds
[2025-01-13T16:22:40.546+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:40.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:22:40.554+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:40.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:41.210+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:22:41.235+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:41.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:22:41.252+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:22:41.252+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:22:41.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.736 seconds
[2025-01-13T16:23:11.678+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:11.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:23:11.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:11.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:12.306+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:12.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:12.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:23:12.358+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:12.358+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:23:12.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.706 seconds
[2025-01-13T16:23:42.813+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:42.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:23:42.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:42.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:43.482+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:23:43.509+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:43.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:23:43.527+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:23:43.526+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:23:43.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T16:24:13.837+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:13.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:24:13.853+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:13.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:14.460+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:14.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:14.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:24:14.496+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:14.496+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:24:14.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.706 seconds
[2025-01-13T16:24:44.924+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:44.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:24:44.932+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:44.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:45.602+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:24:45.625+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:45.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:24:45.646+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:24:45.646+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:24:45.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.754 seconds
[2025-01-13T16:25:15.736+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:15.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:25:15.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:15.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:16.459+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:16.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:16.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:25:16.505+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:16.505+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:25:16.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.805 seconds
[2025-01-13T16:25:47.148+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:47.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:25:47.159+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:47.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:47.878+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:25:47.906+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:47.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:25:47.930+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:25:47.930+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:25:47.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.821 seconds
[2025-01-13T16:26:18.438+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:18.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:26:18.450+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:18.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:19.072+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:19.111+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:19.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:26:19.128+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:19.128+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:26:19.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.733 seconds
[2025-01-13T16:26:49.457+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:49.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:26:49.477+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:49.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:50.170+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:26:50.206+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:50.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:26:50.225+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:26:50.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:26:50.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.808 seconds
[2025-01-13T16:27:20.790+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:20.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:27:20.798+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:20.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:21.450+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:21.474+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:21.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:27:21.491+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:21.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:27:21.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.726 seconds
[2025-01-13T16:27:51.991+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:51.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:27:52.001+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:52.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:52.597+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:27:52.626+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:52.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:27:52.644+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:27:52.644+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:27:52.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.698 seconds
[2025-01-13T16:28:23.112+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:23.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:28:23.121+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:23.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:23.768+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:23.793+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:23.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:28:23.810+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:23.810+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:28:23.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.725 seconds
[2025-01-13T16:28:54.198+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:54.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:28:54.212+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:54.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:54.801+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:28:54.836+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:54.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:28:54.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:28:54.863+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:28:54.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T16:29:25.761+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:29:25.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:29:25.804+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:29:25.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:29:28.290+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:29:28.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:29:28.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:29:28.383+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:29:28.383+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:29:28.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.813 seconds
[2025-01-13T16:29:59.150+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:29:59.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:29:59.165+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:29:59.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:30:00.239+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:30:00.278+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:30:00.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:30:00.298+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:30:00.298+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:30:00.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.239 seconds
[2025-01-13T16:30:30.961+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:30:30.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:30:30.970+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:30:30.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:30:31.842+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:30:31.931+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:30:31.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:30:31.973+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:30:31.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:30:31.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.052 seconds
[2025-01-13T16:31:02.664+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:02.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:31:02.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:02.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:03.358+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:03.391+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:03.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:31:03.408+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:03.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:31:03.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T16:31:33.916+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:33.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:31:33.938+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:33.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:34.693+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:31:34.780+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:34.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:31:34.824+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:31:34.824+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:31:34.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.952 seconds
[2025-01-13T16:32:05.377+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:05.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:32:05.384+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:05.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:06.185+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:06.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:06.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:32:06.277+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:06.277+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:32:06.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.942 seconds
[2025-01-13T16:32:36.920+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:36.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:32:36.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:36.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:37.659+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:32:37.701+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:37.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:32:37.749+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:32:37.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:32:37.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.881 seconds
[2025-01-13T16:33:08.279+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:08.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:33:08.291+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:08.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:08.996+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:09.020+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:09.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:33:09.041+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:09.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:33:09.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.801 seconds
[2025-01-13T16:33:39.605+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:39.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:33:39.630+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:39.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:40.343+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:33:40.383+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:40.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:33:40.417+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:33:40.417+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:33:40.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.859 seconds
[2025-01-13T16:34:11.222+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:11.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:34:11.228+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:11.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:12.327+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:12.384+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:12.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:34:12.407+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:12.407+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:34:12.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.247 seconds
[2025-01-13T16:34:43.234+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:43.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:34:43.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:43.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:44.077+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:34:44.116+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:44.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:34:44.139+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:34:44.139+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:34:44.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.957 seconds
[2025-01-13T16:35:14.728+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:14.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:35:14.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:14.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:15.417+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:15.451+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:15.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:35:15.471+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:15.471+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:35:15.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.781 seconds
[2025-01-13T16:35:46.255+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:46.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:35:46.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:46.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:47.505+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:35:47.562+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:47.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:35:47.586+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:35:47.586+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:35:47.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.378 seconds
[2025-01-13T16:36:17.747+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:17.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:36:17.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:17.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:18.557+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:18.600+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:18.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:36:18.629+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:18.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:36:18.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.917 seconds
[2025-01-13T16:36:49.186+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:49.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:36:49.200+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:49.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:50.012+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:36:50.061+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:50.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:36:50.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:36:50.080+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:36:50.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.936 seconds
[2025-01-13T16:37:20.599+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:20.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:37:20.607+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:20.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:21.290+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:21.319+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:21.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:37:21.337+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:21.337+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:37:21.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.771 seconds
[2025-01-13T16:37:51.523+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:51.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:37:51.531+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:51.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:52.245+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:37:52.288+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:52.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:37:52.329+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:37:52.328+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:37:52.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.889 seconds
[2025-01-13T16:38:23.013+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:23.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:38:23.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:23.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:23.979+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:24.011+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:24.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:38:24.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:24.038+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:38:24.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.140 seconds
[2025-01-13T16:38:54.755+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:54.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:38:54.763+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:54.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:55.520+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:38:55.551+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:55.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:38:55.571+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:38:55.571+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:38:55.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.858 seconds
[2025-01-13T16:39:26.301+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:26.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:39:26.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:26.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:26.963+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:26.999+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:26.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:39:27.020+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:27.019+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:39:27.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T16:39:57.522+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:57.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:39:57.530+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:57.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:58.313+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:39:58.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:58.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:39:58.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:39:58.372+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:39:58.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.884 seconds
[2025-01-13T16:40:28.907+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:40:28.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:40:28.915+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:40:28.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:40:29.567+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:40:29.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:40:29.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:40:29.628+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:40:29.627+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:40:29.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.762 seconds
[2025-01-13T16:41:00.110+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:00.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:41:00.118+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:00.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:00.961+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:01.001+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:01.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:41:01.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:01.022+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:41:01.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.941 seconds
[2025-01-13T16:41:31.199+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:31.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:41:31.209+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:31.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:31.913+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:41:31.964+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:31.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:41:32.003+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:41:32.003+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:41:32.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.855 seconds
[2025-01-13T16:42:02.660+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:02.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:42:02.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:02.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:03.355+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:03.405+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:03.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:42:03.426+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:03.426+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:42:03.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.795 seconds
[2025-01-13T16:42:33.919+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:33.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:42:33.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:33.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:34.528+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:42:34.552+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:34.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:42:34.569+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:42:34.569+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:42:34.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.684 seconds
[2025-01-13T16:43:04.863+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:04.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:43:04.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:04.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:05.611+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:05.648+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:05.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:43:05.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:05.667+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:43:05.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.832 seconds
[2025-01-13T16:43:36.189+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:36.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:43:36.205+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:36.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:36.902+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:43:36.933+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:36.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:43:36.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:43:36.950+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:43:36.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-13T16:44:07.436+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:07.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:44:07.477+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:07.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:08.278+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:08.307+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:08.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:44:08.325+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:08.324+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:44:08.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.915 seconds
[2025-01-13T16:44:39.053+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:39.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:44:39.060+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:39.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:39.711+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:44:39.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:39.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:44:39.804+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:44:39.804+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:44:39.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.793 seconds
[2025-01-13T16:45:10.379+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:10.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:45:10.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:10.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:11.080+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:11.112+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:11.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:45:11.133+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:11.132+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:45:11.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.776 seconds
[2025-01-13T16:45:41.453+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:41.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:45:41.461+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:41.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:42.325+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:45:42.361+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:42.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:45:42.381+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:45:42.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:45:42.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.963 seconds
[2025-01-13T16:46:12.865+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:12.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:46:12.872+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:12.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:13.960+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:14.130+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:14.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:46:14.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:14.161+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:46:14.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.342 seconds
[2025-01-13T16:46:44.374+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:44.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:46:44.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:44.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:45.020+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:46:45.042+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:45.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:46:45.059+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:46:45.058+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:46:45.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T16:47:15.239+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:15.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:47:15.252+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:15.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:15.974+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:16.004+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:16.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:47:16.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:16.022+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:47:16.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.809 seconds
[2025-01-13T16:47:46.611+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:46.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:47:46.619+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:46.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:47.187+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:47:47.212+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:47.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:47:47.232+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:47:47.232+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:47:47.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.656 seconds
[2025-01-13T16:48:17.700+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:17.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:48:17.707+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:17.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:18.609+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:18.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:18.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:48:18.662+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:18.661+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:48:18.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.991 seconds
[2025-01-13T16:48:49.303+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:49.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:48:49.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:49.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:50.535+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:48:50.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:50.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:48:50.648+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:48:50.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:48:50.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.474 seconds
[2025-01-13T16:49:20.803+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:20.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:49:20.822+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:20.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:21.520+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:21.547+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:21.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:49:21.564+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:21.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:49:21.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.826 seconds
[2025-01-13T16:49:52.135+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:52.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:49:52.143+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:52.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:52.776+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:49:52.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:52.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:49:52.829+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:49:52.828+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:49:52.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.744 seconds
[2025-01-13T16:50:23.350+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:23.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:50:23.357+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:23.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:24.011+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:24.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:24.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:50:24.078+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:24.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:50:24.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.754 seconds
[2025-01-13T16:50:54.364+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:54.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:50:54.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:54.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:55.125+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:50:55.165+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:55.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:50:55.185+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:50:55.185+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:50:55.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.854 seconds
[2025-01-13T16:51:25.667+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:25.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:51:25.674+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:25.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:26.351+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:26.376+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:26.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:51:26.394+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:26.394+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:51:26.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.752 seconds
[2025-01-13T16:51:57.471+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:57.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:51:57.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:57.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:59.134+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:51:59.231+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:59.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:51:59.259+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:51:59.258+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:51:59.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.861 seconds
[2025-01-13T16:52:29.852+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:52:29.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:52:29.858+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:52:29.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:52:30.455+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:52:30.477+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:52:30.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:52:30.501+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:52:30.501+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:52:30.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.676 seconds
[2025-01-13T16:53:01.010+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:01.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:53:01.023+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:01.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:01.645+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:01.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:01.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:53:01.699+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:01.699+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:53:01.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.714 seconds
[2025-01-13T16:53:32.132+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:32.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:53:32.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:32.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:32.804+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:53:32.843+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:32.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:53:32.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:53:32.861+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:53:32.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.751 seconds
[2025-01-13T16:54:03.358+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:03.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:54:03.368+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:03.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:04.017+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:04.049+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:04.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:54:04.065+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:04.065+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:54:04.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.731 seconds
[2025-01-13T16:54:34.393+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:34.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:54:34.400+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:34.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:35.054+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:54:35.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:35.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:54:35.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:54:35.100+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:54:35.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-13T16:55:05.584+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:05.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:55:05.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:05.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:06.256+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:06.291+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:06.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:55:06.312+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:06.312+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:55:06.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.847 seconds
[2025-01-13T16:55:36.868+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:36.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:55:36.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:36.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:37.610+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:55:37.645+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:37.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:55:37.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:55:37.663+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:55:37.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.824 seconds
[2025-01-13T16:56:08.581+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:08.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:56:08.654+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:08.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:09.788+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:09.825+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:09.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:56:09.851+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:09.851+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:56:09.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.363 seconds
[2025-01-13T16:56:40.221+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:40.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:56:40.228+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:40.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:40.857+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:56:40.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:40.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:56:40.901+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:56:40.901+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:56:40.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.710 seconds
[2025-01-13T16:57:11.399+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:11.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:57:11.405+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:11.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:12.014+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:12.040+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:12.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:57:12.058+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:12.057+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:57:12.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.680 seconds
[2025-01-13T16:57:42.498+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:42.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:57:42.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:42.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:43.193+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:57:43.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:43.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:57:43.241+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:57:43.241+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:57:43.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.790 seconds
[2025-01-13T16:58:13.388+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:13.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:58:13.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:13.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:14.027+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:14.070+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:14.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:58:14.090+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:14.090+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:58:14.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.728 seconds
[2025-01-13T16:58:44.591+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:44.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:58:44.599+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:44.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:45.237+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:58:45.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:45.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:58:45.282+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:58:45.282+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:58:45.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.737 seconds
[2025-01-13T16:59:15.511+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:15.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:59:15.518+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:15.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:16.159+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:16.187+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:16.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:59:16.204+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:16.204+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:59:16.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T16:59:46.732+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:46.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T16:59:46.740+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:46.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:47.385+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T16:59:47.433+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:47.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T16:59:47.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T16:59:47.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T16:59:47.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.755 seconds
[2025-01-13T17:00:17.934+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:17.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:00:17.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:17.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:18.701+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:18.727+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:18.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:00:18.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:18.744+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:00:18.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.867 seconds
[2025-01-13T17:00:49.178+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:49.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:00:49.186+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:49.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:49.910+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:00:49.937+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:49.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:00:49.963+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:00:49.963+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:00:49.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.813 seconds
[2025-01-13T17:01:20.177+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:20.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:01:20.186+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:20.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:20.779+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:20.813+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:20.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:01:20.830+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:20.829+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:01:20.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.681 seconds
[2025-01-13T17:01:51.269+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:51.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:01:51.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:51.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:51.895+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:01:51.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:51.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:01:51.937+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:01:51.937+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:01:51.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.701 seconds
[2025-01-13T17:02:22.281+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:22.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:02:22.287+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:22.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:22.918+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:22.957+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:22.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:02:22.977+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:22.976+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:02:22.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.725 seconds
[2025-01-13T17:02:53.449+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:53.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:02:53.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:53.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:54.117+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:02:54.152+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:54.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:02:54.169+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:02:54.169+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:02:54.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.748 seconds
[2025-01-13T17:03:24.668+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:24.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:03:24.686+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:24.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:25.321+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:25.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:25.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:03:25.365+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:25.364+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:03:25.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.741 seconds
[2025-01-13T17:03:55.459+0000] {processor.py:186} INFO - Started process (PID=294) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:55.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:03:55.465+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:55.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:56.107+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:03:56.131+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:56.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:03:56.148+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:03:56.147+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:03:56.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T17:04:26.650+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:26.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:04:26.658+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:26.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:27.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:27.244+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:27.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:04:27.264+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:27.264+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:04:27.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.642 seconds
[2025-01-13T17:04:57.695+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:57.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:04:57.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:57.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:58.380+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:04:58.427+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:58.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:04:58.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:04:58.455+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:04:58.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.799 seconds
[2025-01-13T17:05:28.991+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:05:28.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:05:28.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:05:28.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:05:29.593+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:05:29.618+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:05:29.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:05:29.637+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:05:29.637+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:05:29.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.688 seconds
[2025-01-13T17:06:00.169+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:00.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:06:00.178+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:00.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:00.858+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:00.882+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:00.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:06:00.899+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:00.899+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:06:00.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.758 seconds
[2025-01-13T17:06:31.485+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:31.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:06:31.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:31.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:32.308+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:06:32.348+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:32.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:06:32.369+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:06:32.369+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:06:32.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.955 seconds
[2025-01-13T17:07:03.079+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:03.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:07:03.087+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:03.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:03.839+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:03.896+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:03.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:07:03.918+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:03.918+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:07:03.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.911 seconds
[2025-01-13T17:07:34.446+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:34.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:07:34.454+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:34.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:35.098+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:07:35.126+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:35.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:07:35.143+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:07:35.143+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:07:35.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.721 seconds
[2025-01-13T17:08:05.669+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:05.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:08:05.693+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:05.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:06.313+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:06.339+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:06.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:08:06.369+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:06.369+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:08:06.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.728 seconds
[2025-01-13T17:08:36.833+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:36.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:08:36.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:36.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:37.463+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:08:37.492+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:37.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:08:37.515+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:08:37.515+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:08:37.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.722 seconds
[2025-01-13T17:09:07.853+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:07.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:09:07.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:07.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:08.613+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:08.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:08.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:09:08.706+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:08.706+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:09:08.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.906 seconds
[2025-01-13T17:09:39.310+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:39.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:09:39.327+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:39.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:40.341+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:09:40.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:40.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:09:40.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:09:40.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:09:40.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.123 seconds
[2025-01-13T17:10:10.973+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:10.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:10:10.987+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:10.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:11.821+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:11.865+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:11.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:10:11.887+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:11.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:10:11.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.945 seconds
[2025-01-13T17:10:42.760+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:42.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:10:42.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:42.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:43.426+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:10:43.491+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:43.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:10:43.517+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:10:43.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:10:43.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.810 seconds
[2025-01-13T17:11:14.411+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:14.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:11:14.423+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:14.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:15.177+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:15.211+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:15.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:11:15.233+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:15.233+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:11:15.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.886 seconds
[2025-01-13T17:11:46.250+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:46.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:11:46.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:46.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:47.913+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:11:47.995+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:47.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:11:48.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:11:48.038+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:11:48.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.856 seconds
[2025-01-13T17:33:08.328+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:08.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:33:08.335+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:08.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:09.089+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:09.111+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:09.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:33:09.127+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:09.127+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:33:09.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.823 seconds
[2025-01-13T17:33:39.749+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:39.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:33:39.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:39.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:40.413+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:33:40.438+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:40.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:33:40.457+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:33:40.457+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:33:40.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.736 seconds
[2025-01-13T17:34:10.952+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:10.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:34:10.959+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:10.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:11.542+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:11.563+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:11.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:34:11.581+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:11.581+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:34:11.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.668 seconds
[2025-01-13T17:34:42.061+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:42.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:34:42.077+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:42.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:42.909+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:34:42.983+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:42.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:34:43.007+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:34:43.007+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:34:43.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.973 seconds
[2025-01-13T17:35:13.621+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:13.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:35:13.633+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:13.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:14.742+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:14.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:14.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:35:14.809+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:14.809+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:35:14.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.219 seconds
[2025-01-13T17:35:45.274+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:45.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:35:45.293+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:45.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:45.883+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:35:45.911+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:45.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:35:45.935+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:35:45.935+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:35:45.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.704 seconds
[2025-01-13T17:36:16.615+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:16.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:36:16.625+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:16.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:17.358+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:17.397+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:17.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:36:17.417+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:17.417+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:36:17.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.845 seconds
[2025-01-13T17:36:48.229+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:48.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:36:48.236+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:48.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:49.233+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:36:49.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:49.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:36:49.464+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:36:49.463+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:36:49.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.310 seconds
[2025-01-13T17:37:20.092+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:20.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:37:20.097+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:37:20.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:20.964+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:37:20.955+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 41
    post_df['edited'] = 
                        ^
SyntaxError: invalid syntax
[2025-01-13T17:37:20.965+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:21.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.950 seconds
[2025-01-13T17:37:51.907+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:51.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:37:51.922+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:37:51.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:52.607+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:37:52.656+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:37:52.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:37:52.685+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:37:52.685+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:37:52.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.835 seconds
[2025-01-13T17:38:23.411+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:23.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:38:23.418+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:38:23.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:24.134+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:38:24.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 43
    post_df['edited'], edited_mode)
    ^
SyntaxError: invalid syntax
[2025-01-13T17:38:24.134+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:24.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.778 seconds
[2025-01-13T17:38:54.829+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:54.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:38:54.837+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:38:54.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:55.905+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:38:55.984+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:38:55.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:38:56.015+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:38:56.015+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:38:56.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.217 seconds
[2025-01-13T17:39:26.391+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:26.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:39:26.397+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:26.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:27.176+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:27.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:27.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:39:27.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:27.256+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:39:27.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.933 seconds
[2025-01-13T17:39:58.149+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:58.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:39:58.158+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:58.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:59.327+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:39:59.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:59.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:39:59.459+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:39:59.459+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:39:59.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.374 seconds
[2025-01-13T17:40:29.867+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:40:29.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:40:29.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:40:29.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:40:30.825+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:40:30.918+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:40:30.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:40:30.940+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:40:30.940+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:40:30.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.129 seconds
[2025-01-13T17:41:01.705+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:01.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:41:01.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:01.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:02.422+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:02.448+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:02.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:41:02.464+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:02.463+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:41:02.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-13T17:41:33.091+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:33.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:41:33.108+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:33.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:33.829+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:41:33.862+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:33.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:41:33.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:41:33.888+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:41:33.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.824 seconds
[2025-01-13T17:42:04.559+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:04.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:42:04.570+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:04.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:05.566+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:05.619+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:05.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:42:05.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:05.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:42:05.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.114 seconds
[2025-01-13T17:42:36.245+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:36.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:42:36.264+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:36.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:36.967+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:42:36.994+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:36.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:42:37.014+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:42:37.013+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:42:37.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.800 seconds
[2025-01-13T17:43:07.694+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:07.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:43:07.702+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:07.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:08.505+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:08.537+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:08.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:43:08.559+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:08.559+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:43:08.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.920 seconds
[2025-01-13T17:43:39.677+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:39.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:43:39.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:39.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:40.805+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:43:40.881+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:40.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:43:40.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:43:40.914+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:43:40.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.330 seconds
[2025-01-13T17:44:11.327+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:11.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:44:11.341+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:11.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:12.155+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:12.181+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:12.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:44:12.198+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:12.198+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:44:12.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.909 seconds
[2025-01-13T17:44:42.968+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:42.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:44:42.976+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:42.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:44.289+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:44:44.379+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:44.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:44:44.409+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:44:44.409+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:44:44.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.502 seconds
[2025-01-13T17:45:15.011+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:15.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:45:15.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:15.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:15.774+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:15.802+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:15.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:45:15.824+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:15.824+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:45:15.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.846 seconds
[2025-01-13T17:45:46.380+0000] {processor.py:186} INFO - Started process (PID=374) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:46.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:45:46.387+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:46.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:47.116+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:45:47.145+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:47.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:45:47.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:45:47.163+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:45:47.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.830 seconds
[2025-01-13T17:46:17.619+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:17.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:46:17.625+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:17.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:18.327+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:18.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:18.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:46:18.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:18.375+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:46:18.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.782 seconds
[2025-01-13T17:46:48.586+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:48.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:46:48.594+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:48.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:49.285+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:46:49.322+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:49.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:46:49.341+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:46:49.340+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:46:49.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-13T17:47:19.888+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:19.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:47:19.906+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:19.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:20.790+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:20.844+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:20.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:47:20.869+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:20.869+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:47:20.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.012 seconds
[2025-01-13T17:47:51.541+0000] {processor.py:186} INFO - Started process (PID=382) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:51.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:47:51.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:51.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:52.253+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:47:52.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:52.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:47:52.318+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:47:52.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:47:52.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.804 seconds
[2025-01-13T17:48:22.857+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:22.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:48:22.865+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:22.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:23.657+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:23.686+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:23.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:48:23.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:23.703+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:48:23.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.874 seconds
[2025-01-13T17:48:54.367+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:54.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:48:54.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:54.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:55.220+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:48:55.252+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:55.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:48:55.276+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:48:55.276+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:48:55.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.946 seconds
[2025-01-13T17:49:26.166+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:49:26.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:49:26.176+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:49:26.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:49:27.245+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:49:27.299+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:49:27.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:49:27.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:49:27.323+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:49:27.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.204 seconds
[2025-01-13T17:49:58.298+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:49:58.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:49:58.304+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:49:58.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:50:00.782+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:50:01.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:50:01.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:50:01.586+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:50:01.585+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:50:01.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 3.328 seconds
[2025-01-13T17:50:32.646+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:50:32.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:50:32.661+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:50:32.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:50:33.572+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:50:33.617+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:50:33.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T17:50:33.650+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:50:33.650+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T17:50:33.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.050 seconds
[2025-01-13T17:51:04.094+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:04.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:51:04.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:51:04.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:04.942+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:51:04.934+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:51:04.942+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:04.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.885 seconds
[2025-01-13T17:51:35.635+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:35.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:51:35.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:51:35.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:36.332+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:51:36.329+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:51:36.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:51:36.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.746 seconds
[2025-01-13T17:52:07.260+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:07.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:52:07.271+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:52:07.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:08.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:52:08.296+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:52:08.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:08.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.112 seconds
[2025-01-13T17:52:38.995+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:39.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:52:39.013+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:52:39.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:39.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:52:39.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:52:39.661+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:52:39.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.695 seconds
[2025-01-13T17:53:10.254+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:10.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:53:10.258+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:53:10.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:11.138+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:53:11.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:53:11.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:11.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.955 seconds
[2025-01-13T17:53:41.770+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:41.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:53:41.780+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:53:41.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:42.517+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:53:42.513+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:53:42.517+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:53:42.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.810 seconds
[2025-01-13T17:54:13.061+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:13.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:54:13.076+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:54:13.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:13.793+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:54:13.790+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:54:13.794+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:13.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.781 seconds
[2025-01-13T17:54:44.302+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:44.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:54:44.307+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:54:44.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:45.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:54:45.047+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:54:45.050+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:54:45.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.784 seconds
[2025-01-13T17:55:15.579+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:15.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:55:15.584+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:55:15.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:16.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:55:16.300+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:55:16.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:16.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.779 seconds
[2025-01-13T17:55:46.741+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:46.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:55:46.745+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:55:46.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:47.622+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:55:47.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:55:47.623+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:55:47.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.928 seconds
[2025-01-13T17:56:18.185+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:18.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:56:18.191+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:56:18.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:19.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:56:19.262+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:56:19.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:19.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.145 seconds
[2025-01-13T17:56:49.658+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:49.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:56:49.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:56:49.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:50.429+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:56:50.426+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:56:50.429+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:56:50.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.819 seconds
[2025-01-13T17:57:21.092+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:21.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:57:21.105+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:57:21.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:22.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:57:22.477+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:57:22.482+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:22.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.470 seconds
[2025-01-13T17:57:52.983+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:52.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:57:52.989+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:57:52.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:53.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:57:53.688+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:57:53.692+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:57:53.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T17:58:23.904+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:23.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:58:23.909+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:58:23.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:24.639+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:58:24.635+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:58:24.639+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:24.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.774 seconds
[2025-01-13T17:58:55.072+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:55.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:58:55.077+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:58:55.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:55.818+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:58:55.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:58:55.818+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:58:55.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.781 seconds
[2025-01-13T17:59:26.258+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:26.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:59:26.263+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:59:26.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:26.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:59:26.976+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:59:26.981+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:27.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.760 seconds
[2025-01-13T17:59:57.111+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:57.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T17:59:57.125+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:59:57.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:57.819+0000] {logging_mixin.py:190} INFO - [2025-01-13T17:59:57.808+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T17:59:57.820+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T17:59:57.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T18:00:28.311+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:28.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:00:28.315+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:00:28.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:29.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:00:29.047+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:00:29.051+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:29.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.795 seconds
[2025-01-13T18:00:59.200+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:59.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:00:59.206+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:00:59.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:59.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:00:59.866+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:00:59.872+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:00:59.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.745 seconds
[2025-01-13T18:01:30.388+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:01:30.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:01:30.394+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:01:30.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:01:31.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:01:31.185+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:01:31.189+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:01:31.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.873 seconds
[2025-01-13T18:02:01.631+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:01.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:02:01.636+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:02:01.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:02.306+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:02:02.303+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:02:02.306+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:02.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T18:02:32.667+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:32.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:02:32.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:02:32.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:33.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:02:33.349+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:02:33.353+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:02:33.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.738 seconds
[2025-01-13T18:03:03.860+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:03.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:03:03.865+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:03:03.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:04.570+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:03:04.566+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:03:04.570+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:04.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.788 seconds
[2025-01-13T18:03:34.820+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:34.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:03:34.825+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:03:34.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:37.750+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:03:37.729+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:03:37.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:03:37.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 3.006 seconds
[2025-01-13T18:04:08.513+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:08.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:04:08.517+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:04:08.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:09.264+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:04:09.260+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:04:09.265+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:09.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.802 seconds
[2025-01-13T18:04:39.824+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:39.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:04:39.828+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:04:39.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:40.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:04:40.545+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:04:40.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:04:40.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.771 seconds
[2025-01-13T18:05:11.074+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:11.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:05:11.095+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:05:11.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:11.761+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:05:11.757+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:05:11.761+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:11.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T18:05:42.396+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:42.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:05:42.401+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:05:42.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:43.269+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:05:43.263+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:05:43.270+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:05:43.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.210 seconds
[2025-01-13T18:06:14.364+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:14.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:06:14.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:06:14.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:15.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:06:15.344+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:06:15.350+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:15.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.051 seconds
[2025-01-13T18:06:45.853+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:45.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:06:45.857+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:06:45.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:46.564+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:06:46.561+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:06:46.565+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:06:46.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.755 seconds
[2025-01-13T18:07:17.223+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:17.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:07:17.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:07:17.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:18.311+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:07:18.300+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:07:18.312+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:18.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.144 seconds
[2025-01-13T18:07:48.925+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:48.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:07:48.929+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:07:48.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:49.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:07:49.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:07:49.638+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:07:49.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-13T18:08:20.190+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:20.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:08:20.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:08:20.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:20.915+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:08:20.910+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:08:20.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:20.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-13T18:08:51.455+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:51.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:08:51.460+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:08:51.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:52.130+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:08:52.126+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:08:52.130+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:08:52.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.711 seconds
[2025-01-13T18:09:22.719+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:22.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:09:22.724+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:09:22.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:23.392+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:09:23.388+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:09:23.392+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:23.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.737 seconds
[2025-01-13T18:09:53.900+0000] {processor.py:186} INFO - Started process (PID=466) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:53.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:09:53.904+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:09:53.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:54.614+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:09:54.611+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:09:54.614+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:09:54.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.754 seconds
[2025-01-13T18:10:24.833+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:24.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:10:24.838+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:10:24.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:25.575+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:10:25.571+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:10:25.576+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:25.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.784 seconds
[2025-01-13T18:10:56.270+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:56.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:10:56.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:10:56.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:57.139+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:10:57.135+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:10:57.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:10:57.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.906 seconds
[2025-01-13T18:11:27.743+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:27.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:11:27.748+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:11:27.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:28.450+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:11:28.447+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:11:28.450+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:28.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.771 seconds
[2025-01-13T18:11:59.035+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:59.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:11:59.040+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:11:59.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:59.828+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:11:59.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:11:59.828+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:11:59.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.835 seconds
[2025-01-13T18:12:30.383+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:12:30.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:12:30.389+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:12:30.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:12:31.211+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:12:31.208+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:12:31.212+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:12:31.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.872 seconds
[2025-01-13T18:13:01.895+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:01.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:13:01.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:13:01.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:02.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:13:02.678+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:13:02.684+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:02.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.840 seconds
[2025-01-13T18:13:32.955+0000] {processor.py:186} INFO - Started process (PID=480) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:32.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:13:32.961+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:13:32.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:34.191+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:13:34.186+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:13:34.191+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:13:34.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.292 seconds
[2025-01-13T18:14:04.485+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:04.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:14:04.493+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:14:04.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:05.255+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:14:05.251+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:14:05.255+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:05.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.821 seconds
[2025-01-13T18:14:36.102+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:36.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:14:36.110+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:14:36.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:37.149+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:14:37.144+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:14:37.149+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:14:37.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.107 seconds
[2025-01-13T18:15:07.523+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:07.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:15:07.527+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:15:07.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:08.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:15:08.262+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:15:08.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:08.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.774 seconds
[2025-01-13T18:15:38.678+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:38.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:15:38.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:15:38.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:39.410+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:15:39.406+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:15:39.411+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:15:39.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T18:16:09.709+0000] {processor.py:186} INFO - Started process (PID=490) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:09.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:16:09.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:16:09.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:10.443+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:16:10.440+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:16:10.444+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:10.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.784 seconds
[2025-01-13T18:16:41.132+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:41.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:16:41.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:16:41.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:41.899+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:16:41.895+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:16:41.900+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:16:41.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.812 seconds
[2025-01-13T18:17:12.394+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:12.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:17:12.399+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:17:12.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:13.110+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:17:13.107+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:17:13.110+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:13.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.766 seconds
[2025-01-13T18:17:43.558+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:43.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:17:43.562+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:17:43.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:44.297+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:17:44.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:17:44.297+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:17:44.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T18:18:14.503+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:14.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:18:14.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:18:14.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:15.267+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:18:15.263+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:18:15.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:15.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.817 seconds
[2025-01-13T18:18:45.718+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:45.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:18:45.724+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:18:45.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:46.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:18:46.456+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:18:46.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:18:46.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.796 seconds
[2025-01-13T18:19:16.936+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:16.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:19:16.942+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:19:16.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:17.693+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:19:17.689+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:19:17.693+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:17.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.790 seconds
[2025-01-13T18:19:47.869+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:47.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:19:47.877+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:19:47.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:48.664+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:19:48.659+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:19:48.665+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:19:48.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.827 seconds
[2025-01-13T18:20:19.267+0000] {processor.py:186} INFO - Started process (PID=506) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:19.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:20:19.272+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:19.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:20.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:20.051+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:20:20.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:20.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.848 seconds
[2025-01-13T18:20:50.746+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:50.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:20:50.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:50.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:51.879+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:51.875+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:20:51.880+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:51.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.191 seconds
[2025-01-13T18:20:55.069+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:55.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:20:55.073+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:55.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:55.725+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:20:55.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:20:55.725+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:20:55.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.692 seconds
[2025-01-13T18:21:26.209+0000] {processor.py:186} INFO - Started process (PID=512) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:26.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:21:26.212+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:21:26.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:26.906+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:21:26.904+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:21:26.907+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:26.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.731 seconds
[2025-01-13T18:21:57.351+0000] {processor.py:186} INFO - Started process (PID=514) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:57.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:21:57.356+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:21:57.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:58.074+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:21:58.072+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:21:58.075+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:21:58.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T18:22:28.835+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:22:28.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:22:28.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:22:28.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:22:29.653+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:22:29.650+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:22:29.653+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:22:29.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.879 seconds
[2025-01-13T18:23:00.781+0000] {processor.py:186} INFO - Started process (PID=518) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:00.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:23:00.787+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:23:00.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:02.133+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:23:02.125+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:23:02.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:02.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.432 seconds
[2025-01-13T18:23:32.415+0000] {processor.py:186} INFO - Started process (PID=520) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:32.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:23:32.422+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:23:32.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:33.287+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:23:33.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:23:33.288+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:23:33.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.928 seconds
[2025-01-13T18:24:01.978+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:01.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:24:01.983+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:01.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:01.992+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:01.991+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 846, in exec_module
  File "<frozen importlib._bootstrap_external>", line 983, in get_code
  File "<frozen importlib._bootstrap_external>", line 913, in source_to_code
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 47
    )
    ^
SyntaxError: invalid syntax
[2025-01-13T18:24:01.993+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:02.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.079 seconds
[2025-01-13T18:24:13.386+0000] {processor.py:186} INFO - Started process (PID=523) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:13.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:24:13.391+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:13.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:14.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:14.350+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:24:14.356+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:14.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.024 seconds
[2025-01-13T18:24:30.951+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:30.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:24:30.964+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:30.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:31.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:24:31.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:24:31.683+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:24:31.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.770 seconds
[2025-01-13T18:25:02.238+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:02.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:25:02.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:25:02.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:02.965+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:25:02.963+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:25:02.966+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:02.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.761 seconds
[2025-01-13T18:25:33.449+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:33.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:25:33.461+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:25:33.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:34.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:25:34.195+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:25:34.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:25:34.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.800 seconds
[2025-01-13T18:26:04.919+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:04.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:26:04.926+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:26:04.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:06.232+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:26:06.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:26:06.233+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:06.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.416 seconds
[2025-01-13T18:26:36.958+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:36.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:26:36.962+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:26:36.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:37.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:26:37.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T18:26:37.684+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:26:37.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.762 seconds
[2025-01-13T18:27:08.673+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T18:27:08.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T18:27:08.678+0000] {logging_mixin.py:190} INFO - [2025-01-13T18:27:08.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T19:59:59.719+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T19:59:59.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T19:59:59.725+0000] {logging_mixin.py:190} INFO - [2025-01-13T19:59:59.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:00:00.706+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:00:00.700+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:00:00.706+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:00:00.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.053 seconds
[2025-01-13T20:00:31.194+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:00:31.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:00:31.198+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:00:31.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:00:31.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:00:31.923+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:00:31.927+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:00:31.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.780 seconds
[2025-01-13T20:01:02.712+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:02.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:01:02.724+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:01:02.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:03.496+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:01:03.493+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:01:03.496+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:03.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.829 seconds
[2025-01-13T20:01:34.127+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:34.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:01:34.131+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:01:34.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:34.878+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:01:34.875+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:01:34.879+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:01:34.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.809 seconds
[2025-01-13T20:02:05.534+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:05.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:02:05.540+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:02:05.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:06.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:02:06.343+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:02:06.348+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:06.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.852 seconds
[2025-01-13T20:02:36.926+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:36.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:02:36.930+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:02:36.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:37.640+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:02:37.637+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:02:37.640+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:02:37.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.748 seconds
[2025-01-13T20:03:08.075+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:08.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:03:08.078+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:03:08.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:08.779+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:03:08.776+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:03:08.779+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:08.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.737 seconds
[2025-01-13T20:03:39.196+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:39.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:03:39.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:03:39.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:39.859+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:03:39.853+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:03:39.860+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:03:39.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.697 seconds
[2025-01-13T20:04:10.085+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:10.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:04:10.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:04:10.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:10.773+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:04:10.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:04:10.773+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:10.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.718 seconds
[2025-01-13T20:04:41.263+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:41.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:04:41.267+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:04:41.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:42.001+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:04:41.998+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:04:42.001+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:04:42.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.778 seconds
[2025-01-13T20:05:12.107+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:12.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:05:12.110+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:05:12.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:12.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:05:12.804+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:05:12.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:12.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-13T20:05:43.262+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:43.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:05:43.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:05:43.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:43.994+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:05:43.991+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:05:43.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:05:44.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T20:06:14.238+0000] {processor.py:186} INFO - Started process (PID=561) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:14.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:06:14.241+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:06:14.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:14.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:06:14.966+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:06:14.971+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:14.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.767 seconds
[2025-01-13T20:06:45.492+0000] {processor.py:186} INFO - Started process (PID=563) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:45.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:06:45.496+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:06:45.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:46.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:06:46.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:06:46.153+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:06:46.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.702 seconds
[2025-01-13T20:07:16.665+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:16.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:07:16.673+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:07:16.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:17.410+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:07:17.407+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:07:17.410+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:17.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.785 seconds
[2025-01-13T20:07:47.681+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:47.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:07:47.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:07:47.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:48.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:07:48.392+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:07:48.395+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:07:48.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.771 seconds
[2025-01-13T20:08:18.872+0000] {processor.py:186} INFO - Started process (PID=569) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:18.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:08:18.875+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:08:18.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:19.548+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:08:19.545+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:08:19.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:19.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T20:08:49.680+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:49.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:08:49.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:08:49.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:50.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:08:50.343+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:08:50.350+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:08:50.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.707 seconds
[2025-01-13T20:09:20.811+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:20.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:09:20.816+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:09:20.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:21.483+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:09:21.481+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:09:21.484+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:21.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.719 seconds
[2025-01-13T20:09:51.861+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:51.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:09:51.864+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:09:51.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:52.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:09:52.511+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:09:52.520+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:09:52.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.690 seconds
[2025-01-13T20:10:23.057+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:23.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:10:23.063+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:10:23.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:23.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:10:23.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:10:23.757+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:23.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.733 seconds
[2025-01-13T20:10:55.074+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:55.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:10:55.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:10:55.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:55.977+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:10:55.973+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:10:55.977+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:10:56.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.048 seconds
[2025-01-13T20:11:26.659+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:11:26.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:11:26.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:11:26.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:11:27.360+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:11:27.351+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:11:27.361+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:11:27.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T20:37:19.402+0000] {processor.py:186} INFO - Started process (PID=583) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:19.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:37:19.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:37:19.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:19.809+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:37:19.807+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:37:19.810+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:19.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.427 seconds
[2025-01-13T20:37:50.076+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:50.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:37:50.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:37:50.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:50.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:37:50.702+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:37:50.704+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:37:50.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.657 seconds
[2025-01-13T20:38:21.149+0000] {processor.py:186} INFO - Started process (PID=587) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:21.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:38:21.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:38:21.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:21.885+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:38:21.883+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:38:21.886+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:21.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.766 seconds
[2025-01-13T20:38:52.391+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:52.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:38:52.394+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:38:52.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:53.091+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:38:53.088+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:38:53.092+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:38:53.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.727 seconds
[2025-01-13T20:39:23.536+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:23.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:39:23.540+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:39:23.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:24.284+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:39:24.281+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:39:24.284+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:24.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.791 seconds
[2025-01-13T20:39:54.638+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:54.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:39:54.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:39:54.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:55.283+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:39:55.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:39:55.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:39:55.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.675 seconds
[2025-01-13T20:40:25.724+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:25.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:40:25.728+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:40:25.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:26.521+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:40:26.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:40:26.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:26.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.838 seconds
[2025-01-13T20:40:57.042+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:57.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:40:57.049+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:40:57.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:57.802+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:40:57.796+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:40:57.802+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:40:57.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.832 seconds
[2025-01-13T20:41:28.322+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:28.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:41:28.329+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:41:28.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:29.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:41:29.018+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:41:29.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:29.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.773 seconds
[2025-01-13T20:41:59.164+0000] {processor.py:186} INFO - Started process (PID=601) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:59.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:41:59.168+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:41:59.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:59.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:41:59.864+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:41:59.868+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:41:59.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.737 seconds
[2025-01-13T20:42:30.337+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:42:30.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:42:30.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:42:30.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:42:31.059+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:42:31.056+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:42:31.060+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:42:31.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.795 seconds
[2025-01-13T20:43:01.327+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:01.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:43:01.333+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:43:01.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:02.041+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:43:02.039+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:43:02.042+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:02.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.769 seconds
[2025-01-13T20:43:32.538+0000] {processor.py:186} INFO - Started process (PID=607) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:32.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:43:32.542+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:43:32.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:33.241+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:43:33.238+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:43:33.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:43:33.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.735 seconds
[2025-01-13T20:44:03.729+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:03.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:44:03.733+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:44:03.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:04.411+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:44:04.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:44:04.412+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:04.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.716 seconds
[2025-01-13T20:44:35.039+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:35.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:44:35.044+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:44:35.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:35.872+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:44:35.868+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:44:35.873+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:44:35.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.909 seconds
[2025-01-13T20:45:06.791+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:06.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:45:06.795+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:45:06.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:07.603+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:45:07.597+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:45:07.603+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:07.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.854 seconds
[2025-01-13T20:45:38.237+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:38.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:45:38.240+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:45:38.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:38.937+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:45:38.934+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:45:38.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:45:38.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.736 seconds
[2025-01-13T20:46:09.499+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:09.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:46:09.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:46:09.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:10.286+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:46:10.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:46:10.287+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:10.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.825 seconds
[2025-01-13T20:46:40.844+0000] {processor.py:186} INFO - Started process (PID=619) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:40.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:46:40.848+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:46:40.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:41.537+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:46:41.532+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:46:41.537+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:46:41.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-13T20:47:12.030+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:12.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:47:12.034+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:47:12.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:12.726+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:47:12.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:47:12.726+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:12.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.731 seconds
[2025-01-13T20:47:43.259+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:43.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:47:43.263+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:47:43.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:43.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:47:43.977+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:47:43.981+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:47:44.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.758 seconds
[2025-01-13T20:48:14.443+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:14.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:48:14.446+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:48:14.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:15.177+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:48:15.174+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:48:15.177+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:15.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.781 seconds
[2025-01-13T20:48:45.478+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:45.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:48:45.483+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:48:45.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:46.302+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:48:46.299+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:48:46.302+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:48:46.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.888 seconds
[2025-01-13T20:49:16.918+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:16.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:49:16.924+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:49:16.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:17.578+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:49:17.575+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:49:17.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:17.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.721 seconds
[2025-01-13T20:49:48.151+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:48.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:49:48.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:49:48.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:48.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:49:48.860+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:49:48.863+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:49:48.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.748 seconds
[2025-01-13T20:50:19.327+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:19.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:50:19.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:50:19.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:20.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:50:20.059+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:50:20.062+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:20.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.777 seconds
[2025-01-13T20:50:50.556+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:50.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:50:50.560+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:50:50.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:51.282+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:50:51.279+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:50:51.282+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:50:51.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.784 seconds
[2025-01-13T20:51:21.426+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:21.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:51:21.430+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:51:21.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:22.143+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:51:22.140+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:51:22.144+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:22.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.765 seconds
[2025-01-13T20:51:52.734+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:52.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:51:52.738+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:51:52.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:53.509+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:51:53.504+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:51:53.510+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:51:53.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.818 seconds
[2025-01-13T20:52:23.646+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:23.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:52:23.650+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:52:23.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:24.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:52:24.346+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:52:24.349+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:24.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.740 seconds
[2025-01-13T20:52:54.691+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:54.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:52:54.696+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:52:54.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:55.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:52:55.365+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:52:55.370+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:52:55.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.760 seconds
[2025-01-13T20:53:25.883+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:25.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:53:25.886+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:53:25.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:26.589+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:53:26.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:53:26.589+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:26.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.738 seconds
[2025-01-13T20:53:57.089+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:57.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:53:57.093+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:53:57.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:57.758+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:53:57.754+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:53:57.758+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:53:57.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.704 seconds
[2025-01-13T20:54:28.276+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:28.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:54:28.280+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:54:28.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:28.956+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:54:28.952+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:54:28.956+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:28.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.732 seconds
[2025-01-13T20:54:59.161+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:59.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:54:59.166+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:54:59.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:59.835+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:54:59.832+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:54:59.836+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:54:59.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.721 seconds
[2025-01-13T20:55:30.309+0000] {processor.py:186} INFO - Started process (PID=653) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:55:30.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:55:30.313+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:55:30.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:55:30.975+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:55:30.972+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:55:30.975+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:55:31.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T20:56:01.324+0000] {processor.py:186} INFO - Started process (PID=655) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:01.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:56:01.329+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:56:01.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:02.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:56:02.019+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:56:02.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:02.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.743 seconds
[2025-01-13T20:56:32.584+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:32.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:56:32.589+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:56:32.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:33.269+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:56:33.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:56:33.269+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:56:33.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.720 seconds
[2025-01-13T20:57:03.783+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:03.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:57:03.790+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:57:03.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:04.490+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:57:04.487+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:57:04.491+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:04.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.768 seconds
[2025-01-13T20:57:35.026+0000] {processor.py:186} INFO - Started process (PID=661) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:35.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:57:35.036+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:57:35.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:35.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:57:35.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:57:35.816+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:57:35.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.851 seconds
[2025-01-13T20:58:06.324+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:06.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:58:06.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:58:06.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:07.019+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:58:07.010+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:58:07.019+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:07.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.747 seconds
[2025-01-13T20:58:37.327+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:37.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:58:37.332+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:58:37.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:38.014+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:58:38.010+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:58:38.014+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:58:38.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.756 seconds
[2025-01-13T20:59:08.814+0000] {processor.py:186} INFO - Started process (PID=667) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:08.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:59:08.818+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:59:08.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:09.616+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:59:09.610+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:59:09.616+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:09.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.866 seconds
[2025-01-13T20:59:40.300+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:40.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T20:59:40.305+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:59:40.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:41.014+0000] {logging_mixin.py:190} INFO - [2025-01-13T20:59:41.010+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T20:59:41.014+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T20:59:41.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.871 seconds
[2025-01-13T21:00:11.737+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:11.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:00:11.742+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:00:11.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:12.596+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:00:12.593+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:00:12.597+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:12.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.899 seconds
[2025-01-13T21:00:43.342+0000] {processor.py:186} INFO - Started process (PID=673) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:43.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:00:43.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:00:43.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:44.103+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:00:44.100+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:00:44.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:00:44.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.816 seconds
[2025-01-13T21:01:14.692+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:14.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:01:14.697+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:01:14.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:15.336+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:01:15.333+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:01:15.336+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:15.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.682 seconds
[2025-01-13T21:01:45.887+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:45.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:01:45.893+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:01:45.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:46.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:01:46.708+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:01:46.712+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:01:46.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.886 seconds
[2025-01-13T21:02:17.465+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:17.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:02:17.470+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:02:17.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:18.176+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:02:18.172+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:02:18.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:18.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.751 seconds
[2025-01-13T21:02:48.799+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:48.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:02:48.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:02:48.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:50.919+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:02:50.915+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:02:50.920+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:02:50.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 2.179 seconds
[2025-01-13T21:03:21.743+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:21.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:03:21.748+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:03:21.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:22.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:03:22.348+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:03:22.352+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:22.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.650 seconds
[2025-01-13T21:03:52.665+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:52.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:03:52.669+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:03:52.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:53.530+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:03:53.526+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:03:53.531+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:03:53.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.909 seconds
[2025-01-13T21:04:24.050+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:24.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:04:24.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:04:24.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:24.752+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:04:24.749+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:04:24.753+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:24.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.744 seconds
[2025-01-13T21:04:55.236+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:55.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:04:55.241+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:04:55.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:55.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:04:55.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:04:55.950+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:04:55.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.752 seconds
[2025-01-13T21:05:26.161+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:26.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:05:26.165+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:05:26.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:26.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:05:26.864+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:05:26.868+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:26.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.743 seconds
[2025-01-13T21:05:57.383+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:57.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:05:57.388+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:05:57.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:58.086+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:05:58.079+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:05:58.086+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:05:58.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.751 seconds
[2025-01-13T21:06:28.262+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:06:28.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:06:28.266+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:06:28.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:06:29.013+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:06:29.009+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:06:29.013+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:06:29.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.785 seconds
[2025-01-13T21:06:59.516+0000] {processor.py:186} INFO - Started process (PID=697) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:06:59.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:06:59.522+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:06:59.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:07:00.266+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:07:00.259+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:07:00.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:07:00.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.805 seconds
[2025-01-13T21:07:30.623+0000] {processor.py:186} INFO - Started process (PID=699) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:07:30.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:07:30.637+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:07:30.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:07:31.386+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:07:31.382+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:07:31.387+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:07:31.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.814 seconds
[2025-01-13T21:08:01.859+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:01.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:08:01.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:08:01.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:02.538+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:08:02.535+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:08:02.538+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:02.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.710 seconds
[2025-01-13T21:08:33.140+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:33.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:08:33.145+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:08:33.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:34.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:08:34.017+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:08:34.021+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:08:34.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.961 seconds
[2025-01-13T21:09:04.562+0000] {processor.py:186} INFO - Started process (PID=705) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:04.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:09:04.567+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:09:04.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:05.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:09:05.331+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:09:05.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:05.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.873 seconds
[2025-01-13T21:09:35.893+0000] {processor.py:186} INFO - Started process (PID=707) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:35.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:09:35.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:09:35.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:36.613+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:09:36.610+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:09:36.613+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:09:36.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.774 seconds
[2025-01-13T21:10:06.787+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:06.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:10:06.794+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:10:06.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:07.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:10:07.490+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:10:07.495+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:07.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.749 seconds
[2025-01-13T21:10:38.199+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:38.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:10:38.205+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:10:38.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:38.997+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:10:38.994+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:10:38.997+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:10:39.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.857 seconds
[2025-01-13T21:11:09.580+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:09.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:11:09.584+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:11:09.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:10.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:11:10.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:11:10.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:10.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.673 seconds
[2025-01-13T21:11:40.710+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:40.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:11:40.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:11:40.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:41.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:11:41.339+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:11:41.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:11:41.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.667 seconds
[2025-01-13T21:12:11.417+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:11.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:12:11.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:12:11.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:12.122+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:12:12.119+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:12:12.122+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:12.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.740 seconds
[2025-01-13T21:12:42.554+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:42.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:12:42.558+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:12:42.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:43.227+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:12:43.219+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:12:43.228+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:12:43.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.726 seconds
[2025-01-13T21:13:14.160+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:14.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:13:14.166+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:13:14.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:14.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:13:14.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:13:14.920+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:14.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.807 seconds
[2025-01-13T21:13:45.539+0000] {processor.py:186} INFO - Started process (PID=723) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:45.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:13:45.544+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:13:45.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:46.236+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:13:46.233+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:13:46.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:13:46.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.750 seconds
[2025-01-13T21:14:16.723+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:16.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:14:16.728+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:14:16.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:17.430+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:14:17.427+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:14:17.431+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:17.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.742 seconds
[2025-01-13T21:14:47.877+0000] {processor.py:186} INFO - Started process (PID=727) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:47.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:14:47.888+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:14:47.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:48.649+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:14:48.644+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:14:48.650+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:14:48.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.881 seconds
[2025-01-13T21:15:19.321+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:19.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:15:19.326+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:15:19.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:20.144+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:15:20.139+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:15:20.144+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:20.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.883 seconds
[2025-01-13T21:15:50.758+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:50.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:15:50.776+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:15:50.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:51.585+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:15:51.572+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:15:51.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:15:51.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.886 seconds
[2025-01-13T21:16:22.063+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:22.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:16:22.074+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:16:22.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:22.747+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:16:22.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:16:22.747+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:22.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.733 seconds
[2025-01-13T21:16:53.062+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:53.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:16:53.072+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:16:53.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:53.781+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:16:53.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:16:53.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:16:53.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.759 seconds
[2025-01-13T21:17:24.327+0000] {processor.py:186} INFO - Started process (PID=737) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:24.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:17:24.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:17:24.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:25.004+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:17:25.002+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:17:25.005+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:25.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.710 seconds
[2025-01-13T21:17:55.499+0000] {processor.py:186} INFO - Started process (PID=739) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:55.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:17:55.504+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:17:55.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:56.155+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:17:56.152+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:17:56.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:17:56.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.706 seconds
[2025-01-13T21:18:26.683+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:26.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:18:26.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:18:26.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:27.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:18:27.353+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:18:27.356+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:27.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.713 seconds
[2025-01-13T21:18:57.821+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:57.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:18:57.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:18:57.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:58.546+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:18:58.543+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:18:58.547+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:18:58.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.757 seconds
[2025-01-13T21:19:28.917+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:19:28.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:19:28.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:19:28.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:19:29.595+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:19:29.588+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:19:29.596+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:19:29.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.730 seconds
[2025-01-13T21:20:00.075+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:00.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:20:00.078+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:20:00.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:00.794+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:20:00.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:20:00.795+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:00.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.773 seconds
[2025-01-13T21:20:30.957+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:30.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:20:30.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:20:30.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:31.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:20:31.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:20:31.661+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:20:31.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.746 seconds
[2025-01-13T21:21:02.157+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:02.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:21:02.162+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:21:02.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:02.901+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:21:02.897+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:21:02.902+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:02.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.798 seconds
[2025-01-13T21:21:33.102+0000] {processor.py:186} INFO - Started process (PID=753) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:33.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:21:33.106+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:21:33.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:33.763+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:21:33.756+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:21:33.764+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:21:33.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.704 seconds
[2025-01-13T21:22:04.450+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:04.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:22:04.453+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:22:04.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:04.848+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:22:04.845+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:22:04.849+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:04.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.712 seconds
[2025-01-13T21:22:35.170+0000] {processor.py:186} INFO - Started process (PID=757) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:35.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:22:35.175+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:22:35.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:35.645+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:22:35.641+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:22:35.645+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:22:35.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T21:23:05.796+0000] {processor.py:186} INFO - Started process (PID=759) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:05.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:23:05.801+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:23:05.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:06.266+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:23:06.263+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:23:06.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:06.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T21:23:36.475+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:36.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:23:36.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:23:36.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:36.940+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:23:36.937+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:23:36.941+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:23:36.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.523 seconds
[2025-01-13T21:24:07.154+0000] {processor.py:186} INFO - Started process (PID=763) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:07.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:24:07.160+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:24:07.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:07.627+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:24:07.623+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:24:07.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:07.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.542 seconds
[2025-01-13T21:24:37.761+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:37.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:24:37.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:24:37.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:38.272+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:24:38.268+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:24:38.272+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:24:38.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.550 seconds
[2025-01-13T21:25:08.491+0000] {processor.py:186} INFO - Started process (PID=767) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:08.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:25:08.495+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:25:08.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:09.006+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:25:09.003+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:25:09.007+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:09.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.565 seconds
[2025-01-13T21:25:39.507+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:39.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:25:39.511+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:25:39.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:39.994+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:25:39.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:25:39.995+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:25:40.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.531 seconds
[2025-01-13T21:26:10.521+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:10.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:26:10.544+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:26:10.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:10.986+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:26:10.983+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:26:10.987+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:11.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-13T21:26:41.548+0000] {processor.py:186} INFO - Started process (PID=773) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:41.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:26:41.553+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:26:41.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:42.176+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:26:42.172+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:26:42.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:26:42.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.663 seconds
[2025-01-13T21:27:12.637+0000] {processor.py:186} INFO - Started process (PID=775) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:12.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:27:12.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:27:12.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:13.119+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:27:13.116+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:27:13.120+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:13.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-13T21:27:43.665+0000] {processor.py:186} INFO - Started process (PID=777) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:43.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:27:43.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:27:43.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:44.151+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:27:44.148+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:27:44.152+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:27:44.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.540 seconds
[2025-01-13T21:28:14.489+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:14.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:28:14.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:28:14.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:14.983+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:28:14.979+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:28:14.984+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:15.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.536 seconds
[2025-01-13T21:28:45.425+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:45.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:28:45.430+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:28:45.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:45.915+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:28:45.911+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:28:45.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:28:45.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.529 seconds
[2025-01-13T21:29:16.400+0000] {processor.py:186} INFO - Started process (PID=783) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:16.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:29:16.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:29:16.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:16.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:29:16.910+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:29:16.914+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:16.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.582 seconds
[2025-01-13T21:29:47.456+0000] {processor.py:186} INFO - Started process (PID=785) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:47.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:29:47.461+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:29:47.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:47.946+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:29:47.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:29:47.947+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:29:47.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.526 seconds
[2025-01-13T21:30:18.130+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:18.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:30:18.134+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:30:18.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:18.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:30:18.648+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:30:18.651+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:18.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.559 seconds
[2025-01-13T21:30:48.933+0000] {processor.py:186} INFO - Started process (PID=789) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:48.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:30:48.939+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:30:48.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:49.513+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:30:49.510+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:30:49.514+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:30:49.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.627 seconds
[2025-01-13T21:31:19.996+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:20.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:31:20.006+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:31:20.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:20.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:31:20.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:31:20.482+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:20.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-13T21:31:50.836+0000] {processor.py:186} INFO - Started process (PID=793) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:50.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:31:50.839+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:31:50.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:51.300+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:31:51.296+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:31:51.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:31:51.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T21:32:51.295+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:32:51.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:32:51.299+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:32:51.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:32:51.759+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:32:51.756+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:32:51.759+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:32:51.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-13T21:33:22.323+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:22.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:33:22.328+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:33:22.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:22.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:33:22.748+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:33:22.755+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:22.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T21:33:53.216+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:53.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:33:53.222+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:33:53.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:53.707+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:33:53.704+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:33:53.708+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:33:53.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.554 seconds
[2025-01-13T21:34:24.158+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:24.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:34:24.162+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:34:24.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:24.718+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:34:24.715+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:34:24.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:24.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.608 seconds
[2025-01-13T21:34:55.251+0000] {processor.py:186} INFO - Started process (PID=803) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:55.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:34:55.258+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:34:55.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:56.092+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:34:56.085+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:34:56.092+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:34:56.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.916 seconds
[2025-01-13T21:35:26.689+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:26.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:35:26.694+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:35:26.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:27.162+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:35:27.158+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:35:27.162+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:27.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.519 seconds
[2025-01-13T21:35:57.607+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:57.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:35:57.614+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:35:57.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:58.083+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:35:58.080+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:35:58.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:35:58.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.527 seconds
[2025-01-13T21:36:28.538+0000] {processor.py:186} INFO - Started process (PID=809) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:36:28.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:36:28.543+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:36:28.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:36:29.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:36:29.040+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:36:29.044+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:36:29.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.555 seconds
[2025-01-13T21:36:59.481+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:36:59.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:36:59.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:36:59.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:36:59.994+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:36:59.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:36:59.995+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:37:00.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.585 seconds
[2025-01-13T21:37:30.500+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:37:30.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:37:30.504+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:37:30.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:37:30.991+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:37:30.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:37:30.991+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:37:31.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.529 seconds
[2025-01-13T21:38:01.599+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:01.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:38:01.605+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:38:01.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:02.105+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:38:02.102+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:38:02.106+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:02.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.546 seconds
[2025-01-13T21:38:32.509+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:32.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:38:32.514+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:38:32.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:33.003+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:38:32.999+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:38:33.003+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:38:33.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.587 seconds
[2025-01-13T21:39:03.655+0000] {processor.py:186} INFO - Started process (PID=819) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:03.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:39:03.662+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:39:03.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:04.181+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:39:04.178+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:39:04.181+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:04.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.582 seconds
[2025-01-13T21:39:34.356+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:34.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:39:34.361+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:39:34.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:34.920+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:39:34.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:39:34.921+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:39:34.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.608 seconds
[2025-01-13T21:40:05.172+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:05.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:40:05.177+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:40:05.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:05.636+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:40:05.628+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:40:05.637+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:05.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.510 seconds
[2025-01-13T21:40:35.829+0000] {processor.py:186} INFO - Started process (PID=825) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:35.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:40:35.835+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:40:35.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:36.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:40:36.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:40:36.341+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:40:36.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.553 seconds
[2025-01-13T21:41:06.740+0000] {processor.py:186} INFO - Started process (PID=827) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:06.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:41:06.745+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:41:06.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:07.215+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:41:07.211+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:41:07.215+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:07.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-13T21:41:37.371+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:37.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:41:37.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:41:37.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:37.849+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:41:37.843+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:41:37.850+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:41:37.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-13T21:42:08.112+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:08.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:42:08.120+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:42:08.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:08.629+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:42:08.626+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:42:08.630+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:08.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.566 seconds
[2025-01-13T21:42:39.212+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:39.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:42:39.226+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:42:39.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:39.897+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:42:39.892+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:42:39.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:42:40.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.971 seconds
[2025-01-13T21:43:10.680+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:10.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:43:10.686+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:43:10.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:11.201+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:43:11.198+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:43:11.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:11.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.573 seconds
[2025-01-13T21:43:41.515+0000] {processor.py:186} INFO - Started process (PID=837) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:41.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:43:41.521+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:43:41.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:41.985+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:43:41.981+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:43:41.985+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:43:42.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.553 seconds
[2025-01-13T21:44:12.187+0000] {processor.py:186} INFO - Started process (PID=839) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:12.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:44:12.198+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:44:12.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:12.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:44:12.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:44:12.684+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:12.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.548 seconds
[2025-01-13T21:44:43.039+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:43.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:44:43.045+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:44:43.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:43.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:44:43.486+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:44:43.490+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:44:43.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T21:45:13.959+0000] {processor.py:186} INFO - Started process (PID=843) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:13.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:45:13.973+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:45:13.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:14.465+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:45:14.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:45:14.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:14.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.559 seconds
[2025-01-13T21:45:44.866+0000] {processor.py:186} INFO - Started process (PID=845) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:44.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:45:44.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:45:44.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:45.313+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:45:45.309+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:45:45.314+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:45:45.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T21:46:15.781+0000] {processor.py:186} INFO - Started process (PID=847) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:15.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:46:15.787+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:46:15.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:16.227+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:46:16.223+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:46:16.227+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:16.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.507 seconds
[2025-01-13T21:46:46.788+0000] {processor.py:186} INFO - Started process (PID=849) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:46.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:46:46.793+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:46:46.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:47.244+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:46:47.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:46:47.245+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:46:47.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.492 seconds
[2025-01-13T21:47:17.745+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:17.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:47:17.752+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:47:17.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:18.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:47:18.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:47:18.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:18.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.534 seconds
[2025-01-13T21:47:48.944+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:48.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:47:48.948+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:47:48.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:49.444+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:47:49.441+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:47:49.445+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:47:49.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.561 seconds
[2025-01-13T21:48:19.898+0000] {processor.py:186} INFO - Started process (PID=855) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:19.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:48:19.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:48:19.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:20.440+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:48:20.437+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:48:20.441+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:20.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.617 seconds
[2025-01-13T21:48:51.259+0000] {processor.py:186} INFO - Started process (PID=857) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:51.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:48:51.264+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:48:51.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:51.743+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:48:51.740+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:48:51.743+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:48:51.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.541 seconds
[2025-01-13T21:49:21.951+0000] {processor.py:186} INFO - Started process (PID=859) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:21.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:49:21.956+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:49:21.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:22.473+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:49:22.469+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:49:22.473+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:22.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.583 seconds
[2025-01-13T21:49:53.040+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:53.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:49:53.044+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:49:53.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:53.529+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:49:53.526+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:49:53.529+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:49:53.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.531 seconds
[2025-01-13T21:50:24.170+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:24.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:50:24.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:50:24.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:24.658+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:50:24.655+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:50:24.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:24.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.540 seconds
[2025-01-13T21:50:54.932+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:54.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:50:54.938+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:50:54.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:55.650+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:50:55.645+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:50:55.650+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:50:55.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.804 seconds
[2025-01-13T21:51:26.517+0000] {processor.py:186} INFO - Started process (PID=867) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:26.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:51:26.522+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:51:26.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:27.003+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:51:27.000+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:51:27.004+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:27.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.530 seconds
[2025-01-13T21:51:57.484+0000] {processor.py:186} INFO - Started process (PID=869) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:57.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:51:57.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:51:57.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:57.923+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:51:57.920+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:51:57.923+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:51:57.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.489 seconds
[2025-01-13T21:52:28.384+0000] {processor.py:186} INFO - Started process (PID=871) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:28.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:52:28.388+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:52:28.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:28.853+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:52:28.848+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:52:28.854+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:28.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.517 seconds
[2025-01-13T21:52:59.296+0000] {processor.py:186} INFO - Started process (PID=873) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:59.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:52:59.302+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:52:59.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:59.790+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:52:59.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:52:59.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:52:59.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.559 seconds
[2025-01-13T21:53:30.224+0000] {processor.py:186} INFO - Started process (PID=875) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:53:30.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:53:30.228+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:53:30.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:53:30.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:53:30.663+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:53:30.667+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:53:30.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.487 seconds
[2025-01-13T21:54:01.162+0000] {processor.py:186} INFO - Started process (PID=877) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:01.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:54:01.180+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:54:01.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:01.662+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:54:01.658+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:54:01.662+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:01.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
[2025-01-13T21:54:32.087+0000] {processor.py:186} INFO - Started process (PID=879) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:32.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:54:32.092+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:54:32.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:32.557+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:54:32.553+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:54:32.557+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:54:32.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-13T21:55:03.075+0000] {processor.py:186} INFO - Started process (PID=881) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:03.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:55:03.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:55:03.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:03.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:55:03.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:55:03.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:03.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T21:55:33.970+0000] {processor.py:186} INFO - Started process (PID=883) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:33.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:55:33.978+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:55:33.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:34.446+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:55:34.443+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:55:34.447+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:55:34.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.529 seconds
[2025-01-13T21:56:04.901+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:04.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:56:04.905+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:56:04.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:05.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:56:05.417+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:56:05.421+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:05.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.554 seconds
[2025-01-13T21:56:35.879+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:35.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:56:35.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:56:35.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:36.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:56:36.369+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:56:36.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:56:36.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.538 seconds
[2025-01-13T21:57:06.877+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:06.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:57:06.896+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:57:06.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:07.336+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:57:07.333+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:57:07.336+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:07.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T21:57:37.710+0000] {processor.py:186} INFO - Started process (PID=891) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:37.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:57:37.713+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:57:37.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:38.135+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:57:38.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:57:38.136+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:57:38.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.474 seconds
[2025-01-13T21:58:08.654+0000] {processor.py:186} INFO - Started process (PID=893) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:08.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:58:08.658+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:58:08.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:09.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:58:09.134+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:58:09.138+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:09.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.518 seconds
[2025-01-13T21:58:39.453+0000] {processor.py:186} INFO - Started process (PID=895) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:39.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:58:39.456+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:58:39.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:39.911+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:58:39.908+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:58:39.912+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:58:39.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.498 seconds
[2025-01-13T21:59:10.413+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:10.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:59:10.418+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:59:10.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:10.885+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:59:10.882+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:59:10.886+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:10.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.540 seconds
[2025-01-13T21:59:41.307+0000] {processor.py:186} INFO - Started process (PID=899) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:41.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T21:59:41.310+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:59:41.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:41.768+0000] {logging_mixin.py:190} INFO - [2025-01-13T21:59:41.765+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T21:59:41.769+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T21:59:41.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-13T22:00:12.199+0000] {processor.py:186} INFO - Started process (PID=901) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:12.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:00:12.204+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:00:12.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:12.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:00:12.699+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:00:12.704+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:12.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.562 seconds
[2025-01-13T22:00:43.354+0000] {processor.py:186} INFO - Started process (PID=903) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:43.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:00:43.359+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:00:43.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:43.845+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:00:43.841+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:00:43.845+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:00:43.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.550 seconds
[2025-01-13T22:01:14.354+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:14.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:01:14.359+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:01:14.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:14.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:01:14.856+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:01:14.862+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:14.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.574 seconds
[2025-01-13T22:01:45.324+0000] {processor.py:186} INFO - Started process (PID=907) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:45.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:01:45.328+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:01:45.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:45.809+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:01:45.800+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:01:45.810+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:01:45.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.545 seconds
[2025-01-13T22:02:16.465+0000] {processor.py:186} INFO - Started process (PID=909) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:16.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:02:16.470+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:02:16.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:17.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:02:17.286+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:02:17.291+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:17.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.915 seconds
[2025-01-13T22:02:47.918+0000] {processor.py:186} INFO - Started process (PID=911) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:47.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:02:47.926+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:02:47.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:48.436+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:02:48.432+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:02:48.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:02:48.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.592 seconds
[2025-01-13T22:03:19.020+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:19.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:03:19.024+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:03:19.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:19.494+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:03:19.490+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:03:19.494+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:19.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T22:03:50.153+0000] {processor.py:186} INFO - Started process (PID=915) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:50.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:03:50.157+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:03:50.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:50.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:03:50.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:03:50.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:03:50.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.559 seconds
[2025-01-13T22:04:20.984+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:20.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:04:20.991+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:04:20.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:21.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:04:21.438+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:04:21.442+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:21.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.519 seconds
[2025-01-13T22:04:51.903+0000] {processor.py:186} INFO - Started process (PID=919) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:51.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:04:51.908+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:04:51.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:52.423+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:04:52.420+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:04:52.424+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:04:52.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.557 seconds
[2025-01-13T22:05:22.988+0000] {processor.py:186} INFO - Started process (PID=921) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:22.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:05:22.994+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:05:22.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:23.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:05:23.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:05:23.482+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:23.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.555 seconds
[2025-01-13T22:05:53.677+0000] {processor.py:186} INFO - Started process (PID=923) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:53.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:05:53.682+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:05:53.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:54.123+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:05:54.120+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:05:54.124+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:05:54.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.501 seconds
[2025-01-13T22:06:24.610+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:24.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:06:24.615+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:06:24.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:25.091+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:06:25.084+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:06:25.092+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:25.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.547 seconds
[2025-01-13T22:06:55.594+0000] {processor.py:186} INFO - Started process (PID=927) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:55.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:06:55.598+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:06:55.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:56.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:06:56.147+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:06:56.154+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:06:56.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.626 seconds
[2025-01-13T22:07:26.863+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:26.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:07:26.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:07:26.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:27.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:07:27.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:07:27.551+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:27.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.766 seconds
[2025-01-13T22:07:58.122+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:58.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:07:58.127+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:07:58.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:58.636+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:07:58.632+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:07:58.637+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:07:58.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
[2025-01-13T22:08:28.841+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:08:28.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:08:28.853+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:08:28.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:08:29.312+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:08:29.309+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:08:29.313+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:08:29.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.511 seconds
[2025-01-13T22:08:59.539+0000] {processor.py:186} INFO - Started process (PID=935) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:08:59.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:08:59.544+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:08:59.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:09:00.041+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:09:00.024+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:09:00.042+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:09:00.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.545 seconds
[2025-01-13T22:09:30.186+0000] {processor.py:186} INFO - Started process (PID=937) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:09:30.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:09:30.193+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:09:30.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:09:30.688+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:09:30.685+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:09:30.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:09:30.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
[2025-01-13T22:10:00.934+0000] {processor.py:186} INFO - Started process (PID=939) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:00.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:10:00.939+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:10:00.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:01.402+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:10:01.397+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:10:01.403+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:01.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.523 seconds
[2025-01-13T22:10:31.561+0000] {processor.py:186} INFO - Started process (PID=941) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:31.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:10:31.567+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:10:31.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:32.056+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:10:32.052+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:10:32.056+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:10:32.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.538 seconds
[2025-01-13T22:11:02.182+0000] {processor.py:186} INFO - Started process (PID=943) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:02.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:11:02.189+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:11:02.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:02.714+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:11:02.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:11:02.715+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:02.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.572 seconds
[2025-01-13T22:11:33.019+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:33.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:11:33.026+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:11:33.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:33.538+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:11:33.535+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:11:33.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:11:33.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.567 seconds
[2025-01-13T22:12:04.054+0000] {processor.py:186} INFO - Started process (PID=947) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:04.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:12:04.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:12:04.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:04.539+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:12:04.536+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:12:04.540+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:04.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T22:12:34.895+0000] {processor.py:186} INFO - Started process (PID=949) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:34.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:12:34.900+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:12:34.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:35.357+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:12:35.354+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:12:35.358+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:12:35.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.554 seconds
[2025-01-13T22:13:05.851+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:05.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:13:05.881+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:13:05.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:06.334+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:13:06.331+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:13:06.335+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:06.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.521 seconds
[2025-01-13T22:13:36.669+0000] {processor.py:186} INFO - Started process (PID=953) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:36.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:13:36.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:13:36.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:37.193+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:13:37.174+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:13:37.194+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:13:37.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.590 seconds
[2025-01-13T22:14:08.178+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:08.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:14:08.182+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:14:08.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:08.643+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:14:08.639+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:14:08.643+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:08.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.516 seconds
[2025-01-13T22:14:39.092+0000] {processor.py:186} INFO - Started process (PID=957) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:39.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:14:39.097+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:14:39.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:39.584+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:14:39.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:14:39.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:14:39.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.533 seconds
[2025-01-13T22:15:10.337+0000] {processor.py:186} INFO - Started process (PID=959) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:10.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:15:10.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:15:10.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:10.792+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:15:10.789+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:15:10.793+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:10.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.499 seconds
[2025-01-13T22:15:41.106+0000] {processor.py:186} INFO - Started process (PID=961) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:41.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:15:41.112+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:15:41.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:41.636+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:15:41.632+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:15:41.636+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:15:41.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.610 seconds
[2025-01-13T22:16:11.920+0000] {processor.py:186} INFO - Started process (PID=963) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:11.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:16:11.925+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:16:11.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:12.441+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:16:12.438+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:16:12.442+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:12.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.583 seconds
[2025-01-13T22:16:42.942+0000] {processor.py:186} INFO - Started process (PID=965) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:42.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:16:42.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:16:42.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:43.433+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:16:43.429+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:16:43.433+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:16:43.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.549 seconds
[2025-01-13T22:17:13.942+0000] {processor.py:186} INFO - Started process (PID=967) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:13.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:17:13.947+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:17:13.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:14.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:17:14.425+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:17:14.429+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:14.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.529 seconds
[2025-01-13T22:17:44.923+0000] {processor.py:186} INFO - Started process (PID=969) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:44.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:17:44.929+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:17:44.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:45.353+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:17:45.349+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:17:45.353+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:17:45.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.506 seconds
[2025-01-13T22:18:15.919+0000] {processor.py:186} INFO - Started process (PID=971) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:15.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:18:15.926+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:18:15.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:16.427+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:18:16.424+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:18:16.428+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:16.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.568 seconds
[2025-01-13T22:18:46.941+0000] {processor.py:186} INFO - Started process (PID=973) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:46.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:18:46.947+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:18:46.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:47.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:18:47.369+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:18:47.373+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:18:47.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-13T22:19:17.936+0000] {processor.py:186} INFO - Started process (PID=975) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:17.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:19:17.941+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:19:17.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:18.482+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:19:18.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:19:18.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:18.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.609 seconds
[2025-01-13T22:19:48.712+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:48.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:19:48.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:19:48.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:49.194+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:19:49.191+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:19:49.194+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:19:49.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-13T22:20:19.453+0000] {processor.py:186} INFO - Started process (PID=979) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:19.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:20:19.460+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:20:19.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:19.917+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:20:19.913+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:20:19.917+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:19.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-13T22:20:50.482+0000] {processor.py:186} INFO - Started process (PID=981) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:50.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:20:50.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:20:50.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:50.962+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:20:50.959+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:20:50.963+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:20:50.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-13T22:21:21.339+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:21.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:21:21.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:21:21.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:21.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:21:21.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:21:21.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:21.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T22:21:52.318+0000] {processor.py:186} INFO - Started process (PID=985) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:52.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:21:52.329+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:21:52.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:52.757+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:21:52.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:21:52.757+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:21:52.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.469 seconds
[2025-01-13T22:22:23.289+0000] {processor.py:186} INFO - Started process (PID=987) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:23.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:22:23.293+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:22:23.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:23.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:22:23.774+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:22:23.778+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:23.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.528 seconds
[2025-01-13T22:22:54.174+0000] {processor.py:186} INFO - Started process (PID=989) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:54.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:22:54.179+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:22:54.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:54.668+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:22:54.664+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:22:54.668+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:22:54.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.535 seconds
[2025-01-13T22:23:25.143+0000] {processor.py:186} INFO - Started process (PID=991) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:25.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:23:25.148+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:23:25.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:25.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:23:25.664+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:23:25.671+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:25.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.571 seconds
[2025-01-13T22:23:56.117+0000] {processor.py:186} INFO - Started process (PID=993) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:56.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:23:56.121+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:23:56.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:56.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:23:56.571+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:23:56.575+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:23:56.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T22:24:27.047+0000] {processor.py:186} INFO - Started process (PID=995) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:27.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:24:27.051+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:24:27.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:27.484+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:24:27.479+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:24:27.484+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:27.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.484 seconds
[2025-01-13T22:24:58.037+0000] {processor.py:186} INFO - Started process (PID=997) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:58.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:24:58.042+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:24:58.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:58.642+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:24:58.638+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:24:58.642+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:24:58.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.649 seconds
[2025-01-13T22:25:29.187+0000] {processor.py:186} INFO - Started process (PID=999) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:25:29.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:25:29.194+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:25:29.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:25:29.702+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:25:29.699+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:25:29.703+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:25:29.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.583 seconds
[2025-01-13T22:25:59.865+0000] {processor.py:186} INFO - Started process (PID=1001) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:25:59.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:25:59.872+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:25:59.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:26:00.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:26:00.350+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:26:00.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:26:00.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.543 seconds
[2025-01-13T22:26:30.629+0000] {processor.py:186} INFO - Started process (PID=1003) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:26:30.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:26:30.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:26:30.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:26:31.116+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:26:31.111+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:26:31.116+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:26:31.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.564 seconds
[2025-01-13T22:27:01.243+0000] {processor.py:186} INFO - Started process (PID=1005) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:01.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:27:01.250+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:27:01.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:01.708+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:27:01.705+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:27:01.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:01.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.503 seconds
[2025-01-13T22:27:32.158+0000] {processor.py:186} INFO - Started process (PID=1007) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:32.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:27:32.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:27:32.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:32.633+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:27:32.629+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:27:32.634+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:27:32.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.516 seconds
[2025-01-13T22:28:03.138+0000] {processor.py:186} INFO - Started process (PID=1009) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:03.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:28:03.145+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:28:03.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:04.144+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:28:04.139+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:28:04.145+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:04.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 1.086 seconds
[2025-01-13T22:28:34.718+0000] {processor.py:186} INFO - Started process (PID=1011) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:34.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:28:34.725+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:28:34.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:35.197+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:28:35.194+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:28:35.198+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:28:35.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.549 seconds
[2025-01-13T22:29:05.668+0000] {processor.py:186} INFO - Started process (PID=1013) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:05.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:29:05.674+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:29:05.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:06.192+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:29:06.185+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:29:06.193+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:06.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.581 seconds
[2025-01-13T22:29:36.616+0000] {processor.py:186} INFO - Started process (PID=1015) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:36.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:29:36.622+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:29:36.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:37.066+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:29:37.062+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:29:37.066+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:29:37.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.504 seconds
[2025-01-13T22:30:07.591+0000] {processor.py:186} INFO - Started process (PID=1017) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:07.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:30:07.597+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:30:07.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:08.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:30:08.077+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:30:08.081+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:08.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.522 seconds
[2025-01-13T22:30:38.417+0000] {processor.py:186} INFO - Started process (PID=1019) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:38.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:30:38.420+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:30:38.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:38.879+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:30:38.875+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:30:38.880+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:30:38.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.500 seconds
[2025-01-13T22:31:09.400+0000] {processor.py:186} INFO - Started process (PID=1021) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:09.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:31:09.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:31:09.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:09.855+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:31:09.852+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:31:09.856+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:09.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.490 seconds
[2025-01-13T22:31:40.290+0000] {processor.py:186} INFO - Started process (PID=1023) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:40.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:31:40.294+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:31:40.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:40.765+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:31:40.762+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:31:40.765+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:31:40.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.526 seconds
[2025-01-13T22:32:11.319+0000] {processor.py:186} INFO - Started process (PID=1025) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:11.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:32:11.325+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:32:11.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:11.800+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:32:11.796+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:32:11.800+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:11.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-13T22:32:42.083+0000] {processor.py:186} INFO - Started process (PID=1027) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:42.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:32:42.087+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:32:42.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:42.545+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:32:42.542+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:32:42.545+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:32:42.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.498 seconds
[2025-01-13T22:33:13.040+0000] {processor.py:186} INFO - Started process (PID=1029) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:13.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:33:13.046+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:33:13.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:13.522+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:33:13.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:33:13.522+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:13.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.532 seconds
[2025-01-13T22:33:44.117+0000] {processor.py:186} INFO - Started process (PID=1031) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:44.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:33:44.121+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:33:44.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:44.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:33:44.589+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:33:44.593+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:33:44.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.513 seconds
[2025-01-13T22:34:15.199+0000] {processor.py:186} INFO - Started process (PID=1033) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:15.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:34:15.203+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:34:15.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:15.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:34:15.668+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:34:15.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:15.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.525 seconds
[2025-01-13T22:34:46.002+0000] {processor.py:186} INFO - Started process (PID=1035) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:46.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:34:46.008+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:34:46.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:46.459+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:34:46.454+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:34:46.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:34:46.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.520 seconds
[2025-01-13T22:35:16.672+0000] {processor.py:186} INFO - Started process (PID=1037) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:16.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:35:16.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:35:16.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:17.347+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:35:17.343+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:35:17.348+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:17.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.725 seconds
[2025-01-13T22:35:47.851+0000] {processor.py:186} INFO - Started process (PID=1039) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:47.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:35:47.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:35:47.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:48.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:35:48.341+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:35:48.345+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:35:48.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
[2025-01-13T22:36:18.696+0000] {processor.py:186} INFO - Started process (PID=1041) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:18.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:36:18.714+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:36:18.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:19.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:36:19.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:36:19.154+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:19.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.495 seconds
[2025-01-13T22:36:49.727+0000] {processor.py:186} INFO - Started process (PID=1043) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:49.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:36:49.731+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:36:49.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:50.416+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:36:50.413+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:36:50.416+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:36:50.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.742 seconds
[2025-01-13T22:37:20.727+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:20.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:37:20.733+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:37:20.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:21.251+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:37:21.248+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:37:21.252+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:21.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.566 seconds
[2025-01-13T22:37:51.655+0000] {processor.py:186} INFO - Started process (PID=1047) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:51.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:37:51.661+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:37:51.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:52.103+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:37:52.100+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:37:52.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:37:52.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.515 seconds
[2025-01-13T22:38:22.619+0000] {processor.py:186} INFO - Started process (PID=1049) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:22.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:38:22.648+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:38:22.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:23.121+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:38:23.117+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:38:23.121+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:23.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.541 seconds
[2025-01-13T22:38:53.593+0000] {processor.py:186} INFO - Started process (PID=1051) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:53.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:38:53.597+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:38:53.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:54.112+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:38:54.108+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:38:54.113+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:38:54.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.572 seconds
[2025-01-13T22:39:24.582+0000] {processor.py:186} INFO - Started process (PID=1053) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:24.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:39:24.587+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:39:24.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:25.083+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:39:25.079+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:39:25.083+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:25.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.546 seconds
[2025-01-13T22:39:55.717+0000] {processor.py:186} INFO - Started process (PID=1055) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:55.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:39:55.722+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:39:55.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:56.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:39:56.338+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:39:56.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:39:56.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.669 seconds
[2025-01-13T22:40:27.237+0000] {processor.py:186} INFO - Started process (PID=1057) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:40:27.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:40:27.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:40:27.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:40:27.723+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:40:27.720+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:40:27.723+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:40:27.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.550 seconds
[2025-01-13T22:45:27.811+0000] {processor.py:186} INFO - Started process (PID=1059) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:27.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:45:27.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:45:27.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:28.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:45:28.351+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:45:28.356+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:28.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.597 seconds
[2025-01-13T22:45:58.888+0000] {processor.py:186} INFO - Started process (PID=1061) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:58.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:45:58.893+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:45:58.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:59.350+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:45:59.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:45:59.351+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:45:59.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.502 seconds
[2025-01-13T22:46:29.581+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:46:29.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:46:29.586+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:46:29.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:46:30.069+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:46:30.066+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:46:30.069+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:46:30.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.537 seconds
[2025-01-13T22:47:00.300+0000] {processor.py:186} INFO - Started process (PID=1065) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:00.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:47:00.305+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:47:00.305+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:00.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:47:00.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:47:00.806+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:00.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.561 seconds
[2025-01-13T22:47:31.285+0000] {processor.py:186} INFO - Started process (PID=1067) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:31.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:47:31.294+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:47:31.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:31.780+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:47:31.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:47:31.780+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:47:31.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.540 seconds
[2025-01-13T22:48:02.251+0000] {processor.py:186} INFO - Started process (PID=1069) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:48:02.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T22:48:02.255+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:48:02.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:48:02.686+0000] {logging_mixin.py:190} INFO - [2025-01-13T22:48:02.683+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T22:48:02.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T22:48:02.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.508 seconds
[2025-01-13T23:47:16.369+0000] {processor.py:186} INFO - Started process (PID=1071) to work on /opt/airflow/dags/reddis_dag.py
[2025-01-13T23:47:16.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddis_dag.py for tasks to queue
[2025-01-13T23:47:16.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T23:47:16.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddis_dag.py
[2025-01-13T23:47:16.866+0000] {logging_mixin.py:190} INFO - [2025-01-13T23:47:16.862+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddis_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/configparser.py", line 789, in get
    value = d[option]
  File "/usr/local/lib/python3.9/collections/__init__.py", line 941, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.9/collections/__init__.py", line 933, in __missing__
    raise KeyError(key)
KeyError: 'aws_access_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/reddis_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 9, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 18, in <module>
    AWS_ACCESS_KEY = parser.get('aws', 'aws_access_key')
  File "/usr/local/lib/python3.9/configparser.py", line 792, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'aws_access_key' in section: 'aws'
[2025-01-13T23:47:16.867+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddis_dag.py
[2025-01-13T23:47:16.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddis_dag.py took 0.552 seconds
